{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:06.378196Z",
     "start_time": "2025-05-17T17:46:01.039134Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File and create a new dataframe called df\n",
    "df = pd.read_csv('dataset_1.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:06.415399Z",
     "start_time": "2025-05-17T17:46:06.407491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_fractions(text):\n",
    "    # Match optional whole number + fraction, or just fraction\n",
    "    pattern = r'(?:(\\d+)\\s+)?(\\d+)/(\\d+)'\n",
    "\n",
    "    def replacer(match):\n",
    "        whole = int(match.group(1)) if match.group(1) else 0\n",
    "        numerator = int(match.group(2))\n",
    "        denominator = int(match.group(3))\n",
    "        decimal = whole + Fraction(numerator, denominator)\n",
    "        return \"{:.10g}\".format(float(decimal))  # Clean, no trailing zeros\n",
    "\n",
    "    return re.sub(pattern, replacer, text)"
   ],
   "id": "f6177b908ebf022c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:06.471894Z",
     "start_time": "2025-05-17T17:46:06.464509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "# fixed conversions\n",
    "CONVERSIONS = {\n",
    "    \"oz\": 30,      # ounce → gram\n",
    "    \"lb\": 450,      # pounds → gram\n",
    "    \"pt\": 475,      # pint → milliliter\n",
    "    \"qt\": 950,      # quart → milliliter\n",
    "    \"inch\": 2.5        # inches → centimeter\n",
    "}"
   ],
   "id": "35a1e5c191694098",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:07.648770Z",
     "start_time": "2025-05-17T17:46:07.639759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_units(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # Convert oz, lb, pt, qt (form: \"4 oz\", \"2.5 lb\", etc.)\n",
    "    for unit, factor in CONVERSIONS.items():\n",
    "        pattern = r'(\\d+(\\.\\d+)?)\\s*' + unit\n",
    "        text = re.sub(pattern, lambda m: f\"{round(float(m.group(1)) * factor, 1)} {unit_to_metric(unit)}\", text)\n",
    "\n",
    "    # Convert measure in inches in pans\n",
    "    text = re.sub(r'(\\d+)\\s*x\\s*(\\d+)[-\\s]*inch', lambda m: f\"{int(m.group(1)) * CONVERSIONS['inch']:.0f} x {int(m.group(2)) * CONVERSIONS['inch']:.0f} cm\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_fahrenheit_to_celsius(text):\n",
    "    # Match degrees like 275°, 275 °F, 275\\u00b0F (escaped), etc.\n",
    "    pattern = r'(\\d+)\\s*(?:°|\\\\u00b0)'\n",
    "\n",
    "    def replacer(match):\n",
    "        fahrenheit = int(match.group(1))\n",
    "        celsius = round((fahrenheit - 32) * 5 / 9)\n",
    "        return f\"{celsius}°C\"\n",
    "\n",
    "    return re.sub(pattern, replacer, text)\n",
    "\n",
    "def unit_to_metric(unit):\n",
    "    return {\n",
    "        \"oz\": \"g\",\n",
    "        \"lb\": \"g\",\n",
    "        \"pt\": \"ml\",\n",
    "        \"qt\": \"ml\",\n",
    "        \"inch\": \"cm\"\n",
    "    }[unit]"
   ],
   "id": "575170d6f2d61a67",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:37.999575Z",
     "start_time": "2025-05-17T17:46:07.792594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#applying conversions on the INGREDIENTS and DIRECTIOND columns\n",
    "df['INGREDIENTS'] = df['ingredients'].apply(convert_fractions)\n",
    "df['DIRECTIONS'] = df['directions'].apply(convert_fractions)\n",
    "\n",
    "df['INGREDIENTS'] = df['INGREDIENTS'].apply(convert_units)\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_units)\n",
    "\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_fahrenheit_to_celsius)\n",
    "\n",
    "#renaming the title column\n",
    "df = df.rename(columns={\"title\": \"TITLE\"})\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS']].head(200)"
   ],
   "id": "f1908c40439dd4ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     TITLE                                        INGREDIENTS  \\\n",
       "0      No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"0.5 c. eva...   \n",
       "1    Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2              Creamy Corn  [\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....   \n",
       "3            Chicken Funny  [\"1 large whole chicken\", \"2 (315.0 g.) cans c...   \n",
       "4     Reeses Cups(Candy)    [\"1 c. peanut butter\", \"0.75 c. graham cracker...   \n",
       "..                     ...                                                ...   \n",
       "195             Golf Balls  [\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...   \n",
       "196      Crispy Herb Bread  [\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...   \n",
       "197    Festive Fruit Salad  [\"1 (600.0 g.) can pineapple chunks, drained (...   \n",
       "198   Fresh Strawberry Pie  [\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...   \n",
       "199            Egg Custard  [\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....   \n",
       "\n",
       "                                            DIRECTIONS  \n",
       "0    [\"In a heavy 2-quart saucepan, mix brown sugar...  \n",
       "1    [\"Place chipped beef on bottom of baking dish....  \n",
       "2    [\"In a slow cooker, combine all ingredients. C...  \n",
       "3    [\"Boil and debone chicken.\", \"Put bite size pi...  \n",
       "4    [\"Combine first four ingredients and press in ...  \n",
       "..                                                 ...  \n",
       "195  [\"Beat all ingredients together except peanut ...  \n",
       "196  [\"In a small bowl, combine oil and garlic powd...  \n",
       "197  [\"Combine pineapple, oranges, grapes, strawber...  \n",
       "198  [\"Cut up 1 cup strawberries.\", \"Add water.\", \"...  \n",
       "199  [\"Preheat oven to 204°C.\", \"Bake empty pie she...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>DIRECTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"0.5 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (315.0 g.) cans c...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"0.75 c. graham cracker...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Golf Balls</td>\n",
       "      <td>[\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...</td>\n",
       "      <td>[\"Beat all ingredients together except peanut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Crispy Herb Bread</td>\n",
       "      <td>[\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...</td>\n",
       "      <td>[\"In a small bowl, combine oil and garlic powd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Festive Fruit Salad</td>\n",
       "      <td>[\"1 (600.0 g.) can pineapple chunks, drained (...</td>\n",
       "      <td>[\"Combine pineapple, oranges, grapes, strawber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Fresh Strawberry Pie</td>\n",
       "      <td>[\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...</td>\n",
       "      <td>[\"Cut up 1 cup strawberries.\", \"Add water.\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Egg Custard</td>\n",
       "      <td>[\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....</td>\n",
       "      <td>[\"Preheat oven to 204°C.\", \"Bake empty pie she...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:49.293160Z",
     "start_time": "2025-05-17T17:46:38.145083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# patterns to detect time expressions\n",
    "time_pattern = re.compile(\n",
    "    r'(\\d+\\.?\\d*)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h|day|days|d)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "range_pattern = re.compile(\n",
    "    r'(\\d+)\\s*-\\s*(\\d+)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Time estimates for common preparation methods\n",
    "PREP_ESTIMATES = {\n",
    "    'bake': 45,\n",
    "    'boil': 20,\n",
    "    'fry': 15,\n",
    "    'grill': 25,\n",
    "    'chill': 120,\n",
    "    'simmer': 30,\n",
    "    'marinate': 60,\n",
    "    'microwave': 10,\n",
    "    'no-bake': 20,\n",
    "    'refrigerate': 180,\n",
    "    'freeze': 240\n",
    "}\n",
    "\n",
    "# Special cases for recipe types\n",
    "RECIPE_TYPE_ESTIMATES = {\n",
    "    'pasta': 10,\n",
    "    'salad': 15,\n",
    "    'cake': 45,\n",
    "    'pie': 60,\n",
    "    'stew': 120,\n",
    "    'casserole': 60,\n",
    "    'soup': 30,\n",
    "    'cookies': 30,\n",
    "    'bread': 90,\n",
    "    'fudge': 20,\n",
    "    'candy': 30\n",
    "}\n",
    "\n",
    "# Convert time quantities to minutes\n",
    "def convert_to_minutes(qty, unit):\n",
    "    qty = float(qty)\n",
    "    unit = unit.lower()\n",
    "    if unit in ['minute', 'minutes', 'min', 'mins', 'm']:\n",
    "        return qty\n",
    "    elif unit in ['hour', 'hours', 'hr', 'hrs', 'h']:\n",
    "        return qty * 60\n",
    "    elif unit in ['day', 'days', 'd']:\n",
    "        return qty * 24 * 60\n",
    "    return 0\n",
    "\n",
    "# Estimate time on recipe type\n",
    "def estimate_by_recipe_type(recipe_name, ingredients):\n",
    "    recipe_name = str(recipe_name).lower()\n",
    "    ingredients = str(ingredients).lower()\n",
    "\n",
    "    # Check for specific recipe types\n",
    "    for recipe_type, time in RECIPE_TYPE_ESTIMATES.items():\n",
    "        if recipe_type in recipe_name:\n",
    "            return time\n",
    "\n",
    "    # Estimate based on ingredients\n",
    "    if 'raw' in ingredients or 'fresh' in ingredients:\n",
    "        return 15\n",
    "    if 'frozen' in ingredients:\n",
    "        return 20\n",
    "    if 'canned' in ingredients:\n",
    "        return 10\n",
    "\n",
    "    # Default estimation\n",
    "    return 30\n",
    "\n",
    "# Extract and sum all time references from recipe instructions\n",
    "def parse_instructions(instructions):\n",
    "    if isinstance(instructions, str):\n",
    "        try:\n",
    "            instructions = ast.literal_eval(instructions)\n",
    "        except:\n",
    "            instructions = [instructions]\n",
    "\n",
    "    total_time = 0\n",
    "    for step in instructions:\n",
    "        if not isinstance(step, str):\n",
    "            continue\n",
    "\n",
    "        # Handle time ranges\n",
    "        step = re.sub(\n",
    "            range_pattern,\n",
    "            lambda m: f'{m.group(2)} {m.group(3)}',\n",
    "            step\n",
    "        )\n",
    "\n",
    "        # Special cases\n",
    "        if 'overnight' in step.lower():\n",
    "            total_time += 480  # 8 hours\n",
    "        elif 'until set' in step.lower() or 'until firm' in step.lower():\n",
    "            total_time += 60  # 1 hour estimation\n",
    "\n",
    "        # Find all time references\n",
    "        matches = time_pattern.findall(step)\n",
    "        for (qty, unit) in matches:\n",
    "            total_time += convert_to_minutes(qty, unit)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "def categorize_time(total_time):\n",
    "    if total_time == 0:\n",
    "        return 'Not specified'\n",
    "    elif total_time < 10:\n",
    "        return 'Very fast (0-10 mins)'\n",
    "    elif 10 <= total_time < 20:\n",
    "        return 'Fast (10-20 mins)'\n",
    "    elif 20 <= total_time < 40:\n",
    "        return 'Medium (20-40 mins)'\n",
    "    elif 40 <= total_time < 90:\n",
    "        return 'Slow (40-90 mins)'\n",
    "    else:\n",
    "        return 'Very slow (90+ mins)'\n",
    "\n",
    "# Calculate total preparation time\n",
    "df['total_time'] = df['DIRECTIONS'].apply(parse_instructions)\n",
    "\n",
    "# Estimate time for unspecified recipes\n",
    "mask = df['total_time'] == 0\n",
    "df.loc[mask, 'total_time'] = df[mask].apply(\n",
    "    lambda x: estimate_by_recipe_type(x['TITLE'], x['INGREDIENTS']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Categorize preparation times\n",
    "df['PREPARATION_TIME'] = df['total_time'].apply(categorize_time)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS', 'PREPARATION_TIME']].head(200)"
   ],
   "id": "4ca47d472c93a067",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     TITLE                                        INGREDIENTS  \\\n",
       "0      No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"0.5 c. eva...   \n",
       "1    Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2              Creamy Corn  [\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....   \n",
       "3            Chicken Funny  [\"1 large whole chicken\", \"2 (315.0 g.) cans c...   \n",
       "4     Reeses Cups(Candy)    [\"1 c. peanut butter\", \"0.75 c. graham cracker...   \n",
       "..                     ...                                                ...   \n",
       "195             Golf Balls  [\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...   \n",
       "196      Crispy Herb Bread  [\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...   \n",
       "197    Festive Fruit Salad  [\"1 (600.0 g.) can pineapple chunks, drained (...   \n",
       "198   Fresh Strawberry Pie  [\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...   \n",
       "199            Egg Custard  [\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....   \n",
       "\n",
       "                                            DIRECTIONS       PREPARATION_TIME  \n",
       "0    [\"In a heavy 2-quart saucepan, mix brown sugar...   Very slow (90+ mins)  \n",
       "1    [\"Place chipped beef on bottom of baking dish....   Very slow (90+ mins)  \n",
       "2    [\"In a slow cooker, combine all ingredients. C...   Very slow (90+ mins)  \n",
       "3    [\"Boil and debone chicken.\", \"Put bite size pi...    Medium (20-40 mins)  \n",
       "4    [\"Combine first four ingredients and press in ...    Medium (20-40 mins)  \n",
       "..                                                 ...                    ...  \n",
       "195  [\"Beat all ingredients together except peanut ...    Medium (20-40 mins)  \n",
       "196  [\"In a small bowl, combine oil and garlic powd...  Very fast (0-10 mins)  \n",
       "197  [\"Combine pineapple, oranges, grapes, strawber...      Fast (10-20 mins)  \n",
       "198  [\"Cut up 1 cup strawberries.\", \"Add water.\", \"...   Very slow (90+ mins)  \n",
       "199  [\"Preheat oven to 204°C.\", \"Bake empty pie she...  Very fast (0-10 mins)  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>DIRECTIONS</th>\n",
       "      <th>PREPARATION_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"0.5 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (315.0 g.) cans c...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"0.75 c. graham cracker...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Golf Balls</td>\n",
       "      <td>[\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...</td>\n",
       "      <td>[\"Beat all ingredients together except peanut ...</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Crispy Herb Bread</td>\n",
       "      <td>[\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...</td>\n",
       "      <td>[\"In a small bowl, combine oil and garlic powd...</td>\n",
       "      <td>Very fast (0-10 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Festive Fruit Salad</td>\n",
       "      <td>[\"1 (600.0 g.) can pineapple chunks, drained (...</td>\n",
       "      <td>[\"Combine pineapple, oranges, grapes, strawber...</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Fresh Strawberry Pie</td>\n",
       "      <td>[\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...</td>\n",
       "      <td>[\"Cut up 1 cup strawberries.\", \"Add water.\", \"...</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Egg Custard</td>\n",
       "      <td>[\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....</td>\n",
       "      <td>[\"Preheat oven to 204°C.\", \"Bake empty pie she...</td>\n",
       "      <td>Very fast (0-10 mins)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-17T17:46:54.569973Z",
     "start_time": "2025-05-17T17:46:49.406841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "\n",
    "# Converts teh column from strings to python lists\n",
    "df['NER_clean'] = df['NER'].apply(ast.literal_eval)\n",
    "\n",
    "# Creates a list of ingredients using the NER column\n",
    "all_ner = [item.strip().lower() for sublist in df['NER_clean'] for item in sublist]\n",
    "\n",
    "# Removes duplicates and sort the list\n",
    "unique_ingredients = sorted(set(all_ner))\n",
    "\n",
    "df_unique_ingredients = pd.DataFrame(unique_ingredients, columns=['Ingredient'])"
   ],
   "id": "637704cd639f1e51",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# 1. Carica prezzi e normalizza le chiavi\n",
    "prices_df = pd.read_csv('ingredients_prices')  # Assicurati dell'estensione .csv\n",
    "price_dict = {k.strip().lower(): v for k, v in prices_df.set_index('Ingredient')['Cost'].items()}\n",
    "\n",
    "# 2. Conversione unità → kg\n",
    "UNIT_CONVERSION = {\n",
    "    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\n",
    "    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\n",
    "    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\n",
    "    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\n",
    "    'can': 0.4, 'carton': 1.0,\n",
    "    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\n",
    "    'kg': 1.0, 'kilogram': 1.0,\n",
    "    'lb': 0.4536, 'pound': 0.4536,\n",
    "    'oz': 0.02835, 'ounce': 0.02835,\n",
    "    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\n",
    "}\n",
    "\n",
    "# 3. Parsing function (qty, unit, name, grams_in_paren)\n",
    "def parse_ingredient(ing_str):\n",
    "    # peso fra parentesi\n",
    "    m = re.search(r'\\(\\s*([0-9]+(?:\\.[0-9]+)?)\\s*g\\.?\\s*\\)', ing_str, re.IGNORECASE)\n",
    "    grams = float(m.group(1)) if m else None\n",
    "\n",
    "    # quantity e unit\n",
    "    patt = r'^\\s*([\\d\\/.\\s]+)?\\s*([a-zA-Z\\.]+)?'\n",
    "    m2 = re.match(patt, ing_str)\n",
    "    qty_raw = m2.group(1) if m2 else None\n",
    "    try:\n",
    "        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\n",
    "    except:\n",
    "        qty = 1.0\n",
    "    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\n",
    "\n",
    "    # name pulito\n",
    "    name = re.sub(r'\\(.*?\\)|optional', '', ing_str, flags=re.IGNORECASE)\n",
    "    # rimuovo quantità/unità\n",
    "    name = re.sub(r'^[\\d\\/.\\s]+\\s*[a-zA-Z\\.]*', '', name).strip().lower()\n",
    "    return qty, unit, name, grams\n",
    "\n",
    "# 4. Calcolo posizionale con fallback substring e token\n",
    "def calculate_recipe_cost_positional(ingredients_list, ner_list):\n",
    "    total = 0.0\n",
    "    missing = []\n",
    "\n",
    "    for ing_str, ner_item in zip(ingredients_list, ner_list):\n",
    "        key = ner_item.lower()\n",
    "        qty, unit, name, grams = parse_ingredient(ing_str)\n",
    "\n",
    "        # scorporo se passo i grams\n",
    "        if grams is not None:\n",
    "            kg = (grams / 1000) * qty\n",
    "        elif unit == '':  # a pezzo\n",
    "            # prendo prezzo direct key\n",
    "            price = price_dict.get(key)\n",
    "            # fallback substring/token\n",
    "            if price is None:\n",
    "                # substring match\n",
    "                for k, v in price_dict.items():\n",
    "                    if k in key or key in k:\n",
    "                        price = v\n",
    "                        break\n",
    "                # token match\n",
    "                if price is None:\n",
    "                    for token in key.split():\n",
    "                        if token in price_dict:\n",
    "                            price = price_dict[token]\n",
    "                            break\n",
    "            if price:\n",
    "                total += qty * price\n",
    "            else:\n",
    "                missing.append(key)\n",
    "            continue\n",
    "        else:\n",
    "            conv = UNIT_CONVERSION.get(unit, 0.0)\n",
    "            if conv == 0:\n",
    "                missing.append(key)\n",
    "                continue\n",
    "            kg = qty * conv\n",
    "\n",
    "        # prezzo per kg\n",
    "        price = price_dict.get(key)\n",
    "        if price is None:\n",
    "            for k, v in price_dict.items():\n",
    "                if k in key or key in k:\n",
    "                    price = v\n",
    "                    break\n",
    "        if price is None:\n",
    "            missing.append(key)\n",
    "            continue\n",
    "\n",
    "        total += kg * price\n",
    "\n",
    "    return round(total, 2), missing\n",
    "\n",
    "# 5. Applica al DataFrame\n",
    "    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "def compute_cost_row(row):\n",
    "     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\n",
    "     return cost\n",
    "\n",
    "def categorize_cost(total_cost):\n",
    "    if total_cost == 0:\n",
    "        return 'Not specified'\n",
    "    elif total_cost < 10:\n",
    "        return 'Very cheap'\n",
    "    elif 10 <= total_cost < 20:\n",
    "        return 'Cheap'\n",
    "    elif 20 <= total_cost < 45:\n",
    "        return 'Medium'\n",
    "    elif 45 <= total_cost < 90:\n",
    "        return 'Expensive'\n",
    "    else:\n",
    "        return 'Rich'\n",
    "\n",
    "df['total_cost'] = df.apply(compute_cost_row, axis=1)\n",
    "\n",
    "df['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\n",
    "\n",
    "# Mostra risultati\n",
    "df[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T17:47:13.066718Z",
     "start_time": "2025-05-17T17:46:54.810031Z"
    }
   },
   "id": "b4b4981d552d3aac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           INGREDIENTS  \\\n",
       "0    [\"1 c. firmly packed brown sugar\", \"0.5 c. eva...   \n",
       "1    [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2    [\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....   \n",
       "3    [\"1 large whole chicken\", \"2 (315.0 g.) cans c...   \n",
       "4    [\"1 c. peanut butter\", \"0.75 c. graham cracker...   \n",
       "..                                                 ...   \n",
       "195  [\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...   \n",
       "196  [\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...   \n",
       "197  [\"1 (600.0 g.) can pineapple chunks, drained (...   \n",
       "198  [\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...   \n",
       "199  [\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....   \n",
       "\n",
       "                                                   NER CATEGORY_COST  \n",
       "0    [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...        Medium  \n",
       "1    [\"beef\", \"chicken breasts\", \"cream of mushroom...        Medium  \n",
       "2    [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...          Rich  \n",
       "3    [\"chicken\", \"chicken gravy\", \"cream of mushroo...        Medium  \n",
       "4    [\"peanut butter\", \"graham cracker crumbs\", \"bu...        Medium  \n",
       "..                                                 ...           ...  \n",
       "195  [\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...        Medium  \n",
       "196  [\"olive oil\", \"garlic powder\", \"bread\", \"thyme...     Expensive  \n",
       "197  [\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...          Rich  \n",
       "198  [\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...        Medium  \n",
       "199  [\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...        Medium  \n",
       "\n",
       "[200 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>NER</th>\n",
       "      <th>CATEGORY_COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"0.5 c. eva...</td>\n",
       "      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"2 (480.0 g.) pkg. frozen corn\", \"1 (240.0 g....</td>\n",
       "      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"1 large whole chicken\", \"2 (315.0 g.) cans c...</td>\n",
       "      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"1 c. peanut butter\", \"0.75 c. graham cracker...</td>\n",
       "      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[\"1 c. cocoa\", \"1 c. butter, softened\", \"3 (45...</td>\n",
       "      <td>[\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[\"4 tsp. olive oil\", \"0.5 tsp. garlic powder\",...</td>\n",
       "      <td>[\"olive oil\", \"garlic powder\", \"bread\", \"thyme...</td>\n",
       "      <td>Expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[\"1 (600.0 g.) can pineapple chunks, drained (...</td>\n",
       "      <td>[\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...</td>\n",
       "      <td>Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[\"950.0 ml. strawberries\", \"0.75 c. water\", \"p...</td>\n",
       "      <td>[\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[\"2 c. sugar\", \"5 eggs\", \"2 c. milk\", \"2 Tbsp....</td>\n",
       "      <td>[\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:49:23.387403Z",
     "start_time": "2025-05-17T17:47:13.276040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Lista estesa di ingredienti non vegani con controllo contestuale\n",
    "NON_VEGAN_KEYWORDS = {\n",
    "    'milk', 'cheese', 'butter', 'cream', 'yogurt', 'gelatin', 'lard', 'honey',\n",
    "    'egg', 'eggs', 'fish', 'meat', 'chicken', 'beef', 'pork', 'gelatina',\n",
    "    'collagen', 'casein', 'whey', 'lactose', 'ghee', 'isinglass', 'carmine',\n",
    "    'shellac', 'albumen', 'pepsin', 'royal jelly', 'propolis', 'cocoa butter',\n",
    "    'bacon', 'sour cream', 'condensed milk', 'shredded cheese', 'cheddar',\n",
    "    'paraffin', 'marshmallows', 'buttermilk', 'ground beef'\n",
    "}\n",
    "\n",
    "# Eccezioni per sostituti vegani comuni\n",
    "VEGAN_EXCEPTIONS = {\n",
    "    'milk': {'soy', 'almond', 'oat', 'rice', 'coconut', 'cashew', 'hazelnut'},\n",
    "    'cheese': {'vegan', 'nutritional yeast', 'cashew', 'tofu'},\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'butter': {'vegan', 'plant', 'peanut', 'almond', 'soy'},\n",
    "    'cream': {'coconut', 'soy', 'oat', 'vegan'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'}\n",
    "}\n",
    "\n",
    "VEGAN_MODIFIERS = {\n",
    "    'vegan', 'vegetable', 'plant-based', 'no milk', 'no eggs',\n",
    "    'dairy-free', 'without animal derivatives', 'cruelty-free', '100% vegetable'\n",
    "}\n",
    "\n",
    "def contains_vegan_exception(ingredient, keyword):\n",
    "    exceptions = VEGAN_EXCEPTIONS.get(keyword, set())\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE) for ex in exceptions)\n",
    "\n",
    "def is_vegan_recipe(ingredients_input):\n",
    "    \"\"\"\n",
    "    Ritorna True se la ricetta è vegana, False altrimenti.\n",
    "    Gestisce sia input già in lista sia stringhe da parsare.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) Se è già una lista, la uso direttamente\n",
    "        if isinstance(ingredients_input, list):\n",
    "            ingredients = ingredients_input\n",
    "        # 2) Altrimenti, se è una stringa non vuota, provo a parsarla\n",
    "        elif isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "            try:\n",
    "                ingredients = ast.literal_eval(ingredients_input)\n",
    "            except:\n",
    "                ingredients = [\n",
    "                    x.strip().strip('\"').strip(\"'\")\n",
    "                    for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                    if x.strip()\n",
    "                ]\n",
    "        else:\n",
    "            # input mancante o non valido: consideralo non vegano\n",
    "            return False\n",
    "\n",
    "        # Ora ingredients è sicuramente una lista\n",
    "        for ingredient in ingredients:\n",
    "            if not isinstance(ingredient, str):\n",
    "                continue\n",
    "            ing = ingredient.lower()\n",
    "\n",
    "            # Skip solo di acqua e sale\n",
    "            if any(skip in ing for skip in ['water', 'salt']):\n",
    "                continue\n",
    "\n",
    "            # Controlla se contiene un NON_VEGAN_KEYWORD non neutralizzato da eccezioni\n",
    "            for keyword in NON_VEGAN_KEYWORDS:\n",
    "                # support pluralizzazione semplice\n",
    "                pat = rf'\\b{re.escape(keyword)}(?:s)?\\b'\n",
    "                if re.search(pat, ing):\n",
    "                    # se non c'è un'eccezione vegana per quel keyword, non è vegana\n",
    "                    if not contains_vegan_exception(ing, keyword):\n",
    "                        return False\n",
    "                    # altrimenti abbiamo un sostituto (es. \"almond milk\") e continuiamo\n",
    "                    break\n",
    "\n",
    "            # infine, se trovi un modifier esplicito tipo \"vegan\" sei a posto\n",
    "            if any(re.search(rf'\\b{re.escape(mod)}\\b', ing) for mod in VEGAN_MODIFIERS):\n",
    "                # anche se c'era un keyword, il modifier lo rende vegano\n",
    "                continue\n",
    "\n",
    "        # se arrivo qui, non ho trovato elementi non-neutralizzati\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore analisi ingredienti: {e}\")\n",
    "        return False\n",
    "\n",
    "def find_non_vegan_ingredients(ingredients_input):\n",
    "    non_vegan_items = []\n",
    "    try:\n",
    "        # 1) se è già una lista, la uso direttamente\n",
    "        if isinstance(ingredients_input, list):\n",
    "            ingredients = ingredients_input\n",
    "        # 2) altrimenti provo a parse da stringa\n",
    "        elif isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "            try:\n",
    "                ingredients = ast.literal_eval(ingredients_input)\n",
    "            except:\n",
    "                ingredients = [\n",
    "                    x.strip().strip('\"').strip(\"'\")\n",
    "                    for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                    if x.strip()\n",
    "                ]\n",
    "        else:\n",
    "            return non_vegan_items\n",
    "\n",
    "        # ora ingredients è sicuramente una lista\n",
    "        for ingredient in ingredients:\n",
    "            if not isinstance(ingredient, str):\n",
    "                continue\n",
    "\n",
    "            ing = ingredient.lower()\n",
    "\n",
    "            # facciamo solo skip di acqua e sale, non di \"sugar\"\n",
    "            if any(skip in ing for skip in ['water', 'salt']):\n",
    "                continue\n",
    "\n",
    "            for keyword in NON_VEGAN_KEYWORDS:\n",
    "                pat = rf'\\b{re.escape(keyword)}(?:s)?\\b'\n",
    "                if re.search(pat, ing):\n",
    "                    if not contains_vegan_exception(ing, keyword):\n",
    "                        non_vegan_items.append(ingredient)\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore ricerca ingredienti non vegani: {e}\")\n",
    "\n",
    "    return non_vegan_items\n",
    "\n",
    "# Applica le funzioni al dataframe\n",
    "df['VEGAN'] = df['NER_clean'].apply(is_vegan_recipe)\n",
    "df['NON_VEGAN_INGREDIENTS'] = df['NER_clean'].apply(find_non_vegan_ingredients)\n",
    "\n",
    "# Funzione di validazione aggiuntiva\n",
    "def vegan_validation(row):\n",
    "    try:\n",
    "        if row['VEGAN']:\n",
    "            # Controllo incrociato sul nome\n",
    "            anti_patterns = re.compile(\n",
    "                r'\\b(not vegan|meat|fish|cheese|egg|eggs|beef|chicken|pork|bacon|cream)\\b',\n",
    "                re.IGNORECASE\n",
    "            )\n",
    "            if isinstance(row['TITLE'], str) and anti_patterns.search(row['TITLE']):\n",
    "                return False\n",
    "        return row['VEGAN']\n",
    "    except:\n",
    "        return row['VEGAN']\n",
    "\n",
    "df['VEGAN'] = df.apply(vegan_validation, axis=1)\n",
    "\n",
    "# Mostra i risultati - CORREZIONE: usa una lista di colonne\n",
    "df[['TITLE', 'NER', 'VEGAN', 'NON_VEGAN_INGREDIENTS']].head(200)"
   ],
   "id": "6a891063014b4502",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     TITLE                                                NER  \\\n",
       "0      No-Bake Nut Cookies  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...   \n",
       "1    Jewell Ball'S Chicken  [\"beef\", \"chicken breasts\", \"cream of mushroom...   \n",
       "2              Creamy Corn  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...   \n",
       "3            Chicken Funny  [\"chicken\", \"chicken gravy\", \"cream of mushroo...   \n",
       "4     Reeses Cups(Candy)    [\"peanut butter\", \"graham cracker crumbs\", \"bu...   \n",
       "..                     ...                                                ...   \n",
       "195             Golf Balls  [\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...   \n",
       "196      Crispy Herb Bread  [\"olive oil\", \"garlic powder\", \"bread\", \"thyme...   \n",
       "197    Festive Fruit Salad  [\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...   \n",
       "198   Fresh Strawberry Pie  [\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...   \n",
       "199            Egg Custard  [\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...   \n",
       "\n",
       "     VEGAN                              NON_VEGAN_INGREDIENTS  \n",
       "0    False                                     [milk, butter]  \n",
       "1    False  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2    False                             [cream cheese, butter]  \n",
       "3    False  [chicken, chicken gravy, cream of mushroom sou...  \n",
       "4    False                                           [butter]  \n",
       "..     ...                                                ...  \n",
       "195  False                                     [butter, milk]  \n",
       "196  False                                  [Parmesan cheese]  \n",
       "197  False                                     [marshmallows]  \n",
       "198  False                                           [butter]  \n",
       "199  False                                       [eggs, milk]  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NER</th>\n",
       "      <th>VEGAN</th>\n",
       "      <th>NON_VEGAN_INGREDIENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n",
       "      <td>False</td>\n",
       "      <td>[milk, butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n",
       "      <td>False</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n",
       "      <td>False</td>\n",
       "      <td>[cream cheese, butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n",
       "      <td>False</td>\n",
       "      <td>[chicken, chicken gravy, cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n",
       "      <td>False</td>\n",
       "      <td>[butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Golf Balls</td>\n",
       "      <td>[\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[butter, milk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Crispy Herb Bread</td>\n",
       "      <td>[\"olive oil\", \"garlic powder\", \"bread\", \"thyme...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Parmesan cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Festive Fruit Salad</td>\n",
       "      <td>[\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...</td>\n",
       "      <td>False</td>\n",
       "      <td>[marshmallows]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Fresh Strawberry Pie</td>\n",
       "      <td>[\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...</td>\n",
       "      <td>False</td>\n",
       "      <td>[butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Egg Custard</td>\n",
       "      <td>[\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...</td>\n",
       "      <td>False</td>\n",
       "      <td>[eggs, milk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:50:57.179309Z",
     "start_time": "2025-05-17T17:49:23.546599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lista ingredienti non vegetariani\n",
    "NON_VEGETARIAN_KEYWORDS = {\n",
    "    'meat', 'chicken', 'beef', 'pork', 'fish', 'anchovy', 'tuna', 'salmon',\n",
    "    'shellfish', 'shrimp', 'crab', 'lobster', 'bacon', 'gelatin', 'lard',\n",
    "    'collagen', 'isinglass', 'pepsin', 'ground beef'\n",
    "}\n",
    "\n",
    "# Eccezioni per sostituti vegetariani\n",
    "VEGETARIAN_EXCEPTIONS = {\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'},\n",
    "    'gelatin': {'agar', 'pectin'},\n",
    "    'fish': {'banana blossom', 'tofu', 'plant-based'}\n",
    "}\n",
    "\n",
    "VEGETARIAN_MODIFIERS = {\n",
    "    'vegetarian', 'veggie', 'plant-based', 'meatless', 'no meat',\n",
    "    'without meat', 'cruelty-free'\n",
    "}\n",
    "\n",
    "def contains_vegetarian_exception(ingredient, keyword):\n",
    "    exceptions = VEGETARIAN_EXCEPTIONS.get(keyword, set())\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE) for ex in exceptions)\n",
    "\n",
    "def is_vegetarian_recipe(ingredients_input):\n",
    "    try:\n",
    "        if isinstance(ingredients_input, list):\n",
    "            ingredients = ingredients_input\n",
    "        elif isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "            try:\n",
    "                ingredients = ast.literal_eval(ingredients_input)\n",
    "            except:\n",
    "                ingredients = [\n",
    "                    x.strip().strip('\"').strip(\"'\")\n",
    "                    for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                    if x.strip()\n",
    "                ]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        for ingredient in ingredients:\n",
    "            if not isinstance(ingredient, str):\n",
    "                continue\n",
    "\n",
    "            ing = ingredient.lower()\n",
    "\n",
    "            # Skip base\n",
    "            if any(skip in ing for skip in ['water', 'salt']):\n",
    "                continue\n",
    "\n",
    "            for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "                pat = rf'\\b{re.escape(keyword)}(?:s)?\\b'\n",
    "                if re.search(pat, ing):\n",
    "                    if not contains_vegetarian_exception(ing, keyword):\n",
    "                        return False\n",
    "                    break\n",
    "\n",
    "            if any(re.search(rf'\\b{re.escape(mod)}\\b', ing) for mod in VEGETARIAN_MODIFIERS):\n",
    "                continue\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Errore analisi ingredienti (vegetariana): {e}\")\n",
    "        return False\n",
    "\n",
    "def find_non_vegetarian_ingredients(ingredients_input):\n",
    "    non_vegetarian_items = []\n",
    "    try:\n",
    "        if isinstance(ingredients_input, list):\n",
    "            ingredients = ingredients_input\n",
    "        elif isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "            try:\n",
    "                ingredients = ast.literal_eval(ingredients_input)\n",
    "            except:\n",
    "                ingredients = [\n",
    "                    x.strip().strip('\"').strip(\"'\")\n",
    "                    for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                    if x.strip()\n",
    "                ]\n",
    "        else:\n",
    "            return non_vegetarian_items\n",
    "\n",
    "        for ingredient in ingredients:\n",
    "            if not isinstance(ingredient, str):\n",
    "                continue\n",
    "\n",
    "            ing = ingredient.lower()\n",
    "\n",
    "            if any(skip in ing for skip in ['water', 'salt']):\n",
    "                continue\n",
    "\n",
    "            for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "                pat = rf'\\b{re.escape(keyword)}(?:s)?\\b'\n",
    "                if re.search(pat, ing):\n",
    "                    if not contains_vegetarian_exception(ing, keyword):\n",
    "                        non_vegetarian_items.append(ingredient)\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Errore ricerca ingredienti non vegetariani: {e}\")\n",
    "\n",
    "    return non_vegetarian_items\n",
    "\n",
    "# Applica al DataFrame\n",
    "df['VEGETARIAN'] = df['NER_clean'].apply(is_vegetarian_recipe)\n",
    "df['NON_VEGETARIAN_INGREDIENTS'] = df['NER_clean'].apply(find_non_vegetarian_ingredients)\n",
    "\n",
    "# Mostra risultati\n",
    "df[['TITLE', 'NER', 'VEGETARIAN', 'NON_VEGETARIAN_INGREDIENTS']].head(200)\n"
   ],
   "id": "aea747ecfbc718a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     TITLE                                                NER  \\\n",
       "0      No-Bake Nut Cookies  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...   \n",
       "1    Jewell Ball'S Chicken  [\"beef\", \"chicken breasts\", \"cream of mushroom...   \n",
       "2              Creamy Corn  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...   \n",
       "3            Chicken Funny  [\"chicken\", \"chicken gravy\", \"cream of mushroo...   \n",
       "4     Reeses Cups(Candy)    [\"peanut butter\", \"graham cracker crumbs\", \"bu...   \n",
       "..                     ...                                                ...   \n",
       "195             Golf Balls  [\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...   \n",
       "196      Crispy Herb Bread  [\"olive oil\", \"garlic powder\", \"bread\", \"thyme...   \n",
       "197    Festive Fruit Salad  [\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...   \n",
       "198   Fresh Strawberry Pie  [\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...   \n",
       "199            Egg Custard  [\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...   \n",
       "\n",
       "     VEGETARIAN NON_VEGETARIAN_INGREDIENTS  \n",
       "0          True                         []  \n",
       "1         False    [beef, chicken breasts]  \n",
       "2          True                         []  \n",
       "3         False   [chicken, chicken gravy]  \n",
       "4          True                         []  \n",
       "..          ...                        ...  \n",
       "195        True                         []  \n",
       "196        True                         []  \n",
       "197        True                         []  \n",
       "198        True                         []  \n",
       "199        True                         []  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NER</th>\n",
       "      <th>VEGETARIAN</th>\n",
       "      <th>NON_VEGETARIAN_INGREDIENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n",
       "      <td>False</td>\n",
       "      <td>[beef, chicken breasts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n",
       "      <td>False</td>\n",
       "      <td>[chicken, chicken gravy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Golf Balls</td>\n",
       "      <td>[\"cocoa\", \"butter\", \"powdered sugar\", \"milk\", ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Crispy Herb Bread</td>\n",
       "      <td>[\"olive oil\", \"garlic powder\", \"bread\", \"thyme...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Festive Fruit Salad</td>\n",
       "      <td>[\"pineapple\", \"mandarin oranges\", \"grapes\", \"m...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Fresh Strawberry Pie</td>\n",
       "      <td>[\"strawberries\", \"water\", \"salt\", \"sugar\", \"co...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Egg Custard</td>\n",
       "      <td>[\"sugar\", \"eggs\", \"milk\", \"cornstarch\", \"vanil...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# ---------- 1. Category Rules ----------\n",
    "CATEGORY_RULES = {\n",
    "    \"Meat\": [\"bacon\", \"beef\", \"chicken\", \"ham\", \"turkey\", \"liver\", \"hamburger\", \"pancetta\", \"prosciutto\"],\n",
    "    \"Seafood\": [\"shrimp\", \"tuna\", \"anchovy\", \"salmon\"],\n",
    "    \"Vegetable\": [\"onion\", \"garlic\", \"lettuce\", \"carrot\", \"pepper\", \"tomato\", \"potato\", \"celery\", \"scallion\", \"bean sprouts\"],\n",
    "    \"Fruit\": [\"lemon\", \"banana\", \"orange\", \"raisins\", \"apple\", \"avocado\"],\n",
    "    \"Grain\": [\"flour\", \"cornmeal\", \"tortilla\", \"rice\", \"bread\", \"wafer\", \"cake\", \"noodles\", \"linguine\", \"rolls\"],\n",
    "    \"Dairy\": [\"milk\", \"cheese\", \"butter\", \"sour cream\", \"cream cheese\", \"parmesan\", \"whiz\", \"pecorino\"],\n",
    "    \"Fat/Oil\": [\"olive oil\", \"vegetable oil\", \"sunflower oil\", \"margarine\", \"sesame oil\"],\n",
    "    \"Spice\": [\"salt\", \"pepper\", \"cinnamon\", \"nutmeg\", \"ginger\", \"paprika\", \"oregano\", \"thyme\", \"sage\", \"cayenne\"],\n",
    "    \"Sweetener\": [\"sugar\", \"molasses\", \"honey\", \"chocolate\", \"syrup\"],\n",
    "    \"Other\": []\n",
    "}\n",
    "\n",
    "# ---------- 2. Ingredient Classification from DataFrame ----------\n",
    "def extract_ingredients_and_categories(df, column=\"NER\"):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            items = ast.literal_eval(row[column])\n",
    "        except Exception:\n",
    "            continue  # skip malformed rows\n",
    "        for item in items:\n",
    "            item_lower = item.lower()\n",
    "            matched = False\n",
    "            for category, keywords in CATEGORY_RULES.items():\n",
    "                if any(k in item_lower for k in keywords):\n",
    "                    data.append({\"ingredient\": item.strip(), \"category\": category})\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                data.append({\"ingredient\": item.strip(), \"category\": \"Other\"})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ---------- 3. Load and process your CSV ----------\n",
    "df = pd.read_csv(\"dataset_1.csv\")  # your original dataset\n",
    "ingredient_df = extract_ingredients_and_categories(df)  # expanded dataset\n",
    "\n",
    "# ---------- 4. Label encoding ----------\n",
    "label_encoder = LabelEncoder()\n",
    "ingredient_df[\"category\"] = ingredient_df[\"category\"].astype(str)\n",
    "label_encoder.fit(ingredient_df[\"category\"])\n",
    "ingredient_df[\"label\"] = label_encoder.transform(ingredient_df[\"category\"])\n",
    "\n",
    "# Debug info\n",
    "print(f\"Number of categories: {len(label_encoder.classes_)}\")\n",
    "print(f\"Label range: {ingredient_df['label'].min()} - {ingredient_df['label'].max()}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "print(f\"Labels: {sorted(ingredient_df['label'].unique())}\")\n",
    "\n",
    "# ---------- 5. Prepare HuggingFace dataset ----------\n",
    "dataset = Dataset.from_pandas(ingredient_df[[\"ingredient\", \"label\"]])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"ingredient\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# ---------- 6. Load model ----------\n",
    "# FIX: Explicitly set num_labels parameter to match the actual number of classes\n",
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels-1\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Add an output directory\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ---------- 7. Save final model and labels ----------\n",
    "model_path = \"ingredient_classifier_model\"\n",
    "label_mapping_path = \"category_labels.txt\"\n",
    "\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "with open(label_mapping_path, \"w\") as f:\n",
    "    for i, c in enumerate(label_encoder.classes_):\n",
    "        f.write(f\"{i},{c}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T17:50:58.022080Z",
     "start_time": "2025-05-17T17:50:57.325959Z"
    }
   },
   "id": "9f2639d0b8b5276a",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpreprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LabelEncoder\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'datasets'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground beef          ➜ Vegetable\n",
      "sugar                ➜ Vegetable\n",
      "cheddar cheese       ➜ Vegetable\n",
      "fresh basil          ➜ Vegetable\n",
      "shrimp               ➜ Vegetable\n",
      "coconut milk         ➜ Vegetable\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_path = \"ingredient_classifier_model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load label mapping\n",
    "label_map = {}\n",
    "with open(\"category_labels.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        idx, label = line.strip().split(\",\", 1)\n",
    "        label_map[int(idx)] = label\n",
    "\n",
    "# Function to classify one ingredient\n",
    "def classify_ingredient(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return label_map[prediction]\n",
    "\n",
    "# Example usage\n",
    "ingredients = [\n",
    "    \"ground beef\",\n",
    "    \"sugar\",\n",
    "    \"cheddar cheese\",\n",
    "    \"fresh basil\",\n",
    "    \"shrimp\",\n",
    "    \"coconut milk\"\n",
    "]\n",
    "\n",
    "for ing in ingredients:\n",
    "    category = classify_ingredient(ing)\n",
    "    print(f\"{ing:20} ➜ {category}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T17:50:58.077637800Z",
     "start_time": "2025-05-16T22:15:26.853172500Z"
    }
   },
   "id": "50dfb9223c408200"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 87\u001B[39m\n\u001B[32m     83\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28msum\u001B[39m(MEDIAN_PRICES.get(categorize_ingredient(ing), \u001B[32m3.00\u001B[39m)\n\u001B[32m     84\u001B[39m                      \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m valid_ingredients), \u001B[32m2\u001B[39m)\n\u001B[32m     86\u001B[39m \u001B[38;5;66;03m# Process recipes\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mtotal_cost\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mNER\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_recipe_cost\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[38;5;66;03m# Dynamic price categorization\u001B[39;00m\n\u001B[32m     90\u001B[39m costs = df[\u001B[33m'\u001B[39m\u001B[33mtotal_cost\u001B[39m\u001B[33m'\u001B[39m].values\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4922\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4923\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1508\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1509\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36mcalculate_recipe_cost\u001B[39m\u001B[34m(ingredients)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Cost calculation with validation\"\"\"\u001B[39;00m\n\u001B[32m     82\u001B[39m valid_ingredients = [ing \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m ingredients \u001B[38;5;28;01mif\u001B[39;00m ing.strip()]\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mMEDIAN_PRICES\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcategorize_ingredient\u001B[49m\u001B[43m(\u001B[49m\u001B[43ming\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m3.00\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m                 \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ming\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalid_ingredients\u001B[49m\u001B[43m)\u001B[49m, \u001B[32m2\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Cost calculation with validation\"\"\"\u001B[39;00m\n\u001B[32m     82\u001B[39m valid_ingredients = [ing \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m ingredients \u001B[38;5;28;01mif\u001B[39;00m ing.strip()]\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28msum\u001B[39m(MEDIAN_PRICES.get(\u001B[43mcategorize_ingredient\u001B[49m\u001B[43m(\u001B[49m\u001B[43ming\u001B[49m\u001B[43m)\u001B[49m, \u001B[32m3.00\u001B[39m)\n\u001B[32m     84\u001B[39m                  \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m valid_ingredients), \u001B[32m2\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 72\u001B[39m, in \u001B[36mcategorize_ingredient\u001B[39m\u001B[34m(ingredient)\u001B[39m\n\u001B[32m     69\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m classification_cache[cleaned]\n\u001B[32m     71\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m     result = \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcleaned\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCATEGORIES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_label\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     73\u001B[39m     category = result[\u001B[33m'\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m]\n\u001B[32m     74\u001B[39m     classification_cache[cleaned] = category\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:206\u001B[39m, in \u001B[36mZeroShotClassificationPipeline.__call__\u001B[39m\u001B[34m(self, sequences, *args, **kwargs)\u001B[39m\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnable to understand extra arguments \u001B[39m\u001B[38;5;132;01m{\u001B[39;00margs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1371\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1369\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[32m   1370\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ChunkPipeline):\n\u001B[32m-> \u001B[39m\u001B[32m1371\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m   1372\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   1373\u001B[39m             \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   1374\u001B[39m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001B[32m   1375\u001B[39m             )\n\u001B[32m   1376\u001B[39m         )\n\u001B[32m   1377\u001B[39m     )\n\u001B[32m   1378\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1379\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001B[39m, in \u001B[36mPipelineIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    121\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_item()\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m item = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.iterator)\n\u001B[32m    125\u001B[39m processed = \u001B[38;5;28mself\u001B[39m.infer(item, **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    126\u001B[39m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001B[39m, in \u001B[36mPipelinePackIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    266\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m accumulator\n\u001B[32m    268\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_last:\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m     processed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    270\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    271\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed, torch.Tensor):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1286\u001B[39m, in \u001B[36mPipeline.forward\u001B[39m\u001B[34m(self, model_inputs, **forward_params)\u001B[39m\n\u001B[32m   1284\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[32m   1285\u001B[39m         model_inputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_inputs, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m-> \u001B[39m\u001B[32m1286\u001B[39m         model_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1287\u001B[39m         model_outputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m   1288\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:229\u001B[39m, in \u001B[36mZeroShotClassificationPipeline._forward\u001B[39m\u001B[34m(self, inputs)\u001B[39m\n\u001B[32m    227\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect.signature(model_forward).parameters.keys():\n\u001B[32m    228\u001B[39m     model_inputs[\u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m229\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m model_outputs = {\n\u001B[32m    232\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcandidate_label\u001B[39m\u001B[33m\"\u001B[39m: candidate_label,\n\u001B[32m    233\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33msequence\u001B[39m\u001B[33m\"\u001B[39m: sequence,\n\u001B[32m    234\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mis_last\u001B[39m\u001B[33m\"\u001B[39m: inputs[\u001B[33m\"\u001B[39m\u001B[33mis_last\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    235\u001B[39m     **outputs,\n\u001B[32m    236\u001B[39m }\n\u001B[32m    237\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model_outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1775\u001B[39m, in \u001B[36mBartForSequenceClassification.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1770\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[32m   1772\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPassing input embeddings is currently not supported for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1773\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1776\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1777\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1778\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1779\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1780\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1781\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1782\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1783\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1784\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1785\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1786\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1787\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1788\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1790\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1791\u001B[39m hidden_states = outputs[\u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# last hidden state\u001B[39;00m\n\u001B[32m   1793\u001B[39m eos_mask = input_ids.eq(\u001B[38;5;28mself\u001B[39m.config.eos_token_id).to(hidden_states.device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1515\u001B[39m, in \u001B[36mBartModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1512\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m   1514\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m encoder_outputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1515\u001B[39m     encoder_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1516\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1517\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1518\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1519\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1520\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1521\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1523\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1524\u001B[39m \u001B[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001B[39;00m\n\u001B[32m   1525\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, BaseModelOutput):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1113\u001B[39m, in \u001B[36mBartEncoder.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1105\u001B[39m         layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m   1106\u001B[39m             encoder_layer.\u001B[34m__call__\u001B[39m,\n\u001B[32m   1107\u001B[39m             hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1110\u001B[39m             output_attentions,\n\u001B[32m   1111\u001B[39m         )\n\u001B[32m   1112\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1113\u001B[39m         layer_outputs = \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1115\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1116\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1117\u001B[39m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1118\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1120\u001B[39m     hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1122\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:566\u001B[39m, in \u001B[36mBartEncoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    554\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    555\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m    556\u001B[39m \u001B[33;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    563\u001B[39m \u001B[33;03m        returned tensors for more detail.\u001B[39;00m\n\u001B[32m    564\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    565\u001B[39m residual = hidden_states\n\u001B[32m--> \u001B[39m\u001B[32m566\u001B[39m hidden_states, attn_weights, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    568\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    569\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    570\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    571\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    572\u001B[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001B[38;5;28mself\u001B[39m.dropout, training=\u001B[38;5;28mself\u001B[39m.training)\n\u001B[32m    573\u001B[39m hidden_states = residual + hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:473\u001B[39m, in \u001B[36mBartSdpaAttention.forward\u001B[39m\u001B[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    470\u001B[39m     value_states = torch.cat([past_key_value[\u001B[32m1\u001B[39m], value_states], dim=\u001B[32m2\u001B[39m)\n\u001B[32m    471\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    472\u001B[39m     \u001B[38;5;66;03m# self_attention\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m     key_states = \u001B[38;5;28mself\u001B[39m._shape(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m, -\u001B[32m1\u001B[39m, bsz)\n\u001B[32m    474\u001B[39m     value_states = \u001B[38;5;28mself\u001B[39m._shape(\u001B[38;5;28mself\u001B[39m.v_proj(hidden_states), -\u001B[32m1\u001B[39m, bsz)\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_decoder:\n\u001B[32m    477\u001B[39m     \u001B[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001B[39;00m\n\u001B[32m    478\u001B[39m     \u001B[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    482\u001B[39m     \u001B[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001B[39;00m\n\u001B[32m    483\u001B[39m     \u001B[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "data = {'NER': [\n",
    "    [\"eggs\", \"milk\", \"sugar\", \"vanilla\", \"gallon water\", \"dinner rolls\", \"cinnamon roll\"],\n",
    "    [\"tuna\", \"mayonnaise\", \"low-fat sour cream\", \"bacon bits\", \"dill\", \"salt\"],\n",
    "    [\"olive oil\", \"onion\", \"garlic\", \"salt\", \"ground black pepper\", \"tomatoes\",\n",
    "     \"tomatoes\", \"ricotta cheese\", \"Parmesan cheese\", \"fresh basil\", \"egg\", \"salt\",\n",
    "     \"ground black pepper\", \"lasagna noodles\", \"mozzarella\", \"mushrooms\"],\n",
    "    [\"olive oil\", \"onion\", \"red bell pepper\", \"green bell pepper\", \"chili powder\",\n",
    "     \"oregano\", \"ground cumin\", \"garlic\", \"garbanzo beans\", \"black beans\", \"pinto beans\",\n",
    "     \"tomato sauce\", \"taco\", \"shredded iceberg lettuce\", \"tomato\", \"cheddar cheese\", \"salsa\"]\n",
    "]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Food categories and prices\n",
    "CATEGORIES = [\n",
    "    \"dairy\", \"meat\", \"seafood\", \"grain\", \"vegetable\",\n",
    "    \"fruit\", \"spice/herb\", \"processed\", \"sweetener\",\n",
    "    \"condiment\", \"legume\", \"oil/fat\"\n",
    "]\n",
    "\n",
    "MEDIAN_PRICES = {\n",
    "    \"dairy\": 3.00,       # Milk, cheese (per kg)\n",
    "    \"meat\": 8.00,        # Chicken, beef (per kg)\n",
    "    \"seafood\": 12.00,    # Fish, shrimp (per kg)\n",
    "    \"grain\": 2.00,       # Flour, rice (per kg)\n",
    "    \"vegetable\": 1.50,   # Onions, garlic (per kg)\n",
    "    \"fruit\": 2.00,       # Tomatoes, bananas (per kg)\n",
    "    \"spice/herb\": 15.00, # Vanilla, cinnamon (per kg)\n",
    "    \"processed\": 5.00,   # Pasta, canned goods (per kg)\n",
    "    \"sweetener\": 1.80,   # Sugar (per kg)\n",
    "    \"condiment\": 4.00,   # Mayo, dressings (per kg)\n",
    "    \"legume\": 2.50,      # Beans, lentils (per kg)\n",
    "    \"oil/fat\": 6.00      # Olive oil (per kg)\n",
    "}\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"valhalla/distilbart-mnli-12-3\",\n",
    "    device=0,  # Requires CUDA-enabled environment\n",
    "    torch_dtype=torch.float16  # Enable mixed precision\n",
    ")\n",
    "\n",
    "classification_cache = {}\n",
    "\n",
    "# Improved cleaning function\n",
    "def clean_ingredient(ingredient):\n",
    "    \"\"\"More conservative cleaning\"\"\"\n",
    "    # Remove quantities like \"1/2 cup\" or \"200g\"\n",
    "    cleaned = re.sub(r'\\b\\d+[\\d/\\.°]*\\s*(\\w+)?\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    # Remove special characters but keep spaces\n",
    "    cleaned = re.sub(r'[^\\w\\s]', '', cleaned).strip().lower()\n",
    "    return cleaned if cleaned else \"unknown_ingredient\"\n",
    "\n",
    "def categorize_ingredient(ingredient):\n",
    "    \"\"\"Safe classification with error handling\"\"\"\n",
    "    cleaned = clean_ingredient(ingredient)\n",
    "\n",
    "    if not cleaned or cleaned == \"unknown_ingredient\":\n",
    "        return \"processed\"  # Default category\n",
    "\n",
    "    if cleaned in classification_cache:\n",
    "        return classification_cache[cleaned]\n",
    "\n",
    "    try:\n",
    "        result = classifier(cleaned, CATEGORIES, multi_label=False)\n",
    "        category = result['labels'][0]\n",
    "        classification_cache[cleaned] = category\n",
    "        return category\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying '{cleaned}': {str(e)}\")\n",
    "        return \"processed\"\n",
    "\n",
    "def calculate_recipe_cost(ingredients):\n",
    "    \"\"\"Cost calculation with validation\"\"\"\n",
    "    valid_ingredients = [ing for ing in ingredients if ing.strip()]\n",
    "    return round(sum(MEDIAN_PRICES.get(categorize_ingredient(ing), 3.00)\n",
    "                     for ing in valid_ingredients), 2)\n",
    "\n",
    "# Process recipes\n",
    "df['total_cost'] = df['NER'].apply(calculate_recipe_cost)\n",
    "\n",
    "# Dynamic price categorization\n",
    "costs = df['total_cost'].values\n",
    "q33, q66 = np.percentile(costs, [33, 66]) if len(costs) > 0 else (0, 0)\n",
    "\n",
    "def price_category(cost):\n",
    "    if cost <= q33: return 'cheap'\n",
    "    elif cost <= q66: return 'medium'\n",
    "    return 'expensive'\n",
    "\n",
    "\n",
    "df['price_tag'] = df['total_cost'].apply(price_category)\n",
    "\n",
    "\n",
    "ingredient_df = pd.DataFrame.from_dict(classification_cache,\n",
    "                                       orient='index',\n",
    "                                       columns=['category']).reset_index()\n",
    "ingredient_df.columns = ['ingredient', 'category']\n",
    "\n",
    "# Add vegan/vegetarian tags\n",
    "VEGAN_UNSAFE = {'meat', 'seafood', 'dairy', 'egg'}\n",
    "VEGETARIAN_UNSAFE = {'meat', 'seafood'}\n",
    "\n",
    "# ingredient_df['vegan'] = ~ingredient_df['category'].isin(VEGAN_UNSAFE)\n",
    "# ingredient_df['vegetarian'] = ~ingredient_df['category'].isin(VEGETARIAN_UNSAFE)\n",
    "\n",
    "# Save comprehensive dataset\n",
    "ingredient_df.to_csv('ingredient_categories.csv', index=False)\n",
    "\n",
    "# Display sample\n",
    "print(\"Ingredient Categories with Dietary Tags:\")\n",
    "print(ingredient_df.sample(5))\n",
    "\n",
    "df[['NER', 'total_cost', 'price_tag']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T17:50:58.117474200Z",
     "start_time": "2025-05-17T00:11:24.788088Z"
    }
   },
   "id": "8c3fb8ce3efc3060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4190c03acb0a826"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
