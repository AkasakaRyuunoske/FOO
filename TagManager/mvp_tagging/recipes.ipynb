{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:53:30.244646Z",
     "start_time": "2025-05-22T13:53:29.311246Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File and create a new dataframe called 'df'\n",
    "# df = pd.read_csv('dataset_1.csv')\n",
    "df = pd.read_csv('full_tagged_dataset_2%.csv')\n",
    "\n",
    "# Removing useless columns\n",
    "# df = df.drop(columns = ['Unnamed: 0', 'link', 'source'])\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           TITLE  \\\n",
       "0                  Western Sizzlin Bread Pudding   \n",
       "1      Creamy Tuna And Bacon Salad (Reduced Fat)   \n",
       "2                  Spinach And Mushroom Lasagna    \n",
       "3                               Three-Bean Tacos   \n",
       "4                          Hearty Hamburger Soup   \n",
       "...                                          ...   \n",
       "44618             California Chili Powder Recipe   \n",
       "44619                           Pizza Margherita   \n",
       "44620   Frenchish Chicken And Red Wine Casserole   \n",
       "44621   Blueberry Almond Streusel Muffins Recipe   \n",
       "44622                            Sugar Cream Pie   \n",
       "\n",
       "                                                     NER difficulty     time  \\\n",
       "0      ['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...       Hard     Slow   \n",
       "1      ['tuna', 'mayonnaise', 'low-fat sour cream', '...       Hard  Average   \n",
       "2      ['olive oil', 'onion', 'garlic', 'salt', 'grou...       Hard    Quick   \n",
       "3      ['olive oil', 'onion', 'red bell pepper', 'gre...       Hard    Quick   \n",
       "4      ['lean ground beef', 'white onion', 'ground bl...       Hard    Quick   \n",
       "...                                                  ...        ...      ...   \n",
       "44618  ['Mexico chilies', 'grnd cumin', 'cayenne', 'o...       Easy  Average   \n",
       "44619  ['batch pizza', 'marinara sauce', 'mozzarella'...       Easy    Quick   \n",
       "44620  ['tomatoes', 'red wine', 'chicken stock', 'gar...       Hard     Slow   \n",
       "44621  ['flour', 'sugar', 'baking pwdr', 'baking soda...       Hard  Average   \n",
       "44622  ['Pastry', 'cornstarch', 'milk', 'butter', 'va...       Hard    Quick   \n",
       "\n",
       "            cost method                                        INGREDIENTS  \\\n",
       "0          Cheap   Bake  [\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...   \n",
       "1          Cheap  Other  [\"1 (6 ounce) can tuna, drained and flaked\", \"...   \n",
       "2          Cheap   Bake  [\"1 tablespoon olive oil\", \"1 medium onion , c...   \n",
       "3          Cheap   Boil  [\"1 teaspoon olive oil\", \"1 cup diced onion\", ...   \n",
       "4      Expensive   Boil  [\"900.0 gs lean ground beef\", \"1 white onion, ...   \n",
       "...          ...    ...                                                ...   \n",
       "44618      Cheap  Other  [\"0.25 c. grnd Calif or possibly New Mexico ch...   \n",
       "44619      Cheap   Bake  [\"1 batch pizza dough (see preceding recipe)\",...   \n",
       "44620      Cheap   Boil  [\"1 (14 ounce) can chopped tomatoes\", \"1.25 cu...   \n",
       "44621      Cheap   Bake  [\"2.5 c. all-purpose flour\", \"1 c. granulated ...   \n",
       "44622      Cheap   Bake  [\"Pastry for single-crust pie (22.5 cmes)\", \"1...   \n",
       "\n",
       "                                              DIRECTIONS  total_time  \\\n",
       "0      [\"Distribute rolls and cinnamon roll in (4) 2\\...       150.0   \n",
       "1      [\"Put everything in a bowl and mix together un...        15.0   \n",
       "2      [\"Heat oven to 375 degrees.\", \"\", \"In medium s...        70.0   \n",
       "3      [\"Heat oil in a large skillet over medium-high...        22.0   \n",
       "4      [\"Brown ground beef and onion in a large pot. ...        45.0   \n",
       "...                                                  ...         ...   \n",
       "44618  [\"In a 0.3333333333- to 0.5-c. tall, narrow cl...        30.0   \n",
       "44619  [\"Preheat oven to 450 degrees F. Place a pizza...        10.0   \n",
       "44620  [\"Place the tomatoes, wine, stock, garlic, ros...       100.0   \n",
       "44621  [\"Preheat oven to 400 .\", \"Combine first 5 ing...        18.0   \n",
       "44622  [\"Preheat oven to 232°C. Roll out dough to fit...        37.0   \n",
       "\n",
       "           PREPARATION_TIME  \\\n",
       "0      Very slow (90+ mins)   \n",
       "1         Fast (10-20 mins)   \n",
       "2         Slow (40-90 mins)   \n",
       "3       Medium (20-40 mins)   \n",
       "4         Slow (40-90 mins)   \n",
       "...                     ...   \n",
       "44618   Medium (20-40 mins)   \n",
       "44619     Fast (10-20 mins)   \n",
       "44620  Very slow (90+ mins)   \n",
       "44621     Fast (10-20 mins)   \n",
       "44622   Medium (20-40 mins)   \n",
       "\n",
       "                                               NER_clean  VEGAN  \\\n",
       "0      ['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...  False   \n",
       "1      ['tuna', 'mayonnaise', 'low-fat sour cream', '...  False   \n",
       "2      ['olive oil', 'onion', 'garlic', 'salt', 'grou...  False   \n",
       "3      ['olive oil', 'onion', 'red bell pepper', 'gre...  False   \n",
       "4      ['lean ground beef', 'white onion', 'ground bl...  False   \n",
       "...                                                  ...    ...   \n",
       "44618  ['Mexico chilies', 'grnd cumin', 'cayenne', 'o...   True   \n",
       "44619  ['batch pizza', 'marinara sauce', 'mozzarella'...   True   \n",
       "44620  ['tomatoes', 'red wine', 'chicken stock', 'gar...  False   \n",
       "44621  ['flour', 'sugar', 'baking pwdr', 'baking soda...  False   \n",
       "44622  ['Pastry', 'cornstarch', 'milk', 'butter', 'va...  False   \n",
       "\n",
       "                                   NON_VEGAN_INGREDIENTS  VEGETARIAN  \\\n",
       "0                                       ['eggs', 'milk']        True   \n",
       "1           ['tuna', 'low-fat sour cream', 'bacon bits']       False   \n",
       "2           ['ricotta cheese', 'Parmesan cheese', 'egg']        True   \n",
       "3                                     ['cheddar cheese']        True   \n",
       "4      ['lean ground beef', 'parmesan cheese', 'sour ...       False   \n",
       "...                                                  ...         ...   \n",
       "44618                                                 []        True   \n",
       "44619                                                 []        True   \n",
       "44620     ['chicken stock', 'chicken thighs', 'chicken']       False   \n",
       "44621  ['milk', 'low-fat buttermilk', 'light Ricotta ...        True   \n",
       "44622                                 ['milk', 'butter']        True   \n",
       "\n",
       "                           NON_VEGETARIAN_INGREDIENTS  total_cost   price_tag  \\\n",
       "0                                                  []        49.2      medium   \n",
       "1                              ['tuna', 'bacon bits']        52.5   expensive   \n",
       "2                                                  []        78.0        rich   \n",
       "3                                                  []        87.5        rich   \n",
       "4                                ['lean ground beef']        96.3        rich   \n",
       "...                                               ...         ...         ...   \n",
       "44618                                              []        78.8        rich   \n",
       "44619                                              []        18.0  very cheap   \n",
       "44620  ['chicken stock', 'chicken thighs', 'chicken']        60.3   expensive   \n",
       "44621                                              []        91.4        rich   \n",
       "44622                                              []        52.0   expensive   \n",
       "\n",
       "                                              categories  vegan  vegetarian  \n",
       "0      ['seafood', 'dairy', 'sweetener', 'spice/herb'...  False       False  \n",
       "1      ['seafood', 'condiment', None, 'meat', 'spice/...  False       False  \n",
       "2      ['condiment', 'vegetable', 'vegetable', 'condi...  False       False  \n",
       "3      ['condiment', 'vegetable', 'vegetable', 'veget...  False       False  \n",
       "4      ['meat', 'vegetable', 'condiment', 'spice/herb...  False       False  \n",
       "...                                                  ...    ...         ...  \n",
       "44618  [None, 'spice/herb', 'spice/herb', 'spice/herb...   True        True  \n",
       "44619          ['processed', 'condiment', 'dairy', None]  False        True  \n",
       "44620  ['vegetable', 'processed', 'processed', 'veget...  False       False  \n",
       "44621  ['processed', 'sweetener', 'processed', 'spice...  False        True  \n",
       "44622  [None, 'processed', 'dairy', 'dairy', 'spice/h...  False        True  \n",
       "\n",
       "[44623 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NER</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>time</th>\n",
       "      <th>cost</th>\n",
       "      <th>method</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>DIRECTIONS</th>\n",
       "      <th>total_time</th>\n",
       "      <th>PREPARATION_TIME</th>\n",
       "      <th>NER_clean</th>\n",
       "      <th>VEGAN</th>\n",
       "      <th>NON_VEGAN_INGREDIENTS</th>\n",
       "      <th>VEGETARIAN</th>\n",
       "      <th>NON_VEGETARIAN_INGREDIENTS</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>price_tag</th>\n",
       "      <th>categories</th>\n",
       "      <th>vegan</th>\n",
       "      <th>vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Western Sizzlin Bread Pudding</td>\n",
       "      <td>['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Slow</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Bake</td>\n",
       "      <td>[\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...</td>\n",
       "      <td>[\"Distribute rolls and cinnamon roll in (4) 2\\...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "      <td>['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...</td>\n",
       "      <td>False</td>\n",
       "      <td>['eggs', 'milk']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>49.2</td>\n",
       "      <td>medium</td>\n",
       "      <td>['seafood', 'dairy', 'sweetener', 'spice/herb'...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n",
       "      <td>['tuna', 'mayonnaise', 'low-fat sour cream', '...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Average</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Other</td>\n",
       "      <td>[\"1 (6 ounce) can tuna, drained and flaked\", \"...</td>\n",
       "      <td>[\"Put everything in a bowl and mix together un...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "      <td>['tuna', 'mayonnaise', 'low-fat sour cream', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>['tuna', 'low-fat sour cream', 'bacon bits']</td>\n",
       "      <td>False</td>\n",
       "      <td>['tuna', 'bacon bits']</td>\n",
       "      <td>52.5</td>\n",
       "      <td>expensive</td>\n",
       "      <td>['seafood', 'condiment', None, 'meat', 'spice/...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach And Mushroom Lasagna</td>\n",
       "      <td>['olive oil', 'onion', 'garlic', 'salt', 'grou...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Quick</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Bake</td>\n",
       "      <td>[\"1 tablespoon olive oil\", \"1 medium onion , c...</td>\n",
       "      <td>[\"Heat oven to 375 degrees.\", \"\", \"In medium s...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Slow (40-90 mins)</td>\n",
       "      <td>['olive oil', 'onion', 'garlic', 'salt', 'grou...</td>\n",
       "      <td>False</td>\n",
       "      <td>['ricotta cheese', 'Parmesan cheese', 'egg']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>78.0</td>\n",
       "      <td>rich</td>\n",
       "      <td>['condiment', 'vegetable', 'vegetable', 'condi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three-Bean Tacos</td>\n",
       "      <td>['olive oil', 'onion', 'red bell pepper', 'gre...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Quick</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Boil</td>\n",
       "      <td>[\"1 teaspoon olive oil\", \"1 cup diced onion\", ...</td>\n",
       "      <td>[\"Heat oil in a large skillet over medium-high...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "      <td>['olive oil', 'onion', 'red bell pepper', 'gre...</td>\n",
       "      <td>False</td>\n",
       "      <td>['cheddar cheese']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>87.5</td>\n",
       "      <td>rich</td>\n",
       "      <td>['condiment', 'vegetable', 'vegetable', 'veget...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearty Hamburger Soup</td>\n",
       "      <td>['lean ground beef', 'white onion', 'ground bl...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Quick</td>\n",
       "      <td>Expensive</td>\n",
       "      <td>Boil</td>\n",
       "      <td>[\"900.0 gs lean ground beef\", \"1 white onion, ...</td>\n",
       "      <td>[\"Brown ground beef and onion in a large pot. ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Slow (40-90 mins)</td>\n",
       "      <td>['lean ground beef', 'white onion', 'ground bl...</td>\n",
       "      <td>False</td>\n",
       "      <td>['lean ground beef', 'parmesan cheese', 'sour ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['lean ground beef']</td>\n",
       "      <td>96.3</td>\n",
       "      <td>rich</td>\n",
       "      <td>['meat', 'vegetable', 'condiment', 'spice/herb...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44618</th>\n",
       "      <td>California Chili Powder Recipe</td>\n",
       "      <td>['Mexico chilies', 'grnd cumin', 'cayenne', 'o...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Average</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Other</td>\n",
       "      <td>[\"0.25 c. grnd Calif or possibly New Mexico ch...</td>\n",
       "      <td>[\"In a 0.3333333333- to 0.5-c. tall, narrow cl...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "      <td>['Mexico chilies', 'grnd cumin', 'cayenne', 'o...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>78.8</td>\n",
       "      <td>rich</td>\n",
       "      <td>[None, 'spice/herb', 'spice/herb', 'spice/herb...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44619</th>\n",
       "      <td>Pizza Margherita</td>\n",
       "      <td>['batch pizza', 'marinara sauce', 'mozzarella'...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Quick</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Bake</td>\n",
       "      <td>[\"1 batch pizza dough (see preceding recipe)\",...</td>\n",
       "      <td>[\"Preheat oven to 450 degrees F. Place a pizza...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "      <td>['batch pizza', 'marinara sauce', 'mozzarella'...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>18.0</td>\n",
       "      <td>very cheap</td>\n",
       "      <td>['processed', 'condiment', 'dairy', None]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44620</th>\n",
       "      <td>Frenchish Chicken And Red Wine Casserole</td>\n",
       "      <td>['tomatoes', 'red wine', 'chicken stock', 'gar...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Slow</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Boil</td>\n",
       "      <td>[\"1 (14 ounce) can chopped tomatoes\", \"1.25 cu...</td>\n",
       "      <td>[\"Place the tomatoes, wine, stock, garlic, ros...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "      <td>['tomatoes', 'red wine', 'chicken stock', 'gar...</td>\n",
       "      <td>False</td>\n",
       "      <td>['chicken stock', 'chicken thighs', 'chicken']</td>\n",
       "      <td>False</td>\n",
       "      <td>['chicken stock', 'chicken thighs', 'chicken']</td>\n",
       "      <td>60.3</td>\n",
       "      <td>expensive</td>\n",
       "      <td>['vegetable', 'processed', 'processed', 'veget...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44621</th>\n",
       "      <td>Blueberry Almond Streusel Muffins Recipe</td>\n",
       "      <td>['flour', 'sugar', 'baking pwdr', 'baking soda...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Average</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Bake</td>\n",
       "      <td>[\"2.5 c. all-purpose flour\", \"1 c. granulated ...</td>\n",
       "      <td>[\"Preheat oven to 400 .\", \"Combine first 5 ing...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "      <td>['flour', 'sugar', 'baking pwdr', 'baking soda...</td>\n",
       "      <td>False</td>\n",
       "      <td>['milk', 'low-fat buttermilk', 'light Ricotta ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>91.4</td>\n",
       "      <td>rich</td>\n",
       "      <td>['processed', 'sweetener', 'processed', 'spice...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44622</th>\n",
       "      <td>Sugar Cream Pie</td>\n",
       "      <td>['Pastry', 'cornstarch', 'milk', 'butter', 'va...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Quick</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>Bake</td>\n",
       "      <td>[\"Pastry for single-crust pie (22.5 cmes)\", \"1...</td>\n",
       "      <td>[\"Preheat oven to 232°C. Roll out dough to fit...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "      <td>['Pastry', 'cornstarch', 'milk', 'butter', 'va...</td>\n",
       "      <td>False</td>\n",
       "      <td>['milk', 'butter']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>52.0</td>\n",
       "      <td>expensive</td>\n",
       "      <td>[None, 'processed', 'dairy', 'dairy', 'spice/h...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44623 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:55:19.512196Z",
     "start_time": "2025-05-22T13:55:19.506324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_fractions(text):\n",
    "    \"\"\"Defining a method that convert fractions\"\"\"\n",
    "    # Match optional whole number + fraction, or just fraction\n",
    "    pattern = r'(?:(\\d+)\\s+)?(\\d+)/(\\d+)'\n",
    "\n",
    "    def replacer(match):\n",
    "        whole = int(match.group(1)) if match.group(1) else 0\n",
    "        numerator = int(match.group(2))\n",
    "        denominator = int(match.group(3))\n",
    "        decimal = whole + Fraction(numerator, denominator)\n",
    "        return \"{:.10g}\".format(float(decimal))  # Clean, no trailing zeros\n",
    "\n",
    "    return re.sub(pattern, replacer, text)"
   ],
   "id": "f6177b908ebf022c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:55:21.431629Z",
     "start_time": "2025-05-22T13:55:21.257311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "from fractions import Fraction\n",
    "\n",
    "# Fixed conversions\n",
    "CONVERSIONS = {\n",
    "    \"oz\": 30,      # ounce → gram\n",
    "    \"lb\": 450,      # pounds → gram\n",
    "    \"pt\": 475,      # pint → milliliter\n",
    "    \"qt\": 950,      # quart → milliliter\n",
    "    \"inch\": 2.5        # inches → centimeter\n",
    "}\n",
    "\n",
    "def convert_units(text):\n",
    "    \"\"\"Defining a method that converts units by using the fixed conversions\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # Convert oz, lb, pt, qt (form: \"4 oz\", \"2.5 lb\", etc.)\n",
    "    for unit, factor in CONVERSIONS.items():\n",
    "        pattern = r'(\\d+(\\.\\d+)?)\\s*' + unit\n",
    "        text = re.sub(pattern, lambda m: f\"{round(float(m.group(1)) * factor, 1)} {unit_to_metric(unit)}\", text)\n",
    "\n",
    "    # Convert measure in inches in pans\n",
    "    text = re.sub(r'(\\d+)\\s*x\\s*(\\d+)[-\\s]*inch', lambda\n",
    "        m: f\"{int(m.group(1)) * CONVERSIONS['inch']:.0f} x {int(m.group(2)) * CONVERSIONS['inch']:.0f} cm\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_fahrenheit_to_celsius(text):\n",
    "    # Match degrees like 275°, 275 °F, 275\\u00b0F (escaped), etc.\n",
    "    pattern = r'(\\d+)\\s*(?:°|\\\\u00b0)'\n",
    "\n",
    "    def replacer(match):\n",
    "        fahrenheit = int(match.group(1))\n",
    "        celsius = round((fahrenheit - 32) * 5 / 9)\n",
    "        return f\"{celsius}°C\"\n",
    "\n",
    "    return re.sub(pattern, replacer, text)\n",
    "\n",
    "def unit_to_metric(unit):\n",
    "    return {\n",
    "        \"oz\": \"g\",\n",
    "        \"lb\": \"g\",\n",
    "        \"pt\": \"ml\",\n",
    "        \"qt\": \"ml\",\n",
    "        \"inch\": \"cm\"\n",
    "    }[unit]\n",
    "\n",
    "# Applying conversions on the INGREDIENTS and DIRECTIONS columns\n",
    "df['INGREDIENTS'] = df['ingredients'].apply(convert_fractions)\n",
    "df['DIRECTIONS'] = df['directions'].apply(convert_fractions)\n",
    "\n",
    "df['INGREDIENTS'] = df['INGREDIENTS'].apply(convert_units)\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_units)\n",
    "\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_fahrenheit_to_celsius)\n",
    "\n",
    "# Renaming the title column and dropping the converted columns\n",
    "df = df.rename(columns={\"title\": \"TITLE\"})\n",
    "df = df.drop(['ingredients', 'directions'], axis=1)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS']].head(200)\n",
    "'''"
   ],
   "id": "35a1e5c191694098",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ingredients'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'ingredients'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 49\u001B[39m\n\u001B[32m     40\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     41\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33moz\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mg\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     42\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlb\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mg\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     45\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33minch\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mcm\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     46\u001B[39m     }[unit]\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# Applying conversions on the INGREDIENTS and DIRECTIONS columns\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mINGREDIENTS\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mingredients\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m.apply(convert_fractions)\n\u001B[32m     50\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mDIRECTIONS\u001B[39m\u001B[33m'\u001B[39m] = df[\u001B[33m'\u001B[39m\u001B[33mdirections\u001B[39m\u001B[33m'\u001B[39m].apply(convert_fractions)\n\u001B[32m     52\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mINGREDIENTS\u001B[39m\u001B[33m'\u001B[39m] = df[\u001B[33m'\u001B[39m\u001B[33mINGREDIENTS\u001B[39m\u001B[33m'\u001B[39m].apply(convert_units)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'ingredients'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:57:15.720683Z",
     "start_time": "2025-05-22T13:57:13.232731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# Patterns to detect time expressions\n",
    "TIME_PATTERN = re.compile(\n",
    "    r'(\\d+(?:\\.\\d+)?)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h|day|days|d)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "RANGE_PATTERN = re.compile(\n",
    "    r'(\\d+)\\s*-\\s*(\\d+)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Time estimates for common preparation methods\n",
    "PREP_ESTIMATES = {\n",
    "    'bake': 45, 'boil': 20, 'fry': 15, 'grill': 25, 'chill': 120,\n",
    "    'simmer': 30, 'marinate': 60, 'microwave': 10, 'no-bake': 20,\n",
    "    'refrigerate': 180, 'freeze': 240\n",
    "}\n",
    "\n",
    "# Special cases for recipe types\n",
    "RECIPE_TYPE_ESTIMATES = {\n",
    "    'pasta': 10, 'salad': 15, 'cake': 45, 'pie': 60, 'stew': 120,\n",
    "    'casserole': 60, 'soup': 30, 'cookies': 30, 'bread': 90,\n",
    "    'fudge': 20, 'candy': 30\n",
    "}\n",
    "\n",
    "def convert_to_minutes(qty, unit):\n",
    "    \"\"\"Converts time quantity to minutes.\"\"\"\n",
    "    qty = float(qty)\n",
    "    unit = unit.lower()\n",
    "    if unit.startswith('m'): return qty\n",
    "    if unit.startswith('h'): return qty * 60\n",
    "    if unit.startswith('d'): return qty * 1440\n",
    "    return 0\n",
    "\n",
    "def estimate_by_recipe_type(title, ingredients):\n",
    "    \"\"\"Fallback estimation based on recipe title or ingredients.\"\"\"\n",
    "    title = str(title).lower()\n",
    "    ingredients = str(ingredients).lower()\n",
    "\n",
    "    # Check for specific recipe types\n",
    "    for keyword, est in RECIPE_TYPE_ESTIMATES.items():\n",
    "        if keyword in title:\n",
    "            return est\n",
    "\n",
    "    if any(word in ingredients for word in ['raw', 'fresh']):\n",
    "        return 15\n",
    "    if 'frozen' in ingredients:\n",
    "        return 20\n",
    "    if 'canned' in ingredients:\n",
    "        return 10\n",
    "\n",
    "    # Default fallback\n",
    "    return 30\n",
    "\n",
    "def clean_instruction_step(step):\n",
    "    \"\"\"Normalize range formats and identify special cases.\"\"\"\n",
    "    # Replace ranges (e.g., \"10-15 minutes\" → \"15 minutes\")\n",
    "    step = RANGE_PATTERN.sub(lambda m: f\"{m.group(2)} {m.group(3)}\", step)\n",
    "\n",
    "    # Handle special keywords\n",
    "    lowered = step.lower()\n",
    "    if 'overnight' in lowered:\n",
    "        return 480\n",
    "    if 'until set' in lowered or 'until firm' in lowered:\n",
    "        return 60\n",
    "\n",
    "    # Sum all time expressions\n",
    "    return sum(\n",
    "        convert_to_minutes(qty, unit)\n",
    "        for qty, unit in TIME_PATTERN.findall(step)\n",
    "    )\n",
    "\n",
    "def parse_instructions(instructions):\n",
    "    \"\"\"Parses instructions and extracts total estimated time in minutes.\"\"\"\n",
    "    total_time = 0\n",
    "\n",
    "    if not isinstance(instructions, list):\n",
    "        try:\n",
    "            instructions = ast.literal_eval(str(instructions))\n",
    "        except:\n",
    "            instructions = [instructions]\n",
    "\n",
    "    for step in instructions:\n",
    "        if isinstance(step, str):\n",
    "            total_time += clean_instruction_step(step)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "def categorize_time(total_time):\n",
    "    \"\"\"Classify total time into labeled categories.\"\"\"\n",
    "    if total_time == 0:\n",
    "        return 'Not specified'\n",
    "    if total_time < 10:\n",
    "        return 'Very fast (0-10 mins)'\n",
    "    if total_time < 20:\n",
    "        return 'Fast (10-20 mins)'\n",
    "    if total_time < 40:\n",
    "        return 'Medium (20-40 mins)'\n",
    "    if total_time < 90:\n",
    "        return 'Slow (40-90 mins)'\n",
    "    return 'Very slow (90+ mins)'\n",
    "\n",
    "# Calculate total preparation time\n",
    "df['total_time'] = df['DIRECTIONS'].apply(parse_instructions)\n",
    "\n",
    "# Estimate time for unspecified recipes\n",
    "missing = df['total_time'] == 0\n",
    "df.loc[missing, 'total_time'] = df[missing].apply(\n",
    "    lambda row: estimate_by_recipe_type(row['TITLE'], row['INGREDIENTS']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Categorize preparation times\n",
    "df['PREPARATION_TIME'] = df['total_time'].apply(categorize_time)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS', 'PREPARATION_TIME']].head(200)"
   ],
   "id": "4ca47d472c93a067",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 TITLE  \\\n",
       "0                        Western Sizzlin Bread Pudding   \n",
       "1            Creamy Tuna And Bacon Salad (Reduced Fat)   \n",
       "2                        Spinach And Mushroom Lasagna    \n",
       "3                                     Three-Bean Tacos   \n",
       "4                                Hearty Hamburger Soup   \n",
       "..                                                 ...   \n",
       "195                Sweet Potato Brotchen (Bread Rolls)   \n",
       "196  Green Cleaner and Bug Repellant in One (Concen...   \n",
       "197                                 Chocolate Chip Pie   \n",
       "198                                Poppy Seed Dressing   \n",
       "199                                    Scallop Ceviche   \n",
       "\n",
       "                                           INGREDIENTS  \\\n",
       "0    [\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...   \n",
       "1    [\"1 (6 ounce) can tuna, drained and flaked\", \"...   \n",
       "2    [\"1 tablespoon olive oil\", \"1 medium onion , c...   \n",
       "3    [\"1 teaspoon olive oil\", \"1 cup diced onion\", ...   \n",
       "4    [\"900.0 gs lean ground beef\", \"1 white onion, ...   \n",
       "..                                                 ...   \n",
       "195  [\"450 g sweet potatoes\", \"15 g butter or olive...   \n",
       "196  [\"1 tablespoon essential oil (part)\", \"3 table...   \n",
       "197  [\"1 graham cracker crust\", \"20 large marshmall...   \n",
       "198  [\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...   \n",
       "199  [\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...   \n",
       "\n",
       "                                            DIRECTIONS       PREPARATION_TIME  \n",
       "0    [\"Distribute rolls and cinnamon roll in (4) 2\\...   Very slow (90+ mins)  \n",
       "1    [\"Put everything in a bowl and mix together un...      Fast (10-20 mins)  \n",
       "2    [\"Heat oven to 375 degrees.\", \"\", \"In medium s...      Slow (40-90 mins)  \n",
       "3    [\"Heat oil in a large skillet over medium-high...    Medium (20-40 mins)  \n",
       "4    [\"Brown ground beef and onion in a large pot. ...      Slow (40-90 mins)  \n",
       "..                                                 ...                    ...  \n",
       "195  [\"Peel and cut sweet potatoes into chunks.\", \"...   Very slow (90+ mins)  \n",
       "196  [\"Mix all ingredients.\", \"Store in a glass jar...    Medium (20-40 mins)  \n",
       "197  [\"Make crust (I buy the prepared ones from the...      Slow (40-90 mins)  \n",
       "198  [\"Combine first 6 ingredients in a blender con...  Very fast (0-10 mins)  \n",
       "199  [\"Bring a pot of water to a boil, salt the wat...      Fast (10-20 mins)  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>INGREDIENTS</th>\n",
       "      <th>DIRECTIONS</th>\n",
       "      <th>PREPARATION_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Western Sizzlin Bread Pudding</td>\n",
       "      <td>[\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...</td>\n",
       "      <td>[\"Distribute rolls and cinnamon roll in (4) 2\\...</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n",
       "      <td>[\"1 (6 ounce) can tuna, drained and flaked\", \"...</td>\n",
       "      <td>[\"Put everything in a bowl and mix together un...</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach And Mushroom Lasagna</td>\n",
       "      <td>[\"1 tablespoon olive oil\", \"1 medium onion , c...</td>\n",
       "      <td>[\"Heat oven to 375 degrees.\", \"\", \"In medium s...</td>\n",
       "      <td>Slow (40-90 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three-Bean Tacos</td>\n",
       "      <td>[\"1 teaspoon olive oil\", \"1 cup diced onion\", ...</td>\n",
       "      <td>[\"Heat oil in a large skillet over medium-high...</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearty Hamburger Soup</td>\n",
       "      <td>[\"900.0 gs lean ground beef\", \"1 white onion, ...</td>\n",
       "      <td>[\"Brown ground beef and onion in a large pot. ...</td>\n",
       "      <td>Slow (40-90 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Sweet Potato Brotchen (Bread Rolls)</td>\n",
       "      <td>[\"450 g sweet potatoes\", \"15 g butter or olive...</td>\n",
       "      <td>[\"Peel and cut sweet potatoes into chunks.\", \"...</td>\n",
       "      <td>Very slow (90+ mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Green Cleaner and Bug Repellant in One (Concen...</td>\n",
       "      <td>[\"1 tablespoon essential oil (part)\", \"3 table...</td>\n",
       "      <td>[\"Mix all ingredients.\", \"Store in a glass jar...</td>\n",
       "      <td>Medium (20-40 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Chocolate Chip Pie</td>\n",
       "      <td>[\"1 graham cracker crust\", \"20 large marshmall...</td>\n",
       "      <td>[\"Make crust (I buy the prepared ones from the...</td>\n",
       "      <td>Slow (40-90 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Poppy Seed Dressing</td>\n",
       "      <td>[\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...</td>\n",
       "      <td>[\"Combine first 6 ingredients in a blender con...</td>\n",
       "      <td>Very fast (0-10 mins)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Scallop Ceviche</td>\n",
       "      <td>[\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...</td>\n",
       "      <td>[\"Bring a pot of water to a boil, salt the wat...</td>\n",
       "      <td>Fast (10-20 mins)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "# Conversione unità → kg\n",
    "UNIT_CONVERSION = {\n",
    "    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\n",
    "    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\n",
    "    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\n",
    "    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\n",
    "    'can': 0.4, 'carton': 1.0,\n",
    "    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\n",
    "    'kg': 1.0, 'kilogram': 1.0,\n",
    "    'lb': 0.4536, 'pound': 0.4536,\n",
    "    'oz': 0.02835, 'ounce': 0.02835,\n",
    "    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\n",
    "}\n",
    "\n",
    "# 3. Parsing function (qty, unit, name, grams_in_paren)\n",
    "def parse_ingredient(ing_str):\n",
    "    # peso fra parentesi\n",
    "    m = re.search(r'\\(\\s*([0-9]+(?:\\.[0-9]+)?)\\s*g\\.?\\s*\\)', ing_str, re.IGNORECASE)\n",
    "    grams = float(m.group(1)) if m else None\n",
    "\n",
    "    # quantity e unit\n",
    "    patt = r'^\\s*([\\d\\/.\\s]+)?\\s*([a-zA-Z\\.]+)?'\n",
    "    m2 = re.match(patt, ing_str)\n",
    "    qty_raw = m2.group(1) if m2 else None\n",
    "    try:\n",
    "        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\n",
    "    except:\n",
    "        qty = 1.0\n",
    "    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\n",
    "\n",
    "    # name pulito\n",
    "    name = re.sub(r'\\(.*?\\)|optional', '', ing_str, flags=re.IGNORECASE)\n",
    "    # rimuovo quantità/unità\n",
    "    name = re.sub(r'^[\\d\\/.\\s]+\\s*[a-zA-Z\\.]*', '', name).strip().lower()\n",
    "    return qty, unit, name, grams\n",
    "\n",
    "# 4. Calcolo posizionale con fallback substring e token\n",
    "def calculate_recipe_cost_positional(ingredients_list, ner_list):\n",
    "    total = 0.0\n",
    "    missing = []\n",
    "\n",
    "    for ing_str, ner_item in zip(ingredients_list, ner_list):\n",
    "        key = ner_item.lower()\n",
    "        qty, unit, name, grams = parse_ingredient(ing_str)\n",
    "\n",
    "        # scorporo se passo i grams\n",
    "        if grams is not None:\n",
    "            kg = (grams / 1000) * qty\n",
    "        elif unit == '':  # a pezzo\n",
    "            # prendo prezzo direct key\n",
    "            price = price_dict.get(key)\n",
    "            # fallback substring/token\n",
    "            if price is None:\n",
    "                # substring match\n",
    "                for k, v in price_dict.items():\n",
    "                    if k in key or key in k:\n",
    "                        price = v\n",
    "                        break\n",
    "                # token match\n",
    "                if price is None:\n",
    "                    for token in key.split():\n",
    "                        if token in price_dict:\n",
    "                            price = price_dict[token]\n",
    "                            break\n",
    "            if price:\n",
    "                total += qty * price\n",
    "            else:\n",
    "                missing.append(key)\n",
    "            continue\n",
    "        else:\n",
    "            conv = UNIT_CONVERSION.get(unit, 0.0)\n",
    "            if conv == 0:\n",
    "                missing.append(key)\n",
    "                continue\n",
    "            kg = qty * conv\n",
    "\n",
    "        # prezzo per kg\n",
    "        price = price_dict.get(key)\n",
    "        if price is None:\n",
    "            for k, v in price_dict.items():\n",
    "                if k in key or key in k:\n",
    "                    price = v\n",
    "                    break\n",
    "        if price is None:\n",
    "            missing.append(key)\n",
    "            continue\n",
    "\n",
    "        total += kg * price\n",
    "\n",
    "    return round(total, 2), missing\n",
    "\n",
    "# 5. Applica al DataFrame\n",
    "    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "def compute_cost_row(row):\n",
    "     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\n",
    "     return cost\n",
    "\n",
    "df['total_cost'] = df.apply(compute_cost_row, axis=1)\n",
    "\n",
    "df['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\n",
    "\n",
    "# Mostra risultati\n",
    "df[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)'''"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "potrebbe essere eliminata"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:27.432732900Z",
     "start_time": "2025-05-21T20:36:27.421218500Z"
    }
   },
   "id": "99c5e6f021ec1a8f",
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# Conversione unità → kg\\nUNIT_CONVERSION = {\\n    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\\n    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\\n    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\\n    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\\n    'can': 0.4, 'carton': 1.0,\\n    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\\n    'kg': 1.0, 'kilogram': 1.0,\\n    'lb': 0.4536, 'pound': 0.4536,\\n    'oz': 0.02835, 'ounce': 0.02835,\\n    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\\n}\\n\\n# 3. Parsing function (qty, unit, name, grams_in_paren)\\ndef parse_ingredient(ing_str):\\n    # peso fra parentesi\\n    m = re.search(r'\\\\(\\\\s*([0-9]+(?:\\\\.[0-9]+)?)\\\\s*g\\\\.?\\\\s*\\\\)', ing_str, re.IGNORECASE)\\n    grams = float(m.group(1)) if m else None\\n\\n    # quantity e unit\\n    patt = r'^\\\\s*([\\\\d\\\\/.\\\\s]+)?\\\\s*([a-zA-Z\\\\.]+)?'\\n    m2 = re.match(patt, ing_str)\\n    qty_raw = m2.group(1) if m2 else None\\n    try:\\n        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\\n    except:\\n        qty = 1.0\\n    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\\n\\n    # name pulito\\n    name = re.sub(r'\\\\(.*?\\\\)|optional', '', ing_str, flags=re.IGNORECASE)\\n    # rimuovo quantità/unità\\n    name = re.sub(r'^[\\\\d\\\\/.\\\\s]+\\\\s*[a-zA-Z\\\\.]*', '', name).strip().lower()\\n    return qty, unit, name, grams\\n\\n# 4. Calcolo posizionale con fallback substring e token\\ndef calculate_recipe_cost_positional(ingredients_list, ner_list):\\n    total = 0.0\\n    missing = []\\n\\n    for ing_str, ner_item in zip(ingredients_list, ner_list):\\n        key = ner_item.lower()\\n        qty, unit, name, grams = parse_ingredient(ing_str)\\n\\n        # scorporo se passo i grams\\n        if grams is not None:\\n            kg = (grams / 1000) * qty\\n        elif unit == '':  # a pezzo\\n            # prendo prezzo direct key\\n            price = price_dict.get(key)\\n            # fallback substring/token\\n            if price is None:\\n                # substring match\\n                for k, v in price_dict.items():\\n                    if k in key or key in k:\\n                        price = v\\n                        break\\n                # token match\\n                if price is None:\\n                    for token in key.split():\\n                        if token in price_dict:\\n                            price = price_dict[token]\\n                            break\\n            if price:\\n                total += qty * price\\n            else:\\n                missing.append(key)\\n            continue\\n        else:\\n            conv = UNIT_CONVERSION.get(unit, 0.0)\\n            if conv == 0:\\n                missing.append(key)\\n                continue\\n            kg = qty * conv\\n\\n        # prezzo per kg\\n        price = price_dict.get(key)\\n        if price is None:\\n            for k, v in price_dict.items():\\n                if k in key or key in k:\\n                    price = v\\n                    break\\n        if price is None:\\n            missing.append(key)\\n            continue\\n\\n        total += kg * price\\n\\n    return round(total, 2), missing\\n\\n# 5. Applica al DataFrame\\n    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\\n    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\\n\\ndef compute_cost_row(row):\\n     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\\n     return cost\\n\\ndf['total_cost'] = df.apply(compute_cost_row, axis=1)\\n\\ndf['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\\n\\n# Mostra risultati\\ndf[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)\""
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "df['NER_clean'] = df['NER'].apply(ast.literal_eval)\n",
    "\n",
    "# List containing keywords\n",
    "NON_VEGAN_KEYWORDS = {\n",
    "    'milk', 'cheese', 'butter', 'cream', 'yogurt', 'gelatin', 'lard', 'honey',\n",
    "    'egg', 'eggs', 'fish', 'meat', 'chicken', 'beef', 'pork', 'gelatina',\n",
    "    'collagen', 'casein', 'whey', 'lactose', 'ghee', 'isinglass', 'carmine',\n",
    "    'shellac', 'albumen', 'pepsin', 'royal jelly', 'propolis', 'cocoa butter',\n",
    "    'bacon', 'sour cream', 'condensed milk', 'shredded cheese', 'cheddar',\n",
    "    'paraffin', 'marshmallows', 'buttermilk', 'ground beef', 'steak', 'tuna'\n",
    "}\n",
    "\n",
    "VEGAN_EXCEPTIONS = {\n",
    "    'milk': {'soy', 'almond', 'oat', 'rice', 'coconut', 'cashew', 'hazelnut'},\n",
    "    'cheese': {'vegan', 'nutritional yeast', 'cashew', 'tofu'},\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'butter': {'vegan', 'plant', 'peanut', 'almond', 'soy'},\n",
    "    'cream': {'coconut', 'soy', 'oat', 'vegan'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'}\n",
    "}\n",
    "\n",
    "VEGAN_MODIFIERS = {\n",
    "    'vegan', 'vegetable', 'plant-based', 'no milk', 'no eggs',\n",
    "    'dairy-free', 'without animal derivatives', 'cruelty-free', '100% vegetable'\n",
    "}\n",
    "\n",
    "# --- Utility\n",
    "def parse_ingredients(ingredients_input):\n",
    "    \"\"\"Always returning a parsed list of ingredients\"\"\"\n",
    "    if isinstance(ingredients_input, list):\n",
    "        return ingredients_input\n",
    "    if isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "        try:\n",
    "            return ast.literal_eval(ingredients_input)\n",
    "        except:\n",
    "            return [\n",
    "                x.strip().strip('\"').strip(\"'\")\n",
    "                for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                if x.strip()\n",
    "            ]\n",
    "    return []\n",
    "\n",
    "def contains_vegan_exception(ingredient, keyword):\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE)\n",
    "               for ex in VEGAN_EXCEPTIONS.get(keyword, set()))\n",
    "\n",
    "# --- Classification\n",
    "def classify_vegan(ingredients_input):\n",
    "    \"\"\"Returning True or False based on the ingredients\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        if any(re.search(rf'\\b{re.escape(mod)}\\b', ing_lower) for mod in VEGAN_MODIFIERS):\n",
    "            continue\n",
    "        for keyword in NON_VEGAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegan_exception(ing_lower, keyword):\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def get_non_vegan_ingredients(ingredients_input):\n",
    "    \"\"\"Returning list of ingredients without vegan exceptions\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    non_vegan = []\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        for keyword in NON_VEGAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegan_exception(ing_lower, keyword):\n",
    "                    non_vegan.append(ing)\n",
    "                break\n",
    "    return non_vegan\n",
    "\n",
    "# --- Apply\n",
    "df['VEGAN'] = df['NER_clean'].apply(classify_vegan)\n",
    "df['NON_VEGAN_INGREDIENTS'] = df['NER_clean'].apply(get_non_vegan_ingredients)\n",
    "\n",
    "# --- Final validation\n",
    "anti_patterns = re.compile(\n",
    "    r'\\b(not vegan|meat|steak|fish|cheese|egg|eggs|beef|chicken|pork|bacon|cream)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "df['VEGAN'] = df.apply(\n",
    "    lambda row: False if row['VEGAN'] and isinstance(row['TITLE'], str) and anti_patterns.search(row['TITLE']) else row['VEGAN'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# View results\n",
    "df[['TITLE', 'NER', 'VEGAN', 'NON_VEGAN_INGREDIENTS']].head(200)"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:58:11.797507Z",
     "start_time": "2025-05-22T13:57:43.961157Z"
    }
   },
   "id": "fd85d06e00f4b10c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 TITLE  \\\n",
       "0                        Western Sizzlin Bread Pudding   \n",
       "1            Creamy Tuna And Bacon Salad (Reduced Fat)   \n",
       "2                        Spinach And Mushroom Lasagna    \n",
       "3                                     Three-Bean Tacos   \n",
       "4                                Hearty Hamburger Soup   \n",
       "..                                                 ...   \n",
       "195                Sweet Potato Brotchen (Bread Rolls)   \n",
       "196  Green Cleaner and Bug Repellant in One (Concen...   \n",
       "197                                 Chocolate Chip Pie   \n",
       "198                                Poppy Seed Dressing   \n",
       "199                                    Scallop Ceviche   \n",
       "\n",
       "                                                   NER  VEGAN  \\\n",
       "0    ['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...  False   \n",
       "1    ['tuna', 'mayonnaise', 'low-fat sour cream', '...  False   \n",
       "2    ['olive oil', 'onion', 'garlic', 'salt', 'grou...  False   \n",
       "3    ['olive oil', 'onion', 'red bell pepper', 'gre...  False   \n",
       "4    ['lean ground beef', 'white onion', 'ground bl...  False   \n",
       "..                                                 ...    ...   \n",
       "195  ['sweet potatoes', 'butter', 'salt', 'flour', ...  False   \n",
       "196          ['essential oil', 'vodka', 'liquid soap']   True   \n",
       "197  ['graham cracker crust', 'marshmallows', 'milk...  False   \n",
       "198  ['sugar', 'dry mustard', 'salt', 'vinegar', 'o...   True   \n",
       "199  ['scallops', 'Salt', 'ginger', 'garlic', 'stal...   True   \n",
       "\n",
       "                               NON_VEGAN_INGREDIENTS  \n",
       "0                                       [eggs, milk]  \n",
       "1             [tuna, low-fat sour cream, bacon bits]  \n",
       "2             [ricotta cheese, Parmesan cheese, egg]  \n",
       "3                                   [cheddar cheese]  \n",
       "4    [lean ground beef, parmesan cheese, sour cream]  \n",
       "..                                               ...  \n",
       "195                                         [butter]  \n",
       "196                                               []  \n",
       "197             [marshmallows, milk, whipping cream]  \n",
       "198                                               []  \n",
       "199                                               []  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NER</th>\n",
       "      <th>VEGAN</th>\n",
       "      <th>NON_VEGAN_INGREDIENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Western Sizzlin Bread Pudding</td>\n",
       "      <td>['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...</td>\n",
       "      <td>False</td>\n",
       "      <td>[eggs, milk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n",
       "      <td>['tuna', 'mayonnaise', 'low-fat sour cream', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>[tuna, low-fat sour cream, bacon bits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach And Mushroom Lasagna</td>\n",
       "      <td>['olive oil', 'onion', 'garlic', 'salt', 'grou...</td>\n",
       "      <td>False</td>\n",
       "      <td>[ricotta cheese, Parmesan cheese, egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three-Bean Tacos</td>\n",
       "      <td>['olive oil', 'onion', 'red bell pepper', 'gre...</td>\n",
       "      <td>False</td>\n",
       "      <td>[cheddar cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearty Hamburger Soup</td>\n",
       "      <td>['lean ground beef', 'white onion', 'ground bl...</td>\n",
       "      <td>False</td>\n",
       "      <td>[lean ground beef, parmesan cheese, sour cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Sweet Potato Brotchen (Bread Rolls)</td>\n",
       "      <td>['sweet potatoes', 'butter', 'salt', 'flour', ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Green Cleaner and Bug Repellant in One (Concen...</td>\n",
       "      <td>['essential oil', 'vodka', 'liquid soap']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Chocolate Chip Pie</td>\n",
       "      <td>['graham cracker crust', 'marshmallows', 'milk...</td>\n",
       "      <td>False</td>\n",
       "      <td>[marshmallows, milk, whipping cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Poppy Seed Dressing</td>\n",
       "      <td>['sugar', 'dry mustard', 'salt', 'vinegar', 'o...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Scallop Ceviche</td>\n",
       "      <td>['scallops', 'Salt', 'ginger', 'garlic', 'stal...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-22T13:59:06.595954Z",
     "start_time": "2025-05-22T13:58:45.678170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of non vegetarian ingredients\n",
    "NON_VEGETARIAN_KEYWORDS = {\n",
    "    'meat', 'chicken', 'beef', 'pork', 'fish', 'anchovy', 'tuna', 'salmon',\n",
    "    'shellfish', 'shrimp', 'crab', 'lobster', 'bacon', 'gelatin', 'lard',\n",
    "    'collagen', 'isinglass', 'pepsin', 'ground beef', 'steak', 'tuna'\n",
    "}\n",
    "\n",
    "# Exceptions for vegetarian subs\n",
    "VEGETARIAN_EXCEPTIONS = {\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'},\n",
    "    'gelatin': {'agar', 'pectin'},\n",
    "    'fish': {'banana blossom', 'tofu', 'plant-based'}\n",
    "}\n",
    "\n",
    "VEGETARIAN_MODIFIERS = {\n",
    "    'vegetarian', 'veggie', 'plant-based', 'meatless', 'no meat',\n",
    "    'without meat', 'cruelty-free'\n",
    "}\n",
    "\n",
    "# --- Utility\n",
    "def parse_ingredients(ingredients_input):\n",
    "    \"\"\"Always returning a parsed list of ingredients\"\"\"\n",
    "    if isinstance(ingredients_input, list):\n",
    "        return ingredients_input\n",
    "    if isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "        try:\n",
    "            return ast.literal_eval(ingredients_input)\n",
    "        except:\n",
    "            return [\n",
    "                x.strip().strip('\"').strip(\"'\")\n",
    "                for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                if x.strip()\n",
    "            ]\n",
    "    return []\n",
    "\n",
    "def contains_vegetarian_exception(ingredient, keyword):\n",
    "    exceptions = VEGETARIAN_EXCEPTIONS.get(keyword, set())\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE) for ex in exceptions)\n",
    "\n",
    "# --- Classification\n",
    "def classify_vegetarian(ingredients_input):\n",
    "    \"\"\"Returning True or False based on the ingredients\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        if any(re.search(rf'\\b{re.escape(mod)}\\b', ing_lower) for mod in VEGETARIAN_MODIFIERS):\n",
    "            continue\n",
    "        for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegetarian_exception(ing_lower, keyword):\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def get_non_vegetarian_ingredients(ingredients_input):\n",
    "    \"\"\"Returning list of ingredients without vegetarian exceptions\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    non_vegetarian = []\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegetarian_exception(ing_lower, keyword):\n",
    "                    non_vegetarian.append(ing)\n",
    "                break\n",
    "    return non_vegetarian\n",
    "\n",
    "# Apply to dataframe\n",
    "df['VEGETARIAN'] = df['NER_clean'].apply(classify_vegetarian)\n",
    "df['NON_VEGETARIAN_INGREDIENTS'] = df['NER_clean'].apply(get_non_vegetarian_ingredients)\n",
    "\n",
    "anti_patterns = re.compile(\n",
    "    r'\\b(not vegetarian|not veg|meat|steak|fish|beef|chicken|pork|bacon)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "df['VEGETARIAN'] = df.apply(\n",
    "    lambda row: False if row['VEGETARIAN'] and isinstance(row['TITLE'], str) and anti_patterns.search(row['TITLE']) else row['VEGETARIAN'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show results\n",
    "df[['TITLE', 'NER', 'VEGETARIAN', 'NON_VEGETARIAN_INGREDIENTS']].head(200)"
   ],
   "id": "8813043f994e6a4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 TITLE  \\\n",
       "0                        Western Sizzlin Bread Pudding   \n",
       "1            Creamy Tuna And Bacon Salad (Reduced Fat)   \n",
       "2                        Spinach And Mushroom Lasagna    \n",
       "3                                     Three-Bean Tacos   \n",
       "4                                Hearty Hamburger Soup   \n",
       "..                                                 ...   \n",
       "195                Sweet Potato Brotchen (Bread Rolls)   \n",
       "196  Green Cleaner and Bug Repellant in One (Concen...   \n",
       "197                                 Chocolate Chip Pie   \n",
       "198                                Poppy Seed Dressing   \n",
       "199                                    Scallop Ceviche   \n",
       "\n",
       "                                                   NER  VEGETARIAN  \\\n",
       "0    ['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...        True   \n",
       "1    ['tuna', 'mayonnaise', 'low-fat sour cream', '...       False   \n",
       "2    ['olive oil', 'onion', 'garlic', 'salt', 'grou...        True   \n",
       "3    ['olive oil', 'onion', 'red bell pepper', 'gre...        True   \n",
       "4    ['lean ground beef', 'white onion', 'ground bl...       False   \n",
       "..                                                 ...         ...   \n",
       "195  ['sweet potatoes', 'butter', 'salt', 'flour', ...        True   \n",
       "196          ['essential oil', 'vodka', 'liquid soap']        True   \n",
       "197  ['graham cracker crust', 'marshmallows', 'milk...        True   \n",
       "198  ['sugar', 'dry mustard', 'salt', 'vinegar', 'o...        True   \n",
       "199  ['scallops', 'Salt', 'ginger', 'garlic', 'stal...        True   \n",
       "\n",
       "    NON_VEGETARIAN_INGREDIENTS  \n",
       "0                           []  \n",
       "1           [tuna, bacon bits]  \n",
       "2                           []  \n",
       "3                           []  \n",
       "4           [lean ground beef]  \n",
       "..                         ...  \n",
       "195                         []  \n",
       "196                         []  \n",
       "197                         []  \n",
       "198                         []  \n",
       "199                         []  \n",
       "\n",
       "[200 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>NER</th>\n",
       "      <th>VEGETARIAN</th>\n",
       "      <th>NON_VEGETARIAN_INGREDIENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Western Sizzlin Bread Pudding</td>\n",
       "      <td>['eggs', 'milk', 'sugar', 'vanilla', 'gallon w...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n",
       "      <td>['tuna', 'mayonnaise', 'low-fat sour cream', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>[tuna, bacon bits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach And Mushroom Lasagna</td>\n",
       "      <td>['olive oil', 'onion', 'garlic', 'salt', 'grou...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three-Bean Tacos</td>\n",
       "      <td>['olive oil', 'onion', 'red bell pepper', 'gre...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hearty Hamburger Soup</td>\n",
       "      <td>['lean ground beef', 'white onion', 'ground bl...</td>\n",
       "      <td>False</td>\n",
       "      <td>[lean ground beef]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Sweet Potato Brotchen (Bread Rolls)</td>\n",
       "      <td>['sweet potatoes', 'butter', 'salt', 'flour', ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Green Cleaner and Bug Repellant in One (Concen...</td>\n",
       "      <td>['essential oil', 'vodka', 'liquid soap']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Chocolate Chip Pie</td>\n",
       "      <td>['graham cracker crust', 'marshmallows', 'milk...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Poppy Seed Dressing</td>\n",
       "      <td>['sugar', 'dry mustard', 'salt', 'vinegar', 'o...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Scallop Ceviche</td>\n",
       "      <td>['scallops', 'Salt', 'ginger', 'garlic', 'stal...</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Qui inizia la magia:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "345918a28f5a9fc0"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpu = torch.cuda.get_device_name(0)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {gpu}\")\n",
    "\n",
    "# Eseguire questa cella solo se runnata dal Barone\n",
    "if gpu == \"NVIDIA GeForce RTX 3060 Ti\":\n",
    "    classifier = pipeline(\n",
    "        task=\"zero-shot-classification\",\n",
    "        model=\"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\",\n",
    "        device=0,\n",
    "        torch_dtype=torch.float16,\n",
    "        model_kwargs={\"cache_dir\": \"./cache\"},\n",
    "        batch_size=32,  # Optimal for RTX 3060 Ti\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # %% Data Loading\n",
    "    df['NER'] = df['NER'].apply(eval)  # Convert string lists to actual lists\n",
    "    \n",
    "    # %% Food Categories & Prices (EUR/kg)\n",
    "    CATEGORIES = [\n",
    "        \"dairy\", \"meat\", \"seafood\", \"grain\", \"vegetable\",\n",
    "        \"fruit\", \"spice/herb\", \"processed\", \"sweetener\",\n",
    "        \"condiment\", \"legume\", \"oil/fat\"\n",
    "    ]\n",
    "    \n",
    "    MEDIAN_PRICES = {\n",
    "        \"dairy\": 3.50,       # Milk, cheese\n",
    "        \"meat\": 7.50,        # Chicken, beef\n",
    "        \"seafood\": 12.00,    # Fish, shrimp\n",
    "        \"grain\": 2.20,       # Flour, rice\n",
    "        \"vegetable\": 1.80,   # Onions, garlic\n",
    "        \"fruit\": 2.50,       # Tomatoes, bananas\n",
    "        \"spice/herb\": 18.00, # Vanilla, cinnamon\n",
    "        \"processed\": 4.50,   # Pasta, canned goods\n",
    "        \"sweetener\": 2.20,   # Sugar\n",
    "        \"condiment\": 5.00,   # Mayo, dressings\n",
    "        \"legume\": 3.00,      # Beans, lentils\n",
    "        \"oil/fat\": 8.00      # Olive oil\n",
    "    }\n",
    "    \n",
    "    # %% Ingredient Cleaning (Fixed)\n",
    "    def clean_ingredient(ingredient: str) -> str:\n",
    "        \"\"\"Conservative cleaning preserving ingredient names\"\"\"\n",
    "        # Remove quantities (e.g., \"200g\", \"1/2 cup\")\n",
    "        cleaned = re.sub(r'\\b\\d+[\\d/\\.]*\\s*[a-z]*\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "        # Remove special chars except spaces\n",
    "        cleaned = re.sub(r'[^\\w\\s]', '', cleaned).strip().lower()\n",
    "        return cleaned if cleaned else \"unknown\"\n",
    "    \n",
    "    # %% Batch Classification (GPU-optimized)\n",
    "    classification_cache = {}\n",
    "    \n",
    "    def batch_classify(ingredients: list, batch_size: int = 16) -> dict:  # Reduced batch size\n",
    "        unique_ingredients = list(set(ingredients))\n",
    "    \n",
    "        with torch.no_grad():  # Disable gradient tracking\n",
    "            for batch in tqdm([unique_ingredients[i:i+batch_size]\n",
    "                               for i in range(0, len(unique_ingredients), batch_size)],\n",
    "                              desc=\"Classifying Ingredients\"):\n",
    "                # Process batch on GPU\n",
    "                results = classifier(batch, CATEGORIES, multi_label=False)\n",
    "    \n",
    "                # Cache results\n",
    "                for ing, result in zip(batch, results):\n",
    "                    classification_cache[ing] = result['labels'][0]\n",
    "    \n",
    "                # Clear GPU cache\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "        return classification_cache\n",
    "    \n",
    "    # %% Process Entire Dataset\n",
    "    # Get all unique ingredients\n",
    "    all_ingredients = [clean_ingredient(ing)\n",
    "                       for recipe in df['NER']\n",
    "                       for ing in recipe]\n",
    "    unique_ingredients = list(set(all_ingredients))\n",
    "    \n",
    "    # Batch classify with progress bar\n",
    "    _ = batch_classify(unique_ingredients, batch_size=64)\n",
    "    \n",
    "    # Calculate recipe costs\n",
    "    df['total_cost'] = df['NER'].apply(\n",
    "        lambda x: round(sum(\n",
    "            MEDIAN_PRICES.get(classification_cache[clean_ingredient(ing)], 3.00)\n",
    "            for ing in x\n",
    "        ), 2)\n",
    "    )\n",
    "    \n",
    "    # Dynamic price categorization\n",
    "    costs = df['total_cost'].values\n",
    "    \n",
    "    # threshold per le categorie degli prezzi\n",
    "    very_cheap, cheap, medium, expensive = np.percentile(costs, [20, 40, 60, 85])\n",
    "    \n",
    "    df['price_tag'] = df['total_cost'].apply(\n",
    "        lambda x: 'very cheap' if x <= very_cheap\n",
    "        else 'cheap' if x <= cheap\n",
    "        else 'medium' if x <= medium\n",
    "        else 'expensive' if x <= expensive\n",
    "        else 'rich'\n",
    "    )\n",
    "\n",
    "    def get_categories(ingredient_list):\n",
    "        return [classification_cache.get(ing) for ing in ingredient_list]\n",
    "    \n",
    "    def is_vegan(cat_list):\n",
    "        return all(cat not in ['dairy', 'meat', 'seafood'] for cat in cat_list if cat is not None)\n",
    "    \n",
    "    def is_vegetarian(cat_list):\n",
    "        return all(cat not in ['meat', 'seafood'] for cat in cat_list if cat is not None)\n",
    "    \n",
    "    df['categories'] = df['NER_clean'].apply(get_categories)\n",
    "    df['vegan'] = df['categories'].apply(is_vegan)\n",
    "    df['vegetarian'] = df['categories'].apply(is_vegetarian)\n",
    "    \n",
    "    # Save outputs\n",
    "    df.to_csv('full_tagged_dataset_10%', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-21T20:40:23.158053500Z",
     "start_time": "2025-05-21T20:37:38.119163800Z"
    }
   },
   "id": "6c57cbd4e0ba36f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Classifying Ingredients:   0%|          | 0/260 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Classifying Ingredients: 100%|██████████| 260/260 [02:41<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "Qui la magia finisce :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eade76ff96b7ad22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'PREPARATION_TIME' e testing",
   "id": "f22b17441612ef05"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Method to preprocess a dataframe\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "# Method to train a classificator\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Saving model\n",
    "    model.save(f\"classifiers/prep_time/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/prep_time/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/prep_time/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === FIRST MODEL: PREPARATION_TIME ===\n",
    "df_time = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"PREPARATION_TIME\"]].copy()\n",
    "df_time, prep_time_encoder = preprocess(df_time, [\"INGREDIENTS\", \"DIRECTIONS\"], \"PREPARATION_TIME\")\n",
    "prep_time_model = train_text_classifier(df_time, prep_time_encoder, model_name_prefix=\"prep_time_classifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:09:19.366012Z",
     "start_time": "2025-05-22T14:07:44.306112Z"
    }
   },
   "id": "f4190c03acb0a826",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.3440 - loss: 1.5039 - val_accuracy: 0.5595 - val_loss: 1.0874\n",
      "Epoch 2/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 36ms/step - accuracy: 0.5825 - loss: 1.0628 - val_accuracy: 0.6415 - val_loss: 0.9110\n",
      "Epoch 3/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.6505 - loss: 0.9110 - val_accuracy: 0.6780 - val_loss: 0.8400\n",
      "Epoch 4/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 34ms/step - accuracy: 0.6937 - loss: 0.8323 - val_accuracy: 0.6880 - val_loss: 0.8132\n",
      "Epoch 5/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 32ms/step - accuracy: 0.7184 - loss: 0.7549 - val_accuracy: 0.6755 - val_loss: 0.8112\n",
      "Epoch 6/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 30ms/step - accuracy: 0.7518 - loss: 0.6918 - val_accuracy: 0.6895 - val_loss: 0.8040\n",
      "Epoch 7/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 31ms/step - accuracy: 0.7634 - loss: 0.6626 - val_accuracy: 0.6875 - val_loss: 0.8012\n",
      "Epoch 8/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 32ms/step - accuracy: 0.7805 - loss: 0.6040 - val_accuracy: 0.6870 - val_loss: 0.8150\n",
      "Epoch 9/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 30ms/step - accuracy: 0.8110 - loss: 0.5464 - val_accuracy: 0.6900 - val_loss: 0.8216\n",
      "Epoch 10/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 31ms/step - accuracy: 0.8343 - loss: 0.4890 - val_accuracy: 0.6790 - val_loss: 0.8459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello 'prep_time_classifier' salvato con successo.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:10:22.215224Z",
     "start_time": "2025-05-22T14:10:21.981130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "prep_time_model = load_model(\"classifiers/prep_time/prep_time_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/prep_time/prep_time_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    prep_time_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/prep_time/prep_time_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    prep_time_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_prep_time_label_map = {v: k for k, v in prep_time_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected time\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sauté garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_time\": \"15 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_time\": \"10 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"Sauté the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_time\": \"30 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_time\": \"5 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, béchamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, béchamel and cheese. Bake at 180°C for 40 minutes.\",\n",
    "        \"expected_time\": \"60 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_time\": \"10 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_time\": \"25 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_time\": \"30 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_time\": \"20 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. Sauté onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_time\": \"90 min\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "prep_sequences = prep_time_tokenizer.texts_to_sequences(texts)\n",
    "prep_padded = pad_sequences(prep_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting time with probabilities\n",
    "prep_preds = prep_time_model.predict(prep_padded)\n",
    "prep_classes = prep_preds.argmax(axis=1)\n",
    "prep_labels = [inv_prep_time_label_map[c] for c in prep_classes]\n",
    "\n",
    "# Print results with probabilities\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected preparation time: {recipe['expected_time']} minutes\")\n",
    "    print(f\"  Predicted preparation time: {prep_labels[i]}\")\n",
    "    prep_probs_str = \", \".join([f\"{inv_prep_time_label_map[j]}: {prep_preds[i][j]*100:.2f}%\" for j in range(len(prep_preds[i]))])\n",
    "    print(f\"  Preparation time probabilities: {prep_probs_str}\")"
   ],
   "id": "367571519be110ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step\n",
      "Recipe 1:\n",
      "  Expected preparation time: 15 min minutes\n",
      "  Predicted preparation time: Fast (10-20 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 47.13%, Medium (20-40 mins): 32.66%, Slow (40-90 mins): 5.50%, Very fast (0-10 mins): 12.92%, Very slow (90+ mins): 1.79%\n",
      "Recipe 2:\n",
      "  Expected preparation time: 10 min minutes\n",
      "  Predicted preparation time: Fast (10-20 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 68.13%, Medium (20-40 mins): 23.42%, Slow (40-90 mins): 1.01%, Very fast (0-10 mins): 7.07%, Very slow (90+ mins): 0.36%\n",
      "Recipe 3:\n",
      "  Expected preparation time: 30 min minutes\n",
      "  Predicted preparation time: Medium (20-40 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 13.88%, Medium (20-40 mins): 62.13%, Slow (40-90 mins): 14.24%, Very fast (0-10 mins): 7.64%, Very slow (90+ mins): 2.11%\n",
      "Recipe 4:\n",
      "  Expected preparation time: 5 min minutes\n",
      "  Predicted preparation time: Medium (20-40 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 10.17%, Medium (20-40 mins): 69.86%, Slow (40-90 mins): 12.77%, Very fast (0-10 mins): 6.10%, Very slow (90+ mins): 1.10%\n",
      "Recipe 5:\n",
      "  Expected preparation time: 60 min minutes\n",
      "  Predicted preparation time: Slow (40-90 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 6.70%, Medium (20-40 mins): 3.22%, Slow (40-90 mins): 83.20%, Very fast (0-10 mins): 1.34%, Very slow (90+ mins): 5.55%\n",
      "Recipe 6:\n",
      "  Expected preparation time: 10 min minutes\n",
      "  Predicted preparation time: Fast (10-20 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 78.58%, Medium (20-40 mins): 11.56%, Slow (40-90 mins): 6.30%, Very fast (0-10 mins): 3.01%, Very slow (90+ mins): 0.55%\n",
      "Recipe 7:\n",
      "  Expected preparation time: 25 min minutes\n",
      "  Predicted preparation time: Medium (20-40 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 26.66%, Medium (20-40 mins): 65.08%, Slow (40-90 mins): 1.45%, Very fast (0-10 mins): 6.73%, Very slow (90+ mins): 0.09%\n",
      "Recipe 8:\n",
      "  Expected preparation time: 30 min minutes\n",
      "  Predicted preparation time: Medium (20-40 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 1.41%, Medium (20-40 mins): 64.18%, Slow (40-90 mins): 23.63%, Very fast (0-10 mins): 6.49%, Very slow (90+ mins): 4.30%\n",
      "Recipe 9:\n",
      "  Expected preparation time: 20 min minutes\n",
      "  Predicted preparation time: Medium (20-40 mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 8.58%, Medium (20-40 mins): 65.82%, Slow (40-90 mins): 12.20%, Very fast (0-10 mins): 11.97%, Very slow (90+ mins): 1.43%\n",
      "Recipe 10:\n",
      "  Expected preparation time: 90 min minutes\n",
      "  Predicted preparation time: Very slow (90+ mins)\n",
      "  Preparation time probabilities: Fast (10-20 mins): 0.02%, Medium (20-40 mins): 0.19%, Slow (40-90 mins): 2.49%, Very fast (0-10 mins): 0.01%, Very slow (90+ mins): 97.30%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'DIFFICULTY' e testing",
   "id": "2b694bd06c7801a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.291549800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/difficulty/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/difficulty/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/difficulty/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === SECOND MODEL: DIFFICULTY ===\n",
    "df_difficulty = pd.read_csv(\"recipes_with_prices\")\n",
    "df_difficulty, difficulty_encoder = preprocess(df_difficulty, [\"ingredients\", \"directions\"], \"difficulty\")\n",
    "difficulty_model = train_text_classifier(df_difficulty, difficulty_encoder, model_name_prefix=\"difficulty_classifier\")"
   ],
   "id": "2c63caf69e9c1eb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.293549800Z",
     "start_time": "2025-05-21T20:20:50.292551900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "difficulty_model = load_model(\"classifiers/difficulty/difficulty_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/difficulty/difficulty_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    difficulty_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/difficulty/difficulty_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    difficulty_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_difficulty_label_map = {v: k for k, v in difficulty_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected difficulty\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sauté garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"Sauté the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, béchamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, béchamel and cheese. Bake at 180°C for 40 minutes.\",\n",
    "        \"expected_difficulty\": \"Hard\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. Sauté onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_difficulty\": \"Hard\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "diff_sequences = difficulty_tokenizer.texts_to_sequences(texts)\n",
    "diff_padded = pad_sequences(diff_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting difficulty\n",
    "diff_preds = difficulty_model.predict(diff_padded)\n",
    "diff_classes = diff_preds.argmax(axis=1)\n",
    "diff_labels = [inv_difficulty_label_map[c] for c in diff_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected difficulty: {recipe['expected_difficulty']}\")\n",
    "    print(f\"  Predicted difficulty: {diff_labels[i]}\")\n",
    "    diff_probs_str = \", \".join([f\"{inv_difficulty_label_map[j]}: {diff_preds[i][j]*100:.2f}%\" for j in range(len(diff_preds[i]))])\n",
    "    print(f\"  Difficulty probabilities: {diff_probs_str}\\n\")"
   ],
   "id": "8c4c90ec82e24a52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'VEGAN' e testing",
   "id": "a4918a853d499001"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.295554300Z",
     "start_time": "2025-05-21T20:20:50.293549800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/vegan/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/vegan/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/vegan/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === THIRD MODEL: VEGAN ===\n",
    "df_vegan = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"VEGAN\"]].copy()\n",
    "df_vegan, vegan_encoder = preprocess(df_vegan, [\"INGREDIENTS\", \"DIRECTIONS\"], \"VEGAN\")\n",
    "vegan_classifier_model = train_text_classifier(df_vegan, vegan_encoder, model_name_prefix=\"vegan_classifier\")"
   ],
   "id": "a46683e1e4a3fd77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.301553500Z",
     "start_time": "2025-05-21T20:20:50.295554300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "vegan_model = load_model(\"classifiers/vegan/vegan_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/vegan/vegan_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    vegan_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/vegan/vegan_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    vegan_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_vegan_label_map = {v: k for k, v in vegan_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected vegan\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sauté garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_vegan\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"Sauté the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, béchamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, béchamel and cheese. Bake at 180°C for 40 minutes.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_vegan\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. Sauté onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_vegan\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "vegan_sequences = vegan_tokenizer.texts_to_sequences(texts)\n",
    "vegan_padded = pad_sequences(vegan_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting vegan true or false\n",
    "vegan_preds = vegan_model.predict(vegan_padded)\n",
    "vegan_classes = vegan_preds.argmax(axis=1)\n",
    "vegan_labels = [inv_vegan_label_map[c] for c in vegan_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected vegan: {recipe['expected_vegan']}\")\n",
    "    print(f\"  Predicted vegan: {vegan_labels[i]}\")\n",
    "    vegan_probs_str = \", \".join([f\"{inv_vegan_label_map[j]}: {vegan_preds[i][j]*100:.2f}%\" for j in range(len(vegan_preds[i]))])\n",
    "    print(f\"  Vegan probabilities: {vegan_probs_str}\\n\")"
   ],
   "id": "3de5d93512c1d065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'VEGETARIAN' e testing",
   "id": "35c80420b43a76c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.297555600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/vegetarian/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/vegetarian/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/vegetarian/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === FOURTH MODEL: VEGETARIAN ===\n",
    "df_vegetarian = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"VEGETARIAN\"]].copy()\n",
    "df_vegetarian, vegetarian_encoder = preprocess(df_vegetarian, [\"INGREDIENTS\", \"DIRECTIONS\"], \"VEGETARIAN\")\n",
    "vegetarian_classifier_model = train_text_classifier(df_vegetarian, vegetarian_encoder, model_name_prefix=\"vegetarian_classifier\")"
   ],
   "id": "44472144d51bbbb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.298553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "vegetarian_model = load_model(\"classifiers/vegetarian/vegetarian_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/vegetarian/vegetarian_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    vegetarian_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/vegetarian/vegetarian_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    vegetarian_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_vegetarian_label_map = {v: k for k, v in vegetarian_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected vegetarian\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sauté garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_vegetarian\": False  # Tuna = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"Sauté the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, béchamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, béchamel and cheese. Bake at 180°C for 40 minutes.\",\n",
    "        \"expected_vegetarian\": False  # Meat sauce = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_vegetarian\": False  # Chicken = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. Sauté onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "vegetarian_sequences = vegetarian_tokenizer.texts_to_sequences(texts)\n",
    "vegetarian_padded = pad_sequences(vegetarian_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting vegetarian true or false\n",
    "vegetarian_preds = vegetarian_model.predict(vegetarian_padded)\n",
    "vegetarian_classes = vegetarian_preds.argmax(axis=1)\n",
    "vegetarian_labels = [inv_vegetarian_label_map[c] for c in vegetarian_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected vegetarian: {recipe['expected_vegetarian']}\")\n",
    "    print(f\"  Predicted vegetarian: {vegetarian_labels[i]}\")\n",
    "    vegetarian_probs_str = \", \".join([f\"{inv_vegetarian_label_map[j]}: {vegetarian_preds[i][j]*100:.2f}%\" for j in range(len(vegetarian_preds[i]))])\n",
    "    print(f\"  Vegetarian probabilities: {vegetarian_probs_str}\\n\")"
   ],
   "id": "63280a53e93b2d1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'METHOD' e testing",
   "id": "261721095f30435a"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/method/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/method/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/method/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === FIFTH MODEL: METHOD ===\n",
    "df_method = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"method\"]].copy()\n",
    "df_method, method_encoder = preprocess(df_method, [\"INGREDIENTS\", \"DIRECTIONS\"], \"method\")\n",
    "method_classifier_model = train_text_classifier(df_method, method_encoder, model_name_prefix=\"method_classifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:35:40.196362Z",
     "start_time": "2025-05-22T14:34:03.054531Z"
    }
   },
   "id": "7e31b42298771f5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.4803 - loss: 1.5450 - val_accuracy: 0.8685 - val_loss: 0.6252\n",
      "Epoch 2/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 36ms/step - accuracy: 0.8676 - loss: 0.5842 - val_accuracy: 0.9145 - val_loss: 0.4036\n",
      "Epoch 3/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.9044 - loss: 0.4103 - val_accuracy: 0.9195 - val_loss: 0.3357\n",
      "Epoch 4/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 34ms/step - accuracy: 0.9136 - loss: 0.3366 - val_accuracy: 0.9215 - val_loss: 0.2983\n",
      "Epoch 5/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 33ms/step - accuracy: 0.9233 - loss: 0.2860 - val_accuracy: 0.9225 - val_loss: 0.2683\n",
      "Epoch 6/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.9296 - loss: 0.2529 - val_accuracy: 0.9300 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.9324 - loss: 0.2210 - val_accuracy: 0.9320 - val_loss: 0.2335\n",
      "Epoch 8/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.9376 - loss: 0.2054 - val_accuracy: 0.9360 - val_loss: 0.2190\n",
      "Epoch 9/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 37ms/step - accuracy: 0.9444 - loss: 0.1837 - val_accuracy: 0.9395 - val_loss: 0.2101\n",
      "Epoch 10/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 34ms/step - accuracy: 0.9476 - loss: 0.1648 - val_accuracy: 0.9365 - val_loss: 0.2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello 'method_classifier' salvato con successo.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:36:15.603124Z",
     "start_time": "2025-05-22T14:36:15.376901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "method_model = load_model(\"classifiers/method/method_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/method/method_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    method_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/method/method_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    method_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_method_label_map = {v: k for k, v in method_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected method\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"500g potatoes, olive oil, rosemary, salt\",\n",
    "        \"instructions\": \"Peel and cut the potatoes into chunks. Toss with olive oil and rosemary. Cook in oven at 200°C for 45 minutes.\",\n",
    "        \"expected_method\": \"Roasted\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, salt, water\",\n",
    "        \"instructions\": \"Boil water in a large pot, add salt and cook the spaghetti until al dente.\",\n",
    "        \"expected_method\": \"Boiled\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 chicken breasts, olive oil, herbs, salt\",\n",
    "        \"instructions\": \"Brush chicken with oil and herbs. Cook on a preheated grill for 6 minutes per side.\",\n",
    "        \"expected_method\": \"Grilled\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"4 eggs, butter, salt, pepper\",\n",
    "        \"instructions\": \"Heat butter in a pan. Crack eggs in and fry until edges are crispy.\",\n",
    "        \"expected_method\": \"Fried\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"1 salmon fillet, lemon juice, herbs, salt\",\n",
    "        \"instructions\": \"Place salmon in a baking dish, season, and bake at 180°C for 20 minutes.\",\n",
    "        \"expected_method\": \"Baked\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Broccoli, carrots, zucchini, salt\",\n",
    "        \"instructions\": \"Wash and cut vegetables. Eat raw or season with salt and olive oil.\",\n",
    "        \"expected_method\": \"Raw\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Beef steak, salt, pepper, olive oil\",\n",
    "        \"instructions\": \"Season steak and place under a broiler for 5–7 minutes on each side.\",\n",
    "        \"expected_method\": \"Broil\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"1 cauliflower, salt, oil, paprika\",\n",
    "        \"instructions\": \"Cut cauliflower into florets. Toss with oil and paprika. Roast in oven at 220°C for 30 minutes.\",\n",
    "        \"expected_method\": \"Roasted\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Rice, water, salt\",\n",
    "        \"instructions\": \"Rinse the rice and boil in salted water for 15 minutes.\",\n",
    "        \"expected_method\": \"Boil\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"1 can chickpeas, tahini, lemon juice, garlic, olive oil\",\n",
    "        \"instructions\": \"Blend all ingredients in a food processor until smooth. Serve as is.\",\n",
    "        \"expected_method\": \"Other\"  # Nessuna cottura classica, solo preparazione a crudo e frullatura\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "method_sequences = method_tokenizer.texts_to_sequences(texts)\n",
    "method_padded = pad_sequences(method_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting method\n",
    "method_preds = method_model.predict(method_padded)\n",
    "method_classes = method_preds.argmax(axis=1)\n",
    "method_labels = [inv_method_label_map[c] for c in method_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected method: {recipe['expected_method']}\")\n",
    "    print(f\"  Predicted method: {method_labels[i]}\")\n",
    "    method_probs_str = \", \".join([f\"{inv_method_label_map[j]}: {method_preds[i][j]*100:.2f}%\" for j in range(len(method_preds[i]))])\n",
    "    print(f\"  Method probabilities: {method_probs_str}\\n\")"
   ],
   "id": "da1c262d0a0539e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 75ms/step\n",
      "Recipe 1:\n",
      "  Expected method: Roasted\n",
      "  Predicted method: Other\n",
      "  Method probabilities: Bake: 0.62%, Baked: 0.05%, Boil: 1.92%, Boiled: 0.73%, Broil: 2.13%, Fried: 0.75%, Grill: 0.63%, Grilled: 0.07%, Other: 90.87%, Raw: 0.40%, Roasted: 1.84%\n",
      "\n",
      "Recipe 2:\n",
      "  Expected method: Boiled\n",
      "  Predicted method: Boil\n",
      "  Method probabilities: Bake: 0.27%, Baked: 0.12%, Boil: 96.48%, Boiled: 1.41%, Broil: 0.01%, Fried: 0.54%, Grill: 0.00%, Grilled: 0.05%, Other: 0.03%, Raw: 0.56%, Roasted: 0.53%\n",
      "\n",
      "Recipe 3:\n",
      "  Expected method: Grilled\n",
      "  Predicted method: Grill\n",
      "  Method probabilities: Bake: 0.01%, Baked: 0.02%, Boil: 0.19%, Boiled: 0.08%, Broil: 0.19%, Fried: 0.11%, Grill: 98.71%, Grilled: 0.61%, Other: 0.02%, Raw: 0.04%, Roasted: 0.02%\n",
      "\n",
      "Recipe 4:\n",
      "  Expected method: Fried\n",
      "  Predicted method: Other\n",
      "  Method probabilities: Bake: 0.02%, Baked: 0.00%, Boil: 0.22%, Boiled: 0.04%, Broil: 0.13%, Fried: 0.04%, Grill: 0.09%, Grilled: 0.00%, Other: 99.34%, Raw: 0.05%, Roasted: 0.07%\n",
      "\n",
      "Recipe 5:\n",
      "  Expected method: Baked\n",
      "  Predicted method: Bake\n",
      "  Method probabilities: Bake: 98.11%, Baked: 0.21%, Boil: 0.00%, Boiled: 0.44%, Broil: 0.02%, Fried: 0.27%, Grill: 0.00%, Grilled: 0.05%, Other: 0.00%, Raw: 0.50%, Roasted: 0.40%\n",
      "\n",
      "Recipe 6:\n",
      "  Expected method: Raw\n",
      "  Predicted method: Other\n",
      "  Method probabilities: Bake: 0.21%, Baked: 0.24%, Boil: 0.73%, Boiled: 1.17%, Broil: 1.63%, Fried: 1.71%, Grill: 3.44%, Grilled: 2.22%, Other: 81.34%, Raw: 6.34%, Roasted: 0.97%\n",
      "\n",
      "Recipe 7:\n",
      "  Expected method: Broil\n",
      "  Predicted method: Broil\n",
      "  Method probabilities: Bake: 0.53%, Baked: 1.21%, Boil: 1.50%, Boiled: 0.91%, Broil: 73.29%, Fried: 3.14%, Grill: 14.45%, Grilled: 0.87%, Other: 1.91%, Raw: 1.33%, Roasted: 0.86%\n",
      "\n",
      "Recipe 8:\n",
      "  Expected method: Roasted\n",
      "  Predicted method: Other\n",
      "  Method probabilities: Bake: 0.09%, Baked: 0.04%, Boil: 1.80%, Boiled: 0.61%, Broil: 2.35%, Fried: 0.85%, Grill: 0.83%, Grilled: 0.10%, Other: 89.98%, Raw: 0.49%, Roasted: 2.86%\n",
      "\n",
      "Recipe 9:\n",
      "  Expected method: Boil\n",
      "  Predicted method: Boil\n",
      "  Method probabilities: Bake: 0.41%, Baked: 0.09%, Boil: 96.69%, Boiled: 1.44%, Broil: 0.01%, Fried: 0.35%, Grill: 0.00%, Grilled: 0.04%, Other: 0.03%, Raw: 0.44%, Roasted: 0.52%\n",
      "\n",
      "Recipe 10:\n",
      "  Expected method: Other\n",
      "  Predicted method: Other\n",
      "  Method probabilities: Bake: 0.00%, Baked: 0.00%, Boil: 0.15%, Boiled: 0.01%, Broil: 0.04%, Fried: 0.01%, Grill: 0.07%, Grilled: 0.00%, Other: 99.65%, Raw: 0.05%, Roasted: 0.01%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
