{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:48.407632200Z",
     "start_time": "2025-05-16T21:58:47.449886900Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File and create a new dataframe called df\n",
    "df = pd.read_csv('dataset_1.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:48.414191700Z",
     "start_time": "2025-05-16T21:58:48.410145900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_fractions(text):\n",
    "    # Match optional whole number + fraction, or just fraction\n",
    "    pattern = r'(?:(\\d+)\\s+)?(\\d+)/(\\d+)'\n",
    "\n",
    "    def replacer(match):\n",
    "        whole = int(match.group(1)) if match.group(1) else 0\n",
    "        numerator = int(match.group(2))\n",
    "        denominator = int(match.group(3))\n",
    "        decimal = whole + Fraction(numerator, denominator)\n",
    "        return \"{:.10g}\".format(float(decimal))  # Clean, no trailing zeros\n",
    "\n",
    "    return re.sub(pattern, replacer, text)"
   ],
   "id": "f6177b908ebf022c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:48.427350100Z",
     "start_time": "2025-05-16T21:58:48.414191700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "# fixed conversions\n",
    "CONVERSIONS = {\n",
    "    \"oz\": 30,      # ounce → gram\n",
    "    \"lb\": 450,      # pounds → gram\n",
    "    \"pt\": 475,      # pint → milliliter\n",
    "    \"qt\": 950,      # quart → milliliter\n",
    "    \"inch\": 2.5        # inches → centimeter\n",
    "}"
   ],
   "id": "35a1e5c191694098",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:48.445362200Z",
     "start_time": "2025-05-16T21:58:48.428350200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_units(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # Convert oz, lb, pt, qt (form: \"4 oz\", \"2.5 lb\", etc.)\n",
    "    for unit, factor in CONVERSIONS.items():\n",
    "        pattern = r'(\\d+(\\.\\d+)?)\\s*' + unit\n",
    "        text = re.sub(pattern, lambda m: f\"{round(float(m.group(1)) * factor, 1)} {unit_to_metric(unit)}\", text)\n",
    "\n",
    "    # Convert measure in inches in pans\n",
    "    text = re.sub(r'(\\d+)\\s*x\\s*(\\d+)[-\\s]*inch', lambda m: f\"{int(m.group(1)) * CONVERSIONS['inch']:.0f} x {int(m.group(2)) * CONVERSIONS['inch']:.0f} cm\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_fahrenheit_to_celsius(text):\n",
    "    # Match degrees like 275°, 275 °F, 275\\u00b0F (escaped), etc.\n",
    "    pattern = r'(\\d+)\\s*(?:°|\\\\u00b0)'\n",
    "\n",
    "    def replacer(match):\n",
    "        fahrenheit = int(match.group(1))\n",
    "        celsius = round((fahrenheit - 32) * 5 / 9)\n",
    "        return f\"{celsius}°C\"\n",
    "\n",
    "    return re.sub(pattern, replacer, text)\n",
    "\n",
    "def unit_to_metric(unit):\n",
    "    return {\n",
    "        \"oz\": \"g\",\n",
    "        \"lb\": \"g\",\n",
    "        \"pt\": \"ml\",\n",
    "        \"qt\": \"ml\",\n",
    "        \"inch\": \"cm\"\n",
    "    }[unit]"
   ],
   "id": "575170d6f2d61a67",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:53.465219800Z",
     "start_time": "2025-05-16T21:58:48.440347500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#applying conversions on the INGREDIENTS and DIRECTIOND columns\n",
    "df['INGREDIENTS'] = df['ingredients'].apply(convert_fractions)\n",
    "df['DIRECTIONS'] = df['directions'].apply(convert_fractions)\n",
    "\n",
    "df['INGREDIENTS'] = df['INGREDIENTS'].apply(convert_units)\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_units)\n",
    "\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_fahrenheit_to_celsius)\n",
    "\n",
    "#renaming the title column\n",
    "df = df.rename(columns={\"title\": \"TITLE\"})\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS']].head(200)"
   ],
   "id": "f1908c40439dd4ba",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 TITLE  \\\n0                        Western Sizzlin Bread Pudding   \n1            Creamy Tuna And Bacon Salad (Reduced Fat)   \n2                        Spinach And Mushroom Lasagna    \n3                                     Three-Bean Tacos   \n4                                Hearty Hamburger Soup   \n..                                                 ...   \n195                Sweet Potato Brotchen (Bread Rolls)   \n196  Green Cleaner and Bug Repellant in One (Concen...   \n197                                 Chocolate Chip Pie   \n198                                Poppy Seed Dressing   \n199                                    Scallop Ceviche   \n\n                                           INGREDIENTS  \\\n0    [\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...   \n1    [\"1 (6 ounce) can tuna, drained and flaked\", \"...   \n2    [\"1 tablespoon olive oil\", \"1 medium onion , c...   \n3    [\"1 teaspoon olive oil\", \"1 cup diced onion\", ...   \n4    [\"900.0 gs lean ground beef\", \"1 white onion, ...   \n..                                                 ...   \n195  [\"450 g sweet potatoes\", \"15 g butter or olive...   \n196  [\"1 tablespoon essential oil (part)\", \"3 table...   \n197  [\"1 graham cracker crust\", \"20 large marshmall...   \n198  [\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...   \n199  [\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...   \n\n                                            DIRECTIONS  \n0    [\"Distribute rolls and cinnamon roll in (4) 2\\...  \n1    [\"Put everything in a bowl and mix together un...  \n2    [\"Heat oven to 375 degrees.\", \"\", \"In medium s...  \n3    [\"Heat oil in a large skillet over medium-high...  \n4    [\"Brown ground beef and onion in a large pot. ...  \n..                                                 ...  \n195  [\"Peel and cut sweet potatoes into chunks.\", \"...  \n196  [\"Mix all ingredients.\", \"Store in a glass jar...  \n197  [\"Make crust (I buy the prepared ones from the...  \n198  [\"Combine first 6 ingredients in a blender con...  \n199  [\"Bring a pot of water to a boil, salt the wat...  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>INGREDIENTS</th>\n      <th>DIRECTIONS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Western Sizzlin Bread Pudding</td>\n      <td>[\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...</td>\n      <td>[\"Distribute rolls and cinnamon roll in (4) 2\\...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n      <td>[\"1 (6 ounce) can tuna, drained and flaked\", \"...</td>\n      <td>[\"Put everything in a bowl and mix together un...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Spinach And Mushroom Lasagna</td>\n      <td>[\"1 tablespoon olive oil\", \"1 medium onion , c...</td>\n      <td>[\"Heat oven to 375 degrees.\", \"\", \"In medium s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Three-Bean Tacos</td>\n      <td>[\"1 teaspoon olive oil\", \"1 cup diced onion\", ...</td>\n      <td>[\"Heat oil in a large skillet over medium-high...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hearty Hamburger Soup</td>\n      <td>[\"900.0 gs lean ground beef\", \"1 white onion, ...</td>\n      <td>[\"Brown ground beef and onion in a large pot. ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Sweet Potato Brotchen (Bread Rolls)</td>\n      <td>[\"450 g sweet potatoes\", \"15 g butter or olive...</td>\n      <td>[\"Peel and cut sweet potatoes into chunks.\", \"...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Green Cleaner and Bug Repellant in One (Concen...</td>\n      <td>[\"1 tablespoon essential oil (part)\", \"3 table...</td>\n      <td>[\"Mix all ingredients.\", \"Store in a glass jar...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Chocolate Chip Pie</td>\n      <td>[\"1 graham cracker crust\", \"20 large marshmall...</td>\n      <td>[\"Make crust (I buy the prepared ones from the...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Poppy Seed Dressing</td>\n      <td>[\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...</td>\n      <td>[\"Combine first 6 ingredients in a blender con...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Scallop Ceviche</td>\n      <td>[\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...</td>\n      <td>[\"Bring a pot of water to a boil, salt the wat...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:55.568071800Z",
     "start_time": "2025-05-16T21:58:53.462708300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# patterns to detect time expressions\n",
    "time_pattern = re.compile(\n",
    "    r'(\\d+\\.?\\d*)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h|day|days|d)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "range_pattern = re.compile(\n",
    "    r'(\\d+)\\s*-\\s*(\\d+)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Time estimates for common preparation methods\n",
    "PREP_ESTIMATES = {\n",
    "    'bake': 45,\n",
    "    'boil': 20,\n",
    "    'fry': 15,\n",
    "    'grill': 25,\n",
    "    'chill': 120,\n",
    "    'simmer': 30,\n",
    "    'marinate': 60,\n",
    "    'microwave': 10,\n",
    "    'no-bake': 20,\n",
    "    'refrigerate': 180,\n",
    "    'freeze': 240\n",
    "}\n",
    "\n",
    "# Special cases for recipe types\n",
    "RECIPE_TYPE_ESTIMATES = {\n",
    "    'pasta': 10,\n",
    "    'salad': 15,\n",
    "    'cake': 45,\n",
    "    'pie': 60,\n",
    "    'stew': 120,\n",
    "    'casserole': 60,\n",
    "    'soup': 30,\n",
    "    'cookies': 30,\n",
    "    'bread': 90,\n",
    "    'fudge': 20,\n",
    "    'candy': 30\n",
    "}\n",
    "\n",
    "# Convert time quantities to minutes\n",
    "def convert_to_minutes(qty, unit):\n",
    "    qty = float(qty)\n",
    "    unit = unit.lower()\n",
    "    if unit in ['minute', 'minutes', 'min', 'mins', 'm']:\n",
    "        return qty\n",
    "    elif unit in ['hour', 'hours', 'hr', 'hrs', 'h']:\n",
    "        return qty * 60\n",
    "    elif unit in ['day', 'days', 'd']:\n",
    "        return qty * 24 * 60\n",
    "    return 0\n",
    "\n",
    "# Estimate time on recipe type\n",
    "def estimate_by_recipe_type(recipe_name, ingredients):\n",
    "    recipe_name = str(recipe_name).lower()\n",
    "    ingredients = str(ingredients).lower()\n",
    "\n",
    "    # Check for specific recipe types\n",
    "    for recipe_type, time in RECIPE_TYPE_ESTIMATES.items():\n",
    "        if recipe_type in recipe_name:\n",
    "            return time\n",
    "\n",
    "    # Estimate based on ingredients\n",
    "    if 'raw' in ingredients or 'fresh' in ingredients:\n",
    "        return 15\n",
    "    if 'frozen' in ingredients:\n",
    "        return 20\n",
    "    if 'canned' in ingredients:\n",
    "        return 10\n",
    "\n",
    "    # Default estimation\n",
    "    return 30\n",
    "\n",
    "# Extract and sum all time references from recipe instructions\n",
    "def parse_instructions(instructions):\n",
    "    if isinstance(instructions, str):\n",
    "        try:\n",
    "            instructions = ast.literal_eval(instructions)\n",
    "        except:\n",
    "            instructions = [instructions]\n",
    "\n",
    "    total_time = 0\n",
    "    for step in instructions:\n",
    "        if not isinstance(step, str):\n",
    "            continue\n",
    "\n",
    "        # Handle time ranges\n",
    "        step = re.sub(\n",
    "            range_pattern,\n",
    "            lambda m: f'{m.group(2)} {m.group(3)}',\n",
    "            step\n",
    "        )\n",
    "\n",
    "        # Special cases\n",
    "        if 'overnight' in step.lower():\n",
    "            total_time += 480  # 8 hours\n",
    "        elif 'until set' in step.lower() or 'until firm' in step.lower():\n",
    "            total_time += 60  # 1 hour estimation\n",
    "\n",
    "        # Find all time references\n",
    "        matches = time_pattern.findall(step)\n",
    "        for (qty, unit) in matches:\n",
    "            total_time += convert_to_minutes(qty, unit)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "def categorize_time(total_time):\n",
    "    if total_time == 0:\n",
    "        return 'Not specified'\n",
    "    elif total_time < 10:\n",
    "        return 'Very fast (0-10 mins)'\n",
    "    elif 10 <= total_time < 20:\n",
    "        return 'Fast (10-20 mins)'\n",
    "    elif 20 <= total_time < 40:\n",
    "        return 'Medium (20-40 mins)'\n",
    "    elif 40 <= total_time < 90:\n",
    "        return 'Slow (40-90 mins)'\n",
    "    else:\n",
    "        return 'Very slow (90+ mins)'\n",
    "\n",
    "# Calculate total preparation time\n",
    "df['total_time'] = df['DIRECTIONS'].apply(parse_instructions)\n",
    "\n",
    "# Estimate time for unspecified recipes\n",
    "mask = df['total_time'] == 0\n",
    "df.loc[mask, 'total_time'] = df[mask].apply(\n",
    "    lambda x: estimate_by_recipe_type(x['TITLE'], x['INGREDIENTS']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Categorize preparation times\n",
    "df['PREPARATION_TIME'] = df['total_time'].apply(categorize_time)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS', 'PREPARATION_TIME']].head(200)"
   ],
   "id": "4ca47d472c93a067",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 TITLE  \\\n0                        Western Sizzlin Bread Pudding   \n1            Creamy Tuna And Bacon Salad (Reduced Fat)   \n2                        Spinach And Mushroom Lasagna    \n3                                     Three-Bean Tacos   \n4                                Hearty Hamburger Soup   \n..                                                 ...   \n195                Sweet Potato Brotchen (Bread Rolls)   \n196  Green Cleaner and Bug Repellant in One (Concen...   \n197                                 Chocolate Chip Pie   \n198                                Poppy Seed Dressing   \n199                                    Scallop Ceviche   \n\n                                           INGREDIENTS  \\\n0    [\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...   \n1    [\"1 (6 ounce) can tuna, drained and flaked\", \"...   \n2    [\"1 tablespoon olive oil\", \"1 medium onion , c...   \n3    [\"1 teaspoon olive oil\", \"1 cup diced onion\", ...   \n4    [\"900.0 gs lean ground beef\", \"1 white onion, ...   \n..                                                 ...   \n195  [\"450 g sweet potatoes\", \"15 g butter or olive...   \n196  [\"1 tablespoon essential oil (part)\", \"3 table...   \n197  [\"1 graham cracker crust\", \"20 large marshmall...   \n198  [\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...   \n199  [\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...   \n\n                                            DIRECTIONS       PREPARATION_TIME  \n0    [\"Distribute rolls and cinnamon roll in (4) 2\\...   Very slow (90+ mins)  \n1    [\"Put everything in a bowl and mix together un...      Fast (10-20 mins)  \n2    [\"Heat oven to 375 degrees.\", \"\", \"In medium s...      Slow (40-90 mins)  \n3    [\"Heat oil in a large skillet over medium-high...    Medium (20-40 mins)  \n4    [\"Brown ground beef and onion in a large pot. ...      Slow (40-90 mins)  \n..                                                 ...                    ...  \n195  [\"Peel and cut sweet potatoes into chunks.\", \"...   Very slow (90+ mins)  \n196  [\"Mix all ingredients.\", \"Store in a glass jar...    Medium (20-40 mins)  \n197  [\"Make crust (I buy the prepared ones from the...      Slow (40-90 mins)  \n198  [\"Combine first 6 ingredients in a blender con...  Very fast (0-10 mins)  \n199  [\"Bring a pot of water to a boil, salt the wat...      Fast (10-20 mins)  \n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>INGREDIENTS</th>\n      <th>DIRECTIONS</th>\n      <th>PREPARATION_TIME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Western Sizzlin Bread Pudding</td>\n      <td>[\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...</td>\n      <td>[\"Distribute rolls and cinnamon roll in (4) 2\\...</td>\n      <td>Very slow (90+ mins)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Creamy Tuna And Bacon Salad (Reduced Fat)</td>\n      <td>[\"1 (6 ounce) can tuna, drained and flaked\", \"...</td>\n      <td>[\"Put everything in a bowl and mix together un...</td>\n      <td>Fast (10-20 mins)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Spinach And Mushroom Lasagna</td>\n      <td>[\"1 tablespoon olive oil\", \"1 medium onion , c...</td>\n      <td>[\"Heat oven to 375 degrees.\", \"\", \"In medium s...</td>\n      <td>Slow (40-90 mins)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Three-Bean Tacos</td>\n      <td>[\"1 teaspoon olive oil\", \"1 cup diced onion\", ...</td>\n      <td>[\"Heat oil in a large skillet over medium-high...</td>\n      <td>Medium (20-40 mins)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hearty Hamburger Soup</td>\n      <td>[\"900.0 gs lean ground beef\", \"1 white onion, ...</td>\n      <td>[\"Brown ground beef and onion in a large pot. ...</td>\n      <td>Slow (40-90 mins)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Sweet Potato Brotchen (Bread Rolls)</td>\n      <td>[\"450 g sweet potatoes\", \"15 g butter or olive...</td>\n      <td>[\"Peel and cut sweet potatoes into chunks.\", \"...</td>\n      <td>Very slow (90+ mins)</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Green Cleaner and Bug Repellant in One (Concen...</td>\n      <td>[\"1 tablespoon essential oil (part)\", \"3 table...</td>\n      <td>[\"Mix all ingredients.\", \"Store in a glass jar...</td>\n      <td>Medium (20-40 mins)</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Chocolate Chip Pie</td>\n      <td>[\"1 graham cracker crust\", \"20 large marshmall...</td>\n      <td>[\"Make crust (I buy the prepared ones from the...</td>\n      <td>Slow (40-90 mins)</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Poppy Seed Dressing</td>\n      <td>[\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...</td>\n      <td>[\"Combine first 6 ingredients in a blender con...</td>\n      <td>Very fast (0-10 mins)</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Scallop Ceviche</td>\n      <td>[\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...</td>\n      <td>[\"Bring a pot of water to a boil, salt the wat...</td>\n      <td>Fast (10-20 mins)</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:58:56.242361800Z",
     "start_time": "2025-05-16T21:58:55.569579900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "\n",
    "# Converte la colonna da stringhe a liste Python vere e proprie\n",
    "df['NER_clean'] = df['NER'].apply(ast.literal_eval)\n",
    "\n",
    "# Appiattisce tutte le liste in un'unica lista di ingredienti\n",
    "all_ner = [item.strip().lower() for sublist in df['NER_clean'] for item in sublist]\n",
    "\n",
    "# Rimuove duplicati e ordina\n",
    "unique_ingredients = sorted(set(all_ner))\n",
    "\n",
    "# Crea un DataFrame\n",
    "df_unique_ingredients = pd.DataFrame(unique_ingredients, columns=['Ingredient'])\n",
    "\n",
    "#df_unique_ingredients"
   ],
   "id": "637704cd639f1e51",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# 1. Carica prezzi e normalizza le chiavi\n",
    "prices_df = pd.read_csv('ingredients_prices')  # Assicurati dell'estensione .csv\n",
    "price_dict = {k.strip().lower(): v for k, v in prices_df.set_index('Ingredient')['Cost'].items()}\n",
    "\n",
    "# 2. Conversione unità → kg\n",
    "UNIT_CONVERSION = {\n",
    "    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\n",
    "    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\n",
    "    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\n",
    "    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\n",
    "    'can': 0.4, 'carton': 1.0,\n",
    "    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\n",
    "    'kg': 1.0, 'kilogram': 1.0,\n",
    "    'lb': 0.4536, 'pound': 0.4536,\n",
    "    'oz': 0.02835, 'ounce': 0.02835,\n",
    "    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\n",
    "}\n",
    "\n",
    "# 3. Parsing function (qty, unit, name, grams_in_paren)\n",
    "def parse_ingredient(ing_str):\n",
    "    # peso fra parentesi\n",
    "    m = re.search(r'\\(\\s*([0-9]+(?:\\.[0-9]+)?)\\s*g\\.?\\s*\\)', ing_str, re.IGNORECASE)\n",
    "    grams = float(m.group(1)) if m else None\n",
    "\n",
    "    # quantity e unit\n",
    "    patt = r'^\\s*([\\d\\/.\\s]+)?\\s*([a-zA-Z\\.]+)?'\n",
    "    m2 = re.match(patt, ing_str)\n",
    "    qty_raw = m2.group(1) if m2 else None\n",
    "    try:\n",
    "        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\n",
    "    except:\n",
    "        qty = 1.0\n",
    "    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\n",
    "\n",
    "    # name pulito\n",
    "    name = re.sub(r'\\(.*?\\)|optional', '', ing_str, flags=re.IGNORECASE)\n",
    "    # rimuovo quantità/unità\n",
    "    name = re.sub(r'^[\\d\\/.\\s]+\\s*[a-zA-Z\\.]*', '', name).strip().lower()\n",
    "    return qty, unit, name, grams\n",
    "\n",
    "# 4. Calcolo posizionale con fallback substring e token\n",
    "def calculate_recipe_cost_positional(ingredients_list, ner_list):\n",
    "    total = 0.0\n",
    "    missing = []\n",
    "\n",
    "    for ing_str, ner_item in zip(ingredients_list, ner_list):\n",
    "        key = ner_item.lower()\n",
    "        qty, unit, name, grams = parse_ingredient(ing_str)\n",
    "\n",
    "        # scorporo se passo i grams\n",
    "        if grams is not None:\n",
    "            kg = (grams / 1000) * qty\n",
    "        elif unit == '':  # a pezzo\n",
    "            # prendo prezzo direct key\n",
    "            price = price_dict.get(key)\n",
    "            # fallback substring/token\n",
    "            if price is None:\n",
    "                # substring match\n",
    "                for k, v in price_dict.items():\n",
    "                    if k in key or key in k:\n",
    "                        price = v\n",
    "                        break\n",
    "                # token match\n",
    "                if price is None:\n",
    "                    for token in key.split():\n",
    "                        if token in price_dict:\n",
    "                            price = price_dict[token]\n",
    "                            break\n",
    "            if price:\n",
    "                total += qty * price\n",
    "            else:\n",
    "                missing.append(key)\n",
    "            continue\n",
    "        else:\n",
    "            conv = UNIT_CONVERSION.get(unit, 0.0)\n",
    "            if conv == 0:\n",
    "                missing.append(key)\n",
    "                continue\n",
    "            kg = qty * conv\n",
    "\n",
    "        # prezzo per kg\n",
    "        price = price_dict.get(key)\n",
    "        if price is None:\n",
    "            for k, v in price_dict.items():\n",
    "                if k in key or key in k:\n",
    "                    price = v\n",
    "                    break\n",
    "        if price is None:\n",
    "            missing.append(key)\n",
    "            continue\n",
    "\n",
    "        total += kg * price\n",
    "\n",
    "    return round(total, 2), missing\n",
    "\n",
    "# 5. Applica al DataFrame\n",
    "    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "def compute_cost_row(row):\n",
    "     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\n",
    "     return cost\n",
    "\n",
    "def categorize_cost(total_cost):\n",
    "    if total_cost == 0:\n",
    "        return 'Not specified'\n",
    "    elif total_cost < 10:\n",
    "        return 'Very cheap'\n",
    "    elif 10 <= total_cost < 20:\n",
    "        return 'Cheap'\n",
    "    elif 20 <= total_cost < 45:\n",
    "        return 'Medium'\n",
    "    elif 45 <= total_cost < 90:\n",
    "        return 'Expensive'\n",
    "    else:\n",
    "        return 'Rich'\n",
    "\n",
    "df['total_cost'] = df.apply(compute_cost_row, axis=1)\n",
    "\n",
    "df['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\n",
    "\n",
    "# Mostra risultati\n",
    "df[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T21:59:01.358041700Z",
     "start_time": "2025-05-16T21:58:56.253887300Z"
    }
   },
   "id": "b4b4981d552d3aac",
   "outputs": [
    {
     "data": {
      "text/plain": "                                           INGREDIENTS  \\\n0    [\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...   \n1    [\"1 (6 ounce) can tuna, drained and flaked\", \"...   \n2    [\"1 tablespoon olive oil\", \"1 medium onion , c...   \n3    [\"1 teaspoon olive oil\", \"1 cup diced onion\", ...   \n4    [\"900.0 gs lean ground beef\", \"1 white onion, ...   \n..                                                 ...   \n195  [\"450 g sweet potatoes\", \"15 g butter or olive...   \n196  [\"1 tablespoon essential oil (part)\", \"3 table...   \n197  [\"1 graham cracker crust\", \"20 large marshmall...   \n198  [\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...   \n199  [\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...   \n\n                                                   NER CATEGORY_COST  \n0    [\"eggs\", \"milk\", \"sugar\", \"vanilla\", \"gallon w...     Expensive  \n1    [\"tuna\", \"mayonnaise\", \"low-fat sour cream\", \"...        Medium  \n2    [\"olive oil\", \"onion\", \"garlic\", \"salt\", \"grou...        Medium  \n3    [\"olive oil\", \"onion\", \"red bell pepper\", \"gre...     Expensive  \n4    [\"lean ground beef\", \"white onion\", \"ground bl...          Rich  \n..                                                 ...           ...  \n195  [\"sweet potatoes\", \"butter\", \"salt\", \"flour\", ...        Medium  \n196          [\"essential oil\", \"vodka\", \"liquid soap\"]        Medium  \n197  [\"graham cracker crust\", \"marshmallows\", \"milk...        Medium  \n198  [\"sugar\", \"dry mustard\", \"salt\", \"vinegar\", \"o...     Expensive  \n199  [\"scallops\", \"Salt\", \"ginger\", \"garlic\", \"stal...        Medium  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INGREDIENTS</th>\n      <th>NER</th>\n      <th>CATEGORY_COST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[\"16 eggs, beaten\", \"6 -8 evaporated milk, 360...</td>\n      <td>[\"eggs\", \"milk\", \"sugar\", \"vanilla\", \"gallon w...</td>\n      <td>Expensive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[\"1 (6 ounce) can tuna, drained and flaked\", \"...</td>\n      <td>[\"tuna\", \"mayonnaise\", \"low-fat sour cream\", \"...</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[\"1 tablespoon olive oil\", \"1 medium onion , c...</td>\n      <td>[\"olive oil\", \"onion\", \"garlic\", \"salt\", \"grou...</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[\"1 teaspoon olive oil\", \"1 cup diced onion\", ...</td>\n      <td>[\"olive oil\", \"onion\", \"red bell pepper\", \"gre...</td>\n      <td>Expensive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[\"900.0 gs lean ground beef\", \"1 white onion, ...</td>\n      <td>[\"lean ground beef\", \"white onion\", \"ground bl...</td>\n      <td>Rich</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>[\"450 g sweet potatoes\", \"15 g butter or olive...</td>\n      <td>[\"sweet potatoes\", \"butter\", \"salt\", \"flour\", ...</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>[\"1 tablespoon essential oil (part)\", \"3 table...</td>\n      <td>[\"essential oil\", \"vodka\", \"liquid soap\"]</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>[\"1 graham cracker crust\", \"20 large marshmall...</td>\n      <td>[\"graham cracker crust\", \"marshmallows\", \"milk...</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>[\"0.75 c. sugar\", \"2 tsp. dry mustard\", \"2 tsp...</td>\n      <td>[\"sugar\", \"dry mustard\", \"salt\", \"vinegar\", \"o...</td>\n      <td>Expensive</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>[\"1 pound sea scallops\", \"Salt\", \"1 cup choppe...</td>\n      <td>[\"scallops\", \"Salt\", \"ginger\", \"garlic\", \"stal...</td>\n      <td>Medium</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T21:59:01.479840800Z",
     "start_time": "2025-05-16T21:59:01.357041300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il file CSV\n",
    "vegan_df = pd.read_csv('ingredients_prices')\n",
    "\n",
    "# Pulizia degli ingredienti (rimuovi prefissi speciali)\n",
    "vegan_df['Ingredient'] = vegan_df['Ingredient'].str.replace(r'^[s+()\\\\.\",:/-]+\\s*', '', regex=True)\n",
    "\n",
    "# Lista di parole chiave non vegane\n",
    "NON_VEGAN_KEYWORDS = {\n",
    "    'milk', 'cheese', 'butter', 'cream', 'yogurt', 'gelatin', 'lard', 'honey',\n",
    "    'egg', 'eggs', 'fish', 'meat', 'chicken', 'beef', 'pork', 'gelatina',\n",
    "    'collagen', 'casein', 'whey', 'lactose', 'ghee', 'isinglass', 'carmine',\n",
    "    'shellac', 'albumen', 'pepsin', 'royal jelly', 'propolis', 'cocoa butter'\n",
    "}\n",
    "\n",
    "VEGAN_EXCEPTIONS = {\n",
    "    'milk': {'soy', 'almond', 'oat', 'rice', 'coconut', 'cashew', 'hazelnut'},\n",
    "    'cheese': {'vegan', 'nutritional yeast', 'cashew', 'tofu'},\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'butter': {'vegan', 'plant', 'peanut', 'almond', 'soy'},\n",
    "    'cream': {'coconut', 'soy', 'oat', 'vegan'}\n",
    "}\n",
    "\n",
    "VEGAN_MODIFIERS = {\n",
    "    'vegan', 'vegetale', 'plant-based', 'senza latte', 'senza uova',\n",
    "    'dairy-free', 'senza derivati animali', 'cruelty-free', '100% vegetale'\n",
    "}\n",
    "\n",
    "def contains_vegan_exception(ingredient, keyword):\n",
    "    exceptions = VEGAN_EXCEPTIONS.get(keyword, set())\n",
    "    return any(re.search(rf'\\b{ex}\\b', ingredient, re.IGNORECASE) for ex in exceptions)\n",
    "\n",
    "# Funzione di classificazione\n",
    "def is_vegan(ingredient):\n",
    "    ingredient_lower = ingredient.lower()\n",
    "\n",
    "    # Controlla parole chiave non vegane\n",
    "    for keyword in NON_VEGAN_KEYWORDS:\n",
    "        if keyword in ingredient_lower:\n",
    "            return 'No'\n",
    "\n",
    "    # Eccezioni speciali\n",
    "    if 'margarine' in ingredient_lower and 'vegan' not in ingredient_lower:\n",
    "        return 'No'\n",
    "\n",
    "    if 'broth' in ingredient_lower and ('chicken' in ingredient_lower or 'beef' in ingredient_lower):\n",
    "        return 'No'\n",
    "\n",
    "    return 'Yes'\n",
    "\n",
    "# Applica la classificazione\n",
    "vegan_df['Vegan'] = vegan_df['Ingredient'].apply(is_vegan)\n",
    "\n",
    "vegan_df"
   ],
   "id": "6a891063014b4502",
   "outputs": [
    {
     "data": {
      "text/plain": "                Ingredient  Cost Vegan\n0      A Cassell Courtyard   8.0   Yes\n1               A heartfol   8.0   Yes\n2                     A.P.   8.0   Yes\n3                     ABCs   8.0   Yes\n4      Abates tomato sauce   8.0   Yes\n...                    ...   ...   ...\n25693              zuckini   8.0   Yes\n25694                 zuke   8.0   Yes\n25695             zwieback   8.0   Yes\n25696    zwieback crackers   8.0   Yes\n25697      zwieback crumbs   8.0   Yes\n\n[25698 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ingredient</th>\n      <th>Cost</th>\n      <th>Vegan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A Cassell Courtyard</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A heartfol</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A.P.</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ABCs</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abates tomato sauce</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25693</th>\n      <td>zuckini</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>25694</th>\n      <td>zuke</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>25695</th>\n      <td>zwieback</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>25696</th>\n      <td>zwieback crackers</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>25697</th>\n      <td>zwieback crumbs</td>\n      <td>8.0</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>25698 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 10\n",
      "Label range: 0 - 9\n",
      "Classes: ['Dairy' 'Fat/Oil' 'Fruit' 'Grain' 'Meat' 'Other' 'Seafood' 'Spice'\n",
      " 'Sweetener' 'Vegetable']\n",
      "Labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/378537 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a28eb6a17ab44a0f8a9fc275fcef8f82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\akasa\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 9 at dim 1 (got 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 89\u001B[39m\n\u001B[32m     74\u001B[39m training_args = TrainingArguments(\n\u001B[32m     75\u001B[39m     output_dir=\u001B[33m\"\u001B[39m\u001B[33m./results\u001B[39m\u001B[33m\"\u001B[39m,  \u001B[38;5;66;03m# Add an output directory\u001B[39;00m\n\u001B[32m     76\u001B[39m     per_device_train_batch_size=\u001B[32m16\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     80\u001B[39m     disable_tqdm=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     81\u001B[39m )\n\u001B[32m     83\u001B[39m trainer = Trainer(\n\u001B[32m     84\u001B[39m     model=model,\n\u001B[32m     85\u001B[39m     args=training_args,\n\u001B[32m     86\u001B[39m     train_dataset=tokenized_dataset\n\u001B[32m     87\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[38;5;66;03m# ---------- 7. Save final model and labels ----------\u001B[39;00m\n\u001B[32m     92\u001B[39m model_path = \u001B[33m\"\u001B[39m\u001B[33mingredient_classifier_model\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\trainer.py:2514\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2512\u001B[39m update_step += \u001B[32m1\u001B[39m\n\u001B[32m   2513\u001B[39m num_batches = args.gradient_accumulation_steps \u001B[38;5;28;01mif\u001B[39;00m update_step != (total_updates - \u001B[32m1\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m remainder\n\u001B[32m-> \u001B[39m\u001B[32m2514\u001B[39m batch_samples, num_items_in_batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_batch_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_batches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2515\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(batch_samples):\n\u001B[32m   2516\u001B[39m     step += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\trainer.py:5243\u001B[39m, in \u001B[36mTrainer.get_batch_samples\u001B[39m\u001B[34m(self, epoch_iterator, num_batches, device)\u001B[39m\n\u001B[32m   5241\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_batches):\n\u001B[32m   5242\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m5243\u001B[39m         batch_samples.append(\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m   5244\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m   5245\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\accelerate\\data_loader.py:451\u001B[39m, in \u001B[36mDataLoaderShard.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    449\u001B[39m \u001B[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001B[39;00m\n\u001B[32m    450\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m451\u001B[39m     current_batch = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    452\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    453\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\data\\data_collator.py:93\u001B[39m, in \u001B[36mdefault_data_collator\u001B[39m\u001B[34m(features, return_tensors)\u001B[39m\n\u001B[32m     87\u001B[39m \u001B[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001B[39;00m\n\u001B[32m     88\u001B[39m \u001B[38;5;66;03m# have the same attributes.\u001B[39;00m\n\u001B[32m     89\u001B[39m \u001B[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001B[39;00m\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# on the whole batch.\u001B[39;00m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_tensors == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_default_data_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     94\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m return_tensors == \u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m tf_default_data_collator(features)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\data\\data_collator.py:159\u001B[39m, in \u001B[36mtorch_default_data_collator\u001B[39m\u001B[34m(features)\u001B[39m\n\u001B[32m    157\u001B[39m             batch[k] = torch.from_numpy(np.stack([f[k] \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m features]))\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m159\u001B[39m             batch[k] = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m batch\n",
      "\u001B[31mValueError\u001B[39m: expected sequence of length 9 at dim 1 (got 10)"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# ---------- 1. Category Rules ----------\n",
    "CATEGORY_RULES = {\n",
    "    \"Meat\": [\"bacon\", \"beef\", \"chicken\", \"ham\", \"turkey\", \"liver\", \"hamburger\", \"pancetta\", \"prosciutto\"],\n",
    "    \"Seafood\": [\"shrimp\", \"tuna\", \"anchovy\", \"salmon\"],\n",
    "    \"Vegetable\": [\"onion\", \"garlic\", \"lettuce\", \"carrot\", \"pepper\", \"tomato\", \"potato\", \"celery\", \"scallion\", \"bean sprouts\"],\n",
    "    \"Fruit\": [\"lemon\", \"banana\", \"orange\", \"raisins\", \"apple\", \"avocado\"],\n",
    "    \"Grain\": [\"flour\", \"cornmeal\", \"tortilla\", \"rice\", \"bread\", \"wafer\", \"cake\", \"noodles\", \"linguine\", \"rolls\"],\n",
    "    \"Dairy\": [\"milk\", \"cheese\", \"butter\", \"sour cream\", \"cream cheese\", \"parmesan\", \"whiz\", \"pecorino\"],\n",
    "    \"Fat/Oil\": [\"olive oil\", \"vegetable oil\", \"sunflower oil\", \"margarine\", \"sesame oil\"],\n",
    "    \"Spice\": [\"salt\", \"pepper\", \"cinnamon\", \"nutmeg\", \"ginger\", \"paprika\", \"oregano\", \"thyme\", \"sage\", \"cayenne\"],\n",
    "    \"Sweetener\": [\"sugar\", \"molasses\", \"honey\", \"chocolate\", \"syrup\"],\n",
    "    \"Other\": []\n",
    "}\n",
    "\n",
    "# ---------- 2. Ingredient Classification from DataFrame ----------\n",
    "def extract_ingredients_and_categories(df, column=\"NER\"):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            items = ast.literal_eval(row[column])\n",
    "        except Exception:\n",
    "            continue  # skip malformed rows\n",
    "        for item in items:\n",
    "            item_lower = item.lower()\n",
    "            matched = False\n",
    "            for category, keywords in CATEGORY_RULES.items():\n",
    "                if any(k in item_lower for k in keywords):\n",
    "                    data.append({\"ingredient\": item.strip(), \"category\": category})\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                data.append({\"ingredient\": item.strip(), \"category\": \"Other\"})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ---------- 3. Load and process your CSV ----------\n",
    "df = pd.read_csv(\"dataset_1.csv\")  # your original dataset\n",
    "ingredient_df = extract_ingredients_and_categories(df)  # expanded dataset\n",
    "\n",
    "# ---------- 4. Label encoding ----------\n",
    "label_encoder = LabelEncoder()\n",
    "ingredient_df[\"category\"] = ingredient_df[\"category\"].astype(str)\n",
    "label_encoder.fit(ingredient_df[\"category\"])\n",
    "ingredient_df[\"label\"] = label_encoder.transform(ingredient_df[\"category\"])\n",
    "\n",
    "# Debug info\n",
    "print(f\"Number of categories: {len(label_encoder.classes_)}\")\n",
    "print(f\"Label range: {ingredient_df['label'].min()} - {ingredient_df['label'].max()}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "print(f\"Labels: {sorted(ingredient_df['label'].unique())}\")\n",
    "\n",
    "# ---------- 5. Prepare HuggingFace dataset ----------\n",
    "dataset = Dataset.from_pandas(ingredient_df[[\"ingredient\", \"label\"]])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"ingredient\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# ---------- 6. Load model ----------\n",
    "# FIX: Explicitly set num_labels parameter to match the actual number of classes\n",
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels-1\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Add an output directory\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ---------- 7. Save final model and labels ----------\n",
    "model_path = \"ingredient_classifier_model\"\n",
    "label_mapping_path = \"category_labels.txt\"\n",
    "\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "with open(label_mapping_path, \"w\") as f:\n",
    "    for i, c in enumerate(label_encoder.classes_):\n",
    "        f.write(f\"{i},{c}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T22:55:39.803234800Z",
     "start_time": "2025-05-16T22:55:29.843908600Z"
    }
   },
   "id": "9f2639d0b8b5276a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground beef          ➜ Vegetable\n",
      "sugar                ➜ Vegetable\n",
      "cheddar cheese       ➜ Vegetable\n",
      "fresh basil          ➜ Vegetable\n",
      "shrimp               ➜ Vegetable\n",
      "coconut milk         ➜ Vegetable\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_path = \"ingredient_classifier_model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load label mapping\n",
    "label_map = {}\n",
    "with open(\"category_labels.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        idx, label = line.strip().split(\",\", 1)\n",
    "        label_map[int(idx)] = label\n",
    "\n",
    "# Function to classify one ingredient\n",
    "def classify_ingredient(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return label_map[prediction]\n",
    "\n",
    "# Example usage\n",
    "ingredients = [\n",
    "    \"ground beef\",\n",
    "    \"sugar\",\n",
    "    \"cheddar cheese\",\n",
    "    \"fresh basil\",\n",
    "    \"shrimp\",\n",
    "    \"coconut milk\"\n",
    "]\n",
    "\n",
    "for ing in ingredients:\n",
    "    category = classify_ingredient(ing)\n",
    "    print(f\"{ing:20} ➜ {category}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T22:15:27.023746800Z",
     "start_time": "2025-05-16T22:15:26.853172500Z"
    }
   },
   "id": "50dfb9223c408200"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 87\u001B[39m\n\u001B[32m     83\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28msum\u001B[39m(MEDIAN_PRICES.get(categorize_ingredient(ing), \u001B[32m3.00\u001B[39m)\n\u001B[32m     84\u001B[39m                      \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m valid_ingredients), \u001B[32m2\u001B[39m)\n\u001B[32m     86\u001B[39m \u001B[38;5;66;03m# Process recipes\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mtotal_cost\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mNER\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_recipe_cost\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[38;5;66;03m# Dynamic price categorization\u001B[39;00m\n\u001B[32m     90\u001B[39m costs = df[\u001B[33m'\u001B[39m\u001B[33mtotal_cost\u001B[39m\u001B[33m'\u001B[39m].values\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4922\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4923\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1508\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1509\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36mcalculate_recipe_cost\u001B[39m\u001B[34m(ingredients)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Cost calculation with validation\"\"\"\u001B[39;00m\n\u001B[32m     82\u001B[39m valid_ingredients = [ing \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m ingredients \u001B[38;5;28;01mif\u001B[39;00m ing.strip()]\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mMEDIAN_PRICES\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcategorize_ingredient\u001B[49m\u001B[43m(\u001B[49m\u001B[43ming\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m3.00\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m                 \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ming\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalid_ingredients\u001B[49m\u001B[43m)\u001B[49m, \u001B[32m2\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Cost calculation with validation\"\"\"\u001B[39;00m\n\u001B[32m     82\u001B[39m valid_ingredients = [ing \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m ingredients \u001B[38;5;28;01mif\u001B[39;00m ing.strip()]\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28msum\u001B[39m(MEDIAN_PRICES.get(\u001B[43mcategorize_ingredient\u001B[49m\u001B[43m(\u001B[49m\u001B[43ming\u001B[49m\u001B[43m)\u001B[49m, \u001B[32m3.00\u001B[39m)\n\u001B[32m     84\u001B[39m                  \u001B[38;5;28;01mfor\u001B[39;00m ing \u001B[38;5;129;01min\u001B[39;00m valid_ingredients), \u001B[32m2\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 72\u001B[39m, in \u001B[36mcategorize_ingredient\u001B[39m\u001B[34m(ingredient)\u001B[39m\n\u001B[32m     69\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m classification_cache[cleaned]\n\u001B[32m     71\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m     result = \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcleaned\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCATEGORIES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_label\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     73\u001B[39m     category = result[\u001B[33m'\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m'\u001B[39m][\u001B[32m0\u001B[39m]\n\u001B[32m     74\u001B[39m     classification_cache[cleaned] = category\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:206\u001B[39m, in \u001B[36mZeroShotClassificationPipeline.__call__\u001B[39m\u001B[34m(self, sequences, *args, **kwargs)\u001B[39m\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnable to understand extra arguments \u001B[39m\u001B[38;5;132;01m{\u001B[39;00margs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1371\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1369\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[32m   1370\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ChunkPipeline):\n\u001B[32m-> \u001B[39m\u001B[32m1371\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m   1372\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   1373\u001B[39m             \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   1374\u001B[39m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001B[32m   1375\u001B[39m             )\n\u001B[32m   1376\u001B[39m         )\n\u001B[32m   1377\u001B[39m     )\n\u001B[32m   1378\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1379\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001B[39m, in \u001B[36mPipelineIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    121\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_item()\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m item = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.iterator)\n\u001B[32m    125\u001B[39m processed = \u001B[38;5;28mself\u001B[39m.infer(item, **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    126\u001B[39m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001B[39m, in \u001B[36mPipelinePackIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    266\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m accumulator\n\u001B[32m    268\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_last:\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m     processed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    270\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    271\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed, torch.Tensor):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1286\u001B[39m, in \u001B[36mPipeline.forward\u001B[39m\u001B[34m(self, model_inputs, **forward_params)\u001B[39m\n\u001B[32m   1284\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[32m   1285\u001B[39m         model_inputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_inputs, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m-> \u001B[39m\u001B[32m1286\u001B[39m         model_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1287\u001B[39m         model_outputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m   1288\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:229\u001B[39m, in \u001B[36mZeroShotClassificationPipeline._forward\u001B[39m\u001B[34m(self, inputs)\u001B[39m\n\u001B[32m    227\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect.signature(model_forward).parameters.keys():\n\u001B[32m    228\u001B[39m     model_inputs[\u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m229\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m model_outputs = {\n\u001B[32m    232\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcandidate_label\u001B[39m\u001B[33m\"\u001B[39m: candidate_label,\n\u001B[32m    233\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33msequence\u001B[39m\u001B[33m\"\u001B[39m: sequence,\n\u001B[32m    234\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mis_last\u001B[39m\u001B[33m\"\u001B[39m: inputs[\u001B[33m\"\u001B[39m\u001B[33mis_last\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    235\u001B[39m     **outputs,\n\u001B[32m    236\u001B[39m }\n\u001B[32m    237\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model_outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1775\u001B[39m, in \u001B[36mBartForSequenceClassification.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1770\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[32m   1772\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPassing input embeddings is currently not supported for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1773\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1776\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1777\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1778\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1779\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1780\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1781\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1782\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1783\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1784\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1785\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1786\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1787\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1788\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1790\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1791\u001B[39m hidden_states = outputs[\u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# last hidden state\u001B[39;00m\n\u001B[32m   1793\u001B[39m eos_mask = input_ids.eq(\u001B[38;5;28mself\u001B[39m.config.eos_token_id).to(hidden_states.device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1515\u001B[39m, in \u001B[36mBartModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1512\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m   1514\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m encoder_outputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1515\u001B[39m     encoder_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1516\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1517\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1518\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1519\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1520\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1521\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1523\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1524\u001B[39m \u001B[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001B[39;00m\n\u001B[32m   1525\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, BaseModelOutput):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1113\u001B[39m, in \u001B[36mBartEncoder.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1105\u001B[39m         layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m   1106\u001B[39m             encoder_layer.\u001B[34m__call__\u001B[39m,\n\u001B[32m   1107\u001B[39m             hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1110\u001B[39m             output_attentions,\n\u001B[32m   1111\u001B[39m         )\n\u001B[32m   1112\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1113\u001B[39m         layer_outputs = \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1115\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1116\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1117\u001B[39m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1118\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1120\u001B[39m     hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1122\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:566\u001B[39m, in \u001B[36mBartEncoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    554\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    555\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m    556\u001B[39m \u001B[33;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    563\u001B[39m \u001B[33;03m        returned tensors for more detail.\u001B[39;00m\n\u001B[32m    564\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    565\u001B[39m residual = hidden_states\n\u001B[32m--> \u001B[39m\u001B[32m566\u001B[39m hidden_states, attn_weights, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    568\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    569\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    570\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    571\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    572\u001B[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001B[38;5;28mself\u001B[39m.dropout, training=\u001B[38;5;28mself\u001B[39m.training)\n\u001B[32m    573\u001B[39m hidden_states = residual + hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:473\u001B[39m, in \u001B[36mBartSdpaAttention.forward\u001B[39m\u001B[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    470\u001B[39m     value_states = torch.cat([past_key_value[\u001B[32m1\u001B[39m], value_states], dim=\u001B[32m2\u001B[39m)\n\u001B[32m    471\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    472\u001B[39m     \u001B[38;5;66;03m# self_attention\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m     key_states = \u001B[38;5;28mself\u001B[39m._shape(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m, -\u001B[32m1\u001B[39m, bsz)\n\u001B[32m    474\u001B[39m     value_states = \u001B[38;5;28mself\u001B[39m._shape(\u001B[38;5;28mself\u001B[39m.v_proj(hidden_states), -\u001B[32m1\u001B[39m, bsz)\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_decoder:\n\u001B[32m    477\u001B[39m     \u001B[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001B[39;00m\n\u001B[32m    478\u001B[39m     \u001B[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    482\u001B[39m     \u001B[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001B[39;00m\n\u001B[32m    483\u001B[39m     \u001B[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FOO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "data = {'NER': [\n",
    "    [\"eggs\", \"milk\", \"sugar\", \"vanilla\", \"gallon water\", \"dinner rolls\", \"cinnamon roll\"],\n",
    "    [\"tuna\", \"mayonnaise\", \"low-fat sour cream\", \"bacon bits\", \"dill\", \"salt\"],\n",
    "    [\"olive oil\", \"onion\", \"garlic\", \"salt\", \"ground black pepper\", \"tomatoes\",\n",
    "     \"tomatoes\", \"ricotta cheese\", \"Parmesan cheese\", \"fresh basil\", \"egg\", \"salt\",\n",
    "     \"ground black pepper\", \"lasagna noodles\", \"mozzarella\", \"mushrooms\"],\n",
    "    [\"olive oil\", \"onion\", \"red bell pepper\", \"green bell pepper\", \"chili powder\",\n",
    "     \"oregano\", \"ground cumin\", \"garlic\", \"garbanzo beans\", \"black beans\", \"pinto beans\",\n",
    "     \"tomato sauce\", \"taco\", \"shredded iceberg lettuce\", \"tomato\", \"cheddar cheese\", \"salsa\"]\n",
    "]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Food categories and prices\n",
    "CATEGORIES = [\n",
    "    \"dairy\", \"meat\", \"seafood\", \"grain\", \"vegetable\",\n",
    "    \"fruit\", \"spice/herb\", \"processed\", \"sweetener\",\n",
    "    \"condiment\", \"legume\", \"oil/fat\"\n",
    "]\n",
    "\n",
    "MEDIAN_PRICES = {\n",
    "    \"dairy\": 3.00,       # Milk, cheese (per kg)\n",
    "    \"meat\": 8.00,        # Chicken, beef (per kg)\n",
    "    \"seafood\": 12.00,    # Fish, shrimp (per kg)\n",
    "    \"grain\": 2.00,       # Flour, rice (per kg)\n",
    "    \"vegetable\": 1.50,   # Onions, garlic (per kg)\n",
    "    \"fruit\": 2.00,       # Tomatoes, bananas (per kg)\n",
    "    \"spice/herb\": 15.00, # Vanilla, cinnamon (per kg)\n",
    "    \"processed\": 5.00,   # Pasta, canned goods (per kg)\n",
    "    \"sweetener\": 1.80,   # Sugar (per kg)\n",
    "    \"condiment\": 4.00,   # Mayo, dressings (per kg)\n",
    "    \"legume\": 2.50,      # Beans, lentils (per kg)\n",
    "    \"oil/fat\": 6.00      # Olive oil (per kg)\n",
    "}\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"valhalla/distilbart-mnli-12-3\",\n",
    "    device=0,  # Requires CUDA-enabled environment\n",
    "    torch_dtype=torch.float16  # Enable mixed precision\n",
    ")\n",
    "\n",
    "classification_cache = {}\n",
    "\n",
    "# Improved cleaning function\n",
    "def clean_ingredient(ingredient):\n",
    "    \"\"\"More conservative cleaning\"\"\"\n",
    "    # Remove quantities like \"1/2 cup\" or \"200g\"\n",
    "    cleaned = re.sub(r'\\b\\d+[\\d/\\.°]*\\s*(\\w+)?\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    # Remove special characters but keep spaces\n",
    "    cleaned = re.sub(r'[^\\w\\s]', '', cleaned).strip().lower()\n",
    "    return cleaned if cleaned else \"unknown_ingredient\"\n",
    "\n",
    "def categorize_ingredient(ingredient):\n",
    "    \"\"\"Safe classification with error handling\"\"\"\n",
    "    cleaned = clean_ingredient(ingredient)\n",
    "\n",
    "    if not cleaned or cleaned == \"unknown_ingredient\":\n",
    "        return \"processed\"  # Default category\n",
    "\n",
    "    if cleaned in classification_cache:\n",
    "        return classification_cache[cleaned]\n",
    "\n",
    "    try:\n",
    "        result = classifier(cleaned, CATEGORIES, multi_label=False)\n",
    "        category = result['labels'][0]\n",
    "        classification_cache[cleaned] = category\n",
    "        return category\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying '{cleaned}': {str(e)}\")\n",
    "        return \"processed\"\n",
    "\n",
    "def calculate_recipe_cost(ingredients):\n",
    "    \"\"\"Cost calculation with validation\"\"\"\n",
    "    valid_ingredients = [ing for ing in ingredients if ing.strip()]\n",
    "    return round(sum(MEDIAN_PRICES.get(categorize_ingredient(ing), 3.00)\n",
    "                     for ing in valid_ingredients), 2)\n",
    "\n",
    "# Process recipes\n",
    "df['total_cost'] = df['NER'].apply(calculate_recipe_cost)\n",
    "\n",
    "# Dynamic price categorization\n",
    "costs = df['total_cost'].values\n",
    "q33, q66 = np.percentile(costs, [33, 66]) if len(costs) > 0 else (0, 0)\n",
    "\n",
    "def price_category(cost):\n",
    "    if cost <= q33: return 'cheap'\n",
    "    elif cost <= q66: return 'medium'\n",
    "    return 'expensive'\n",
    "\n",
    "\n",
    "df['price_tag'] = df['total_cost'].apply(price_category)\n",
    "\n",
    "\n",
    "ingredient_df = pd.DataFrame.from_dict(classification_cache,\n",
    "                                       orient='index',\n",
    "                                       columns=['category']).reset_index()\n",
    "ingredient_df.columns = ['ingredient', 'category']\n",
    "\n",
    "# Add vegan/vegetarian tags\n",
    "VEGAN_UNSAFE = {'meat', 'seafood', 'dairy', 'egg'}\n",
    "VEGETARIAN_UNSAFE = {'meat', 'seafood'}\n",
    "\n",
    "# ingredient_df['vegan'] = ~ingredient_df['category'].isin(VEGAN_UNSAFE)\n",
    "# ingredient_df['vegetarian'] = ~ingredient_df['category'].isin(VEGETARIAN_UNSAFE)\n",
    "\n",
    "# Save comprehensive dataset\n",
    "ingredient_df.to_csv('ingredient_categories.csv', index=False)\n",
    "\n",
    "# Display sample\n",
    "print(\"Ingredient Categories with Dietary Tags:\")\n",
    "print(ingredient_df.sample(5))\n",
    "\n",
    "df[['NER', 'total_cost', 'price_tag']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T00:12:17.649122400Z",
     "start_time": "2025-05-17T00:11:24.788088Z"
    }
   },
   "id": "8c3fb8ce3efc3060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4190c03acb0a826"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
