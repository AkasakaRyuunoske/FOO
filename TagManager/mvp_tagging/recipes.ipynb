{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:18.800346500Z",
     "start_time": "2025-05-21T20:36:18.225643300Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File and create a new dataframe called 'df'\n",
    "# df = pd.read_csv('dataset_1.csv')\n",
    "df = pd.read_csv('recipies_dataset_tagged_chunk_12%')\n",
    "\n",
    "# Removing useless columns\n",
    "df = df.drop(columns = ['Unnamed: 0', 'link', 'source'])\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                                       title  \\\n0                        Chocolate Chip Cake   \n1                           Cheesy Ham Rolls   \n2            Light(Er) Cajun Chicken Alfredo   \n3      No Bubbles! Easy Mentsuyu Chawanmushi   \n4            Neiman Marcus Tuna Pecan Salad    \n...                                      ...   \n44618      Light Wheat Sandwich Bread Recipe   \n44619                   Low-Fat Corn Pudding   \n44620                           Greek Salata   \n44621                      Spicy Peanut Soup   \n44622   Mache, Pomegranate, and Walnut Salad   \n\n                                             ingredients  \\\n0      [\"1/2 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...   \n1      [\"16 ounces green beans, Canned Whole\", \"1 lb ...   \n2      [\"3 boneless skinless chicken breasts (1lb)\", ...   \n3      [\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...   \n4      [\"3 cans (6 oz. each) chunk white albacore tun...   \n...                                                  ...   \n44618  [\"1 cup warm water (about 110A F)\", \"2 14 teas...   \n44619  [\"2 cups uncooked corn kernels (from about 4 e...   \n44620  [\"1/2 head lettuce\", \"1/2 bunch radishes, thin...   \n44621  [\"1 tablespoon vegetable oil\", \"1 large onion,...   \n44622  [\"1 pomegranate\", \"1/2 teaspoon sugar\", \"1/2 t...   \n\n                                              directions  \\\n0      [\"Cream butter and sugar.\", \"Add all other ing...   \n1      [\"Drain green beans WELL. (I've used reg.cut &...   \n2      [\"Place chicken and blackening spice or Cajun ...   \n3      [\"Note: check how much the steaming containers...   \n4      [\"In a large bowl, lightly break up the tuna w...   \n...                                                  ...   \n44618  [\"In large mixing bowl, combine warm water and...   \n44619  [\"Preheat the oven to 350 degrees. Have ready ...   \n44620  [\"Tear the lettuce into bite size pieces. Toss...   \n44621  [\"In a large saucepan, heat vegetable oil to m...   \n44622  [\"Halve pomegranate crosswise and reserve 2 ta...   \n\n                                                     NER difficulty     time  \\\n0      [\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...       Hard    Quick   \n1      [\"green beans\", \"ham slices\", \"butter\", \"flour...       Hard    Quick   \n2      [\"chicken breasts\", \"fresh linguine\", \"blacken...       Hard  Average   \n3      [\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...       Hard    Quick   \n4      [\"white albacore\", \"celery\", \"water chestnuts\"...       Hard  Average   \n...                                                  ...        ...      ...   \n44618  [\"warm water\", \"active dry yeast\", \"honey\", \"s...       Hard     Slow   \n44619  [\"corn kernels\", \"flour\", \"sugar\", \"kosher sal...       Hard    Quick   \n44620  [\"head lettuce\", \"radishes\", \"green onions\", \"...       Hard  Average   \n44621  [\"vegetable oil\", \"onion\", \"sweet potato\", \"ga...       Hard    Quick   \n44622  [\"pomegranate\", \"sugar\", \"red-wine vinegar\", \"...       Hard  Average   \n\n            cost method  \n0          Cheap   Bake  \n1          Cheap   Bake  \n2          Cheap   Boil  \n3          Cheap  Fried  \n4          Cheap  Other  \n...          ...    ...  \n44618      Cheap   Bake  \n44619      Cheap   Bake  \n44620  Expensive  Other  \n44621      Cheap   Boil  \n44622  Expensive  Other  \n\n[44623 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>NER</th>\n      <th>difficulty</th>\n      <th>time</th>\n      <th>cost</th>\n      <th>method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chocolate Chip Cake</td>\n      <td>[\"1/2 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...</td>\n      <td>[\"Cream butter and sugar.\", \"Add all other ing...</td>\n      <td>[\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...</td>\n      <td>Hard</td>\n      <td>Quick</td>\n      <td>Cheap</td>\n      <td>Bake</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cheesy Ham Rolls</td>\n      <td>[\"16 ounces green beans, Canned Whole\", \"1 lb ...</td>\n      <td>[\"Drain green beans WELL. (I've used reg.cut &amp;...</td>\n      <td>[\"green beans\", \"ham slices\", \"butter\", \"flour...</td>\n      <td>Hard</td>\n      <td>Quick</td>\n      <td>Cheap</td>\n      <td>Bake</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Light(Er) Cajun Chicken Alfredo</td>\n      <td>[\"3 boneless skinless chicken breasts (1lb)\", ...</td>\n      <td>[\"Place chicken and blackening spice or Cajun ...</td>\n      <td>[\"chicken breasts\", \"fresh linguine\", \"blacken...</td>\n      <td>Hard</td>\n      <td>Average</td>\n      <td>Cheap</td>\n      <td>Boil</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Bubbles! Easy Mentsuyu Chawanmushi</td>\n      <td>[\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...</td>\n      <td>[\"Note: check how much the steaming containers...</td>\n      <td>[\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...</td>\n      <td>Hard</td>\n      <td>Quick</td>\n      <td>Cheap</td>\n      <td>Fried</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neiman Marcus Tuna Pecan Salad</td>\n      <td>[\"3 cans (6 oz. each) chunk white albacore tun...</td>\n      <td>[\"In a large bowl, lightly break up the tuna w...</td>\n      <td>[\"white albacore\", \"celery\", \"water chestnuts\"...</td>\n      <td>Hard</td>\n      <td>Average</td>\n      <td>Cheap</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44618</th>\n      <td>Light Wheat Sandwich Bread Recipe</td>\n      <td>[\"1 cup warm water (about 110A F)\", \"2 14 teas...</td>\n      <td>[\"In large mixing bowl, combine warm water and...</td>\n      <td>[\"warm water\", \"active dry yeast\", \"honey\", \"s...</td>\n      <td>Hard</td>\n      <td>Slow</td>\n      <td>Cheap</td>\n      <td>Bake</td>\n    </tr>\n    <tr>\n      <th>44619</th>\n      <td>Low-Fat Corn Pudding</td>\n      <td>[\"2 cups uncooked corn kernels (from about 4 e...</td>\n      <td>[\"Preheat the oven to 350 degrees. Have ready ...</td>\n      <td>[\"corn kernels\", \"flour\", \"sugar\", \"kosher sal...</td>\n      <td>Hard</td>\n      <td>Quick</td>\n      <td>Cheap</td>\n      <td>Bake</td>\n    </tr>\n    <tr>\n      <th>44620</th>\n      <td>Greek Salata</td>\n      <td>[\"1/2 head lettuce\", \"1/2 bunch radishes, thin...</td>\n      <td>[\"Tear the lettuce into bite size pieces. Toss...</td>\n      <td>[\"head lettuce\", \"radishes\", \"green onions\", \"...</td>\n      <td>Hard</td>\n      <td>Average</td>\n      <td>Expensive</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>44621</th>\n      <td>Spicy Peanut Soup</td>\n      <td>[\"1 tablespoon vegetable oil\", \"1 large onion,...</td>\n      <td>[\"In a large saucepan, heat vegetable oil to m...</td>\n      <td>[\"vegetable oil\", \"onion\", \"sweet potato\", \"ga...</td>\n      <td>Hard</td>\n      <td>Quick</td>\n      <td>Cheap</td>\n      <td>Boil</td>\n    </tr>\n    <tr>\n      <th>44622</th>\n      <td>Mache, Pomegranate, and Walnut Salad</td>\n      <td>[\"1 pomegranate\", \"1/2 teaspoon sugar\", \"1/2 t...</td>\n      <td>[\"Halve pomegranate crosswise and reserve 2 ta...</td>\n      <td>[\"pomegranate\", \"sugar\", \"red-wine vinegar\", \"...</td>\n      <td>Hard</td>\n      <td>Average</td>\n      <td>Expensive</td>\n      <td>Other</td>\n    </tr>\n  </tbody>\n</table>\n<p>44623 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:18.803348900Z",
     "start_time": "2025-05-21T20:36:18.779853700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_fractions(text):\n",
    "    \"\"\"Defining a method that convert fractions\"\"\"\n",
    "    # Match optional whole number + fraction, or just fraction\n",
    "    pattern = r'(?:(\\d+)\\s+)?(\\d+)/(\\d+)'\n",
    "\n",
    "    def replacer(match):\n",
    "        whole = int(match.group(1)) if match.group(1) else 0\n",
    "        numerator = int(match.group(2))\n",
    "        denominator = int(match.group(3))\n",
    "        decimal = whole + Fraction(numerator, denominator)\n",
    "        return \"{:.10g}\".format(float(decimal))  # Clean, no trailing zeros\n",
    "\n",
    "    return re.sub(pattern, replacer, text)"
   ],
   "id": "f6177b908ebf022c",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:25.045458100Z",
     "start_time": "2025-05-21T20:36:18.787347100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "# Fixed conversions\n",
    "CONVERSIONS = {\n",
    "    \"oz\": 30,      # ounce â†’ gram\n",
    "    \"lb\": 450,      # pounds â†’ gram\n",
    "    \"pt\": 475,      # pint â†’ milliliter\n",
    "    \"qt\": 950,      # quart â†’ milliliter\n",
    "    \"inch\": 2.5        # inches â†’ centimeter\n",
    "}\n",
    "\n",
    "def convert_units(text):\n",
    "    \"\"\"Defining a method that converts units by using the fixed conversions\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # Convert oz, lb, pt, qt (form: \"4 oz\", \"2.5 lb\", etc.)\n",
    "    for unit, factor in CONVERSIONS.items():\n",
    "        pattern = r'(\\d+(\\.\\d+)?)\\s*' + unit\n",
    "        text = re.sub(pattern, lambda m: f\"{round(float(m.group(1)) * factor, 1)} {unit_to_metric(unit)}\", text)\n",
    "\n",
    "    # Convert measure in inches in pans\n",
    "    text = re.sub(r'(\\d+)\\s*x\\s*(\\d+)[-\\s]*inch', lambda\n",
    "        m: f\"{int(m.group(1)) * CONVERSIONS['inch']:.0f} x {int(m.group(2)) * CONVERSIONS['inch']:.0f} cm\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_fahrenheit_to_celsius(text):\n",
    "    # Match degrees like 275Â°, 275 Â°F, 275\\u00b0F (escaped), etc.\n",
    "    pattern = r'(\\d+)\\s*(?:Â°|\\\\u00b0)'\n",
    "\n",
    "    def replacer(match):\n",
    "        fahrenheit = int(match.group(1))\n",
    "        celsius = round((fahrenheit - 32) * 5 / 9)\n",
    "        return f\"{celsius}Â°C\"\n",
    "\n",
    "    return re.sub(pattern, replacer, text)\n",
    "\n",
    "def unit_to_metric(unit):\n",
    "    return {\n",
    "        \"oz\": \"g\",\n",
    "        \"lb\": \"g\",\n",
    "        \"pt\": \"ml\",\n",
    "        \"qt\": \"ml\",\n",
    "        \"inch\": \"cm\"\n",
    "    }[unit]\n",
    "\n",
    "# Applying conversions on the INGREDIENTS and DIRECTIONS columns\n",
    "df['INGREDIENTS'] = df['ingredients'].apply(convert_fractions)\n",
    "df['DIRECTIONS'] = df['directions'].apply(convert_fractions)\n",
    "\n",
    "df['INGREDIENTS'] = df['INGREDIENTS'].apply(convert_units)\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_units)\n",
    "\n",
    "df['DIRECTIONS'] = df['DIRECTIONS'].apply(convert_fahrenheit_to_celsius)\n",
    "\n",
    "# Renaming the title column and dropping the converted columns\n",
    "df = df.rename(columns={\"title\": \"TITLE\"})\n",
    "df = df.drop(['ingredients', 'directions'], axis=1)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS']].head(200)"
   ],
   "id": "35a1e5c191694098",
   "outputs": [
    {
     "data": {
      "text/plain": "                                     TITLE  \\\n0                      Chocolate Chip Cake   \n1                         Cheesy Ham Rolls   \n2          Light(Er) Cajun Chicken Alfredo   \n3    No Bubbles! Easy Mentsuyu Chawanmushi   \n4          Neiman Marcus Tuna Pecan Salad    \n..                                     ...   \n195             Laura'S Famous Cheese Ball   \n196                         Ginger Muffins   \n197               Stuffing For Slow Cooker   \n198                           Marbled Eggs   \n199        Vickys Banana Cinnamon Pancakes   \n\n                                           INGREDIENTS  \\\n0    [\"0.5 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...   \n1    [\"16 ounces green beans, Canned Whole\", \"450.0...   \n2    [\"3 boneless skinless chicken breasts (450.0 g...   \n3    [\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...   \n4    [\"3 cans (180.0 g. each) chunk white albacore ...   \n..                                                 ...   \n195  [\"1 (240.0 g.) pkg. cream cheese\", \"1 small pk...   \n196  [\"1.5 cups flour\", \"2 teaspoons baking powder\"...   \n197  [\"1 c. water and 2 bouillon cubes or broth\", \"...   \n198  [\"3 medium-size fresh beets, peeled and thinly...   \n199  [\"158 grams (1 cup) rice flour\", \"120 grams (1...   \n\n                                            DIRECTIONS  \n0    [\"Cream butter and sugar.\", \"Add all other ing...  \n1    [\"Drain green beans WELL. (I've used reg.cut &...  \n2    [\"Place chicken and blackening spice or Cajun ...  \n3    [\"Note: check how much the steaming containers...  \n4    [\"In a large bowl, lightly break up the tuna w...  \n..                                                 ...  \n195  [\"In a large bowl, combine semi-softened chees...  \n196  [\"Thoroughly combine first 5 ingredients.\", \"C...  \n197  [\"Cook on high for 1 hour, then on low.\", \"The...  \n198  [\"Bring beets, water, vinegar, sugar, salt, on...  \n199  [\"Lightly grease a frying pan with olive oil o...  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>INGREDIENTS</th>\n      <th>DIRECTIONS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chocolate Chip Cake</td>\n      <td>[\"0.5 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...</td>\n      <td>[\"Cream butter and sugar.\", \"Add all other ing...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cheesy Ham Rolls</td>\n      <td>[\"16 ounces green beans, Canned Whole\", \"450.0...</td>\n      <td>[\"Drain green beans WELL. (I've used reg.cut &amp;...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Light(Er) Cajun Chicken Alfredo</td>\n      <td>[\"3 boneless skinless chicken breasts (450.0 g...</td>\n      <td>[\"Place chicken and blackening spice or Cajun ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Bubbles! Easy Mentsuyu Chawanmushi</td>\n      <td>[\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...</td>\n      <td>[\"Note: check how much the steaming containers...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neiman Marcus Tuna Pecan Salad</td>\n      <td>[\"3 cans (180.0 g. each) chunk white albacore ...</td>\n      <td>[\"In a large bowl, lightly break up the tuna w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Laura'S Famous Cheese Ball</td>\n      <td>[\"1 (240.0 g.) pkg. cream cheese\", \"1 small pk...</td>\n      <td>[\"In a large bowl, combine semi-softened chees...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Ginger Muffins</td>\n      <td>[\"1.5 cups flour\", \"2 teaspoons baking powder\"...</td>\n      <td>[\"Thoroughly combine first 5 ingredients.\", \"C...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Stuffing For Slow Cooker</td>\n      <td>[\"1 c. water and 2 bouillon cubes or broth\", \"...</td>\n      <td>[\"Cook on high for 1 hour, then on low.\", \"The...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Marbled Eggs</td>\n      <td>[\"3 medium-size fresh beets, peeled and thinly...</td>\n      <td>[\"Bring beets, water, vinegar, sugar, salt, on...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Vickys Banana Cinnamon Pancakes</td>\n      <td>[\"158 grams (1 cup) rice flour\", \"120 grams (1...</td>\n      <td>[\"Lightly grease a frying pan with olive oil o...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:27.425735400Z",
     "start_time": "2025-05-21T20:36:25.048459300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# Patterns to detect time expressions\n",
    "TIME_PATTERN = re.compile(\n",
    "    r'(\\d+(?:\\.\\d+)?)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h|day|days|d)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "RANGE_PATTERN = re.compile(\n",
    "    r'(\\d+)\\s*-\\s*(\\d+)\\s*(minute|minutes|min|mins|m|hour|hours|hr|hrs|h)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Time estimates for common preparation methods\n",
    "PREP_ESTIMATES = {\n",
    "    'bake': 45, 'boil': 20, 'fry': 15, 'grill': 25, 'chill': 120,\n",
    "    'simmer': 30, 'marinate': 60, 'microwave': 10, 'no-bake': 20,\n",
    "    'refrigerate': 180, 'freeze': 240\n",
    "}\n",
    "\n",
    "# Special cases for recipe types\n",
    "RECIPE_TYPE_ESTIMATES = {\n",
    "    'pasta': 10, 'salad': 15, 'cake': 45, 'pie': 60, 'stew': 120,\n",
    "    'casserole': 60, 'soup': 30, 'cookies': 30, 'bread': 90,\n",
    "    'fudge': 20, 'candy': 30\n",
    "}\n",
    "\n",
    "def convert_to_minutes(qty, unit):\n",
    "    \"\"\"Converts time quantity to minutes.\"\"\"\n",
    "    qty = float(qty)\n",
    "    unit = unit.lower()\n",
    "    if unit.startswith('m'): return qty\n",
    "    if unit.startswith('h'): return qty * 60\n",
    "    if unit.startswith('d'): return qty * 1440\n",
    "    return 0\n",
    "\n",
    "def estimate_by_recipe_type(title, ingredients):\n",
    "    \"\"\"Fallback estimation based on recipe title or ingredients.\"\"\"\n",
    "    title = str(title).lower()\n",
    "    ingredients = str(ingredients).lower()\n",
    "\n",
    "    # Check for specific recipe types\n",
    "    for keyword, est in RECIPE_TYPE_ESTIMATES.items():\n",
    "        if keyword in title:\n",
    "            return est\n",
    "\n",
    "    if any(word in ingredients for word in ['raw', 'fresh']):\n",
    "        return 15\n",
    "    if 'frozen' in ingredients:\n",
    "        return 20\n",
    "    if 'canned' in ingredients:\n",
    "        return 10\n",
    "\n",
    "    # Default fallback\n",
    "    return 30\n",
    "\n",
    "def clean_instruction_step(step):\n",
    "    \"\"\"Normalize range formats and identify special cases.\"\"\"\n",
    "    # Replace ranges (e.g., \"10-15 minutes\" â†’ \"15 minutes\")\n",
    "    step = RANGE_PATTERN.sub(lambda m: f\"{m.group(2)} {m.group(3)}\", step)\n",
    "\n",
    "    # Handle special keywords\n",
    "    lowered = step.lower()\n",
    "    if 'overnight' in lowered:\n",
    "        return 480\n",
    "    if 'until set' in lowered or 'until firm' in lowered:\n",
    "        return 60\n",
    "\n",
    "    # Sum all time expressions\n",
    "    return sum(\n",
    "        convert_to_minutes(qty, unit)\n",
    "        for qty, unit in TIME_PATTERN.findall(step)\n",
    "    )\n",
    "\n",
    "def parse_instructions(instructions):\n",
    "    \"\"\"Parses instructions and extracts total estimated time in minutes.\"\"\"\n",
    "    total_time = 0\n",
    "\n",
    "    if not isinstance(instructions, list):\n",
    "        try:\n",
    "            instructions = ast.literal_eval(str(instructions))\n",
    "        except:\n",
    "            instructions = [instructions]\n",
    "\n",
    "    for step in instructions:\n",
    "        if isinstance(step, str):\n",
    "            total_time += clean_instruction_step(step)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "def categorize_time(total_time):\n",
    "    \"\"\"Classify total time into labeled categories.\"\"\"\n",
    "    if total_time == 0:\n",
    "        return 'Not specified'\n",
    "    if total_time < 10:\n",
    "        return 'Very fast (0-10 mins)'\n",
    "    if total_time < 20:\n",
    "        return 'Fast (10-20 mins)'\n",
    "    if total_time < 40:\n",
    "        return 'Medium (20-40 mins)'\n",
    "    if total_time < 90:\n",
    "        return 'Slow (40-90 mins)'\n",
    "    return 'Very slow (90+ mins)'\n",
    "\n",
    "# Calculate total preparation time\n",
    "df['total_time'] = df['DIRECTIONS'].apply(parse_instructions)\n",
    "\n",
    "# Estimate time for unspecified recipes\n",
    "missing = df['total_time'] == 0\n",
    "df.loc[missing, 'total_time'] = df[missing].apply(\n",
    "    lambda row: estimate_by_recipe_type(row['TITLE'], row['INGREDIENTS']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Categorize preparation times\n",
    "df['PREPARATION_TIME'] = df['total_time'].apply(categorize_time)\n",
    "\n",
    "df[['TITLE', 'INGREDIENTS', 'DIRECTIONS', 'PREPARATION_TIME']].head(200)"
   ],
   "id": "4ca47d472c93a067",
   "outputs": [
    {
     "data": {
      "text/plain": "                                     TITLE  \\\n0                      Chocolate Chip Cake   \n1                         Cheesy Ham Rolls   \n2          Light(Er) Cajun Chicken Alfredo   \n3    No Bubbles! Easy Mentsuyu Chawanmushi   \n4          Neiman Marcus Tuna Pecan Salad    \n..                                     ...   \n195             Laura'S Famous Cheese Ball   \n196                         Ginger Muffins   \n197               Stuffing For Slow Cooker   \n198                           Marbled Eggs   \n199        Vickys Banana Cinnamon Pancakes   \n\n                                           INGREDIENTS  \\\n0    [\"0.5 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...   \n1    [\"16 ounces green beans, Canned Whole\", \"450.0...   \n2    [\"3 boneless skinless chicken breasts (450.0 g...   \n3    [\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...   \n4    [\"3 cans (180.0 g. each) chunk white albacore ...   \n..                                                 ...   \n195  [\"1 (240.0 g.) pkg. cream cheese\", \"1 small pk...   \n196  [\"1.5 cups flour\", \"2 teaspoons baking powder\"...   \n197  [\"1 c. water and 2 bouillon cubes or broth\", \"...   \n198  [\"3 medium-size fresh beets, peeled and thinly...   \n199  [\"158 grams (1 cup) rice flour\", \"120 grams (1...   \n\n                                            DIRECTIONS       PREPARATION_TIME  \n0    [\"Cream butter and sugar.\", \"Add all other ing...      Slow (40-90 mins)  \n1    [\"Drain green beans WELL. (I've used reg.cut &...    Medium (20-40 mins)  \n2    [\"Place chicken and blackening spice or Cajun ...      Fast (10-20 mins)  \n3    [\"Note: check how much the steaming containers...      Fast (10-20 mins)  \n4    [\"In a large bowl, lightly break up the tuna w...      Fast (10-20 mins)  \n..                                                 ...                    ...  \n195  [\"In a large bowl, combine semi-softened chees...    Medium (20-40 mins)  \n196  [\"Thoroughly combine first 5 ingredients.\", \"C...    Medium (20-40 mins)  \n197  [\"Cook on high for 1 hour, then on low.\", \"The...      Slow (40-90 mins)  \n198  [\"Bring beets, water, vinegar, sugar, salt, on...   Very slow (90+ mins)  \n199  [\"Lightly grease a frying pan with olive oil o...  Very fast (0-10 mins)  \n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>INGREDIENTS</th>\n      <th>DIRECTIONS</th>\n      <th>PREPARATION_TIME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chocolate Chip Cake</td>\n      <td>[\"0.5 c. butter or oleo\", \"1 c. sugar\", \"1 tsp...</td>\n      <td>[\"Cream butter and sugar.\", \"Add all other ing...</td>\n      <td>Slow (40-90 mins)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cheesy Ham Rolls</td>\n      <td>[\"16 ounces green beans, Canned Whole\", \"450.0...</td>\n      <td>[\"Drain green beans WELL. (I've used reg.cut &amp;...</td>\n      <td>Medium (20-40 mins)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Light(Er) Cajun Chicken Alfredo</td>\n      <td>[\"3 boneless skinless chicken breasts (450.0 g...</td>\n      <td>[\"Place chicken and blackening spice or Cajun ...</td>\n      <td>Fast (10-20 mins)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Bubbles! Easy Mentsuyu Chawanmushi</td>\n      <td>[\"2 Eggs\", \"280 ml Water\", \"3 tbsp of each Mir...</td>\n      <td>[\"Note: check how much the steaming containers...</td>\n      <td>Fast (10-20 mins)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neiman Marcus Tuna Pecan Salad</td>\n      <td>[\"3 cans (180.0 g. each) chunk white albacore ...</td>\n      <td>[\"In a large bowl, lightly break up the tuna w...</td>\n      <td>Fast (10-20 mins)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Laura'S Famous Cheese Ball</td>\n      <td>[\"1 (240.0 g.) pkg. cream cheese\", \"1 small pk...</td>\n      <td>[\"In a large bowl, combine semi-softened chees...</td>\n      <td>Medium (20-40 mins)</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Ginger Muffins</td>\n      <td>[\"1.5 cups flour\", \"2 teaspoons baking powder\"...</td>\n      <td>[\"Thoroughly combine first 5 ingredients.\", \"C...</td>\n      <td>Medium (20-40 mins)</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Stuffing For Slow Cooker</td>\n      <td>[\"1 c. water and 2 bouillon cubes or broth\", \"...</td>\n      <td>[\"Cook on high for 1 hour, then on low.\", \"The...</td>\n      <td>Slow (40-90 mins)</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Marbled Eggs</td>\n      <td>[\"3 medium-size fresh beets, peeled and thinly...</td>\n      <td>[\"Bring beets, water, vinegar, sugar, salt, on...</td>\n      <td>Very slow (90+ mins)</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Vickys Banana Cinnamon Pancakes</td>\n      <td>[\"158 grams (1 cup) rice flour\", \"120 grams (1...</td>\n      <td>[\"Lightly grease a frying pan with olive oil o...</td>\n      <td>Very fast (0-10 mins)</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "# Conversione unitÃ  â†’ kg\n",
    "UNIT_CONVERSION = {\n",
    "    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\n",
    "    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\n",
    "    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\n",
    "    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\n",
    "    'can': 0.4, 'carton': 1.0,\n",
    "    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\n",
    "    'kg': 1.0, 'kilogram': 1.0,\n",
    "    'lb': 0.4536, 'pound': 0.4536,\n",
    "    'oz': 0.02835, 'ounce': 0.02835,\n",
    "    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\n",
    "}\n",
    "\n",
    "# 3. Parsing function (qty, unit, name, grams_in_paren)\n",
    "def parse_ingredient(ing_str):\n",
    "    # peso fra parentesi\n",
    "    m = re.search(r'\\(\\s*([0-9]+(?:\\.[0-9]+)?)\\s*g\\.?\\s*\\)', ing_str, re.IGNORECASE)\n",
    "    grams = float(m.group(1)) if m else None\n",
    "\n",
    "    # quantity e unit\n",
    "    patt = r'^\\s*([\\d\\/.\\s]+)?\\s*([a-zA-Z\\.]+)?'\n",
    "    m2 = re.match(patt, ing_str)\n",
    "    qty_raw = m2.group(1) if m2 else None\n",
    "    try:\n",
    "        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\n",
    "    except:\n",
    "        qty = 1.0\n",
    "    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\n",
    "\n",
    "    # name pulito\n",
    "    name = re.sub(r'\\(.*?\\)|optional', '', ing_str, flags=re.IGNORECASE)\n",
    "    # rimuovo quantitÃ /unitÃ \n",
    "    name = re.sub(r'^[\\d\\/.\\s]+\\s*[a-zA-Z\\.]*', '', name).strip().lower()\n",
    "    return qty, unit, name, grams\n",
    "\n",
    "# 4. Calcolo posizionale con fallback substring e token\n",
    "def calculate_recipe_cost_positional(ingredients_list, ner_list):\n",
    "    total = 0.0\n",
    "    missing = []\n",
    "\n",
    "    for ing_str, ner_item in zip(ingredients_list, ner_list):\n",
    "        key = ner_item.lower()\n",
    "        qty, unit, name, grams = parse_ingredient(ing_str)\n",
    "\n",
    "        # scorporo se passo i grams\n",
    "        if grams is not None:\n",
    "            kg = (grams / 1000) * qty\n",
    "        elif unit == '':  # a pezzo\n",
    "            # prendo prezzo direct key\n",
    "            price = price_dict.get(key)\n",
    "            # fallback substring/token\n",
    "            if price is None:\n",
    "                # substring match\n",
    "                for k, v in price_dict.items():\n",
    "                    if k in key or key in k:\n",
    "                        price = v\n",
    "                        break\n",
    "                # token match\n",
    "                if price is None:\n",
    "                    for token in key.split():\n",
    "                        if token in price_dict:\n",
    "                            price = price_dict[token]\n",
    "                            break\n",
    "            if price:\n",
    "                total += qty * price\n",
    "            else:\n",
    "                missing.append(key)\n",
    "            continue\n",
    "        else:\n",
    "            conv = UNIT_CONVERSION.get(unit, 0.0)\n",
    "            if conv == 0:\n",
    "                missing.append(key)\n",
    "                continue\n",
    "            kg = qty * conv\n",
    "\n",
    "        # prezzo per kg\n",
    "        price = price_dict.get(key)\n",
    "        if price is None:\n",
    "            for k, v in price_dict.items():\n",
    "                if k in key or key in k:\n",
    "                    price = v\n",
    "                    break\n",
    "        if price is None:\n",
    "            missing.append(key)\n",
    "            continue\n",
    "\n",
    "        total += kg * price\n",
    "\n",
    "    return round(total, 2), missing\n",
    "\n",
    "# 5. Applica al DataFrame\n",
    "    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "def compute_cost_row(row):\n",
    "     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\n",
    "     return cost\n",
    "\n",
    "df['total_cost'] = df.apply(compute_cost_row, axis=1)\n",
    "\n",
    "df['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\n",
    "\n",
    "# Mostra risultati\n",
    "df[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)'''"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "potrebbe essere eliminata"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:27.432732900Z",
     "start_time": "2025-05-21T20:36:27.421218500Z"
    }
   },
   "id": "99c5e6f021ec1a8f",
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# Conversione unitÃ  â†’ kg\\nUNIT_CONVERSION = {\\n    'cup': 0.24, 'c.': 0.24, 'c': 0.24,\\n    'teaspoon': 0.005, 'tsp': 0.005, 'tsp.': 0.005,\\n    'tablespoon': 0.015, 'tbsp': 0.015, 'tbsp.': 0.015,\\n    'package': 0.2, 'pkg': 0.2, 'pkg.': 0.2,\\n    'can': 0.4, 'carton': 1.0,\\n    'g': 0.001, 'g.': 0.001, 'gram': 0.001,\\n    'kg': 1.0, 'kilogram': 1.0,\\n    'lb': 0.4536, 'pound': 0.4536,\\n    'oz': 0.02835, 'ounce': 0.02835,\\n    'large package': 0.5, 'large pkg.': 0.5, 'large pkg': 0.5\\n}\\n\\n# 3. Parsing function (qty, unit, name, grams_in_paren)\\ndef parse_ingredient(ing_str):\\n    # peso fra parentesi\\n    m = re.search(r'\\\\(\\\\s*([0-9]+(?:\\\\.[0-9]+)?)\\\\s*g\\\\.?\\\\s*\\\\)', ing_str, re.IGNORECASE)\\n    grams = float(m.group(1)) if m else None\\n\\n    # quantity e unit\\n    patt = r'^\\\\s*([\\\\d\\\\/.\\\\s]+)?\\\\s*([a-zA-Z\\\\.]+)?'\\n    m2 = re.match(patt, ing_str)\\n    qty_raw = m2.group(1) if m2 else None\\n    try:\\n        qty = eval(qty_raw.replace(' ', '+')) if qty_raw else 1.0\\n    except:\\n        qty = 1.0\\n    unit = (m2.group(2) or '').strip('.').lower() if m2 else ''\\n\\n    # name pulito\\n    name = re.sub(r'\\\\(.*?\\\\)|optional', '', ing_str, flags=re.IGNORECASE)\\n    # rimuovo quantitÃ /unitÃ \\n    name = re.sub(r'^[\\\\d\\\\/.\\\\s]+\\\\s*[a-zA-Z\\\\.]*', '', name).strip().lower()\\n    return qty, unit, name, grams\\n\\n# 4. Calcolo posizionale con fallback substring e token\\ndef calculate_recipe_cost_positional(ingredients_list, ner_list):\\n    total = 0.0\\n    missing = []\\n\\n    for ing_str, ner_item in zip(ingredients_list, ner_list):\\n        key = ner_item.lower()\\n        qty, unit, name, grams = parse_ingredient(ing_str)\\n\\n        # scorporo se passo i grams\\n        if grams is not None:\\n            kg = (grams / 1000) * qty\\n        elif unit == '':  # a pezzo\\n            # prendo prezzo direct key\\n            price = price_dict.get(key)\\n            # fallback substring/token\\n            if price is None:\\n                # substring match\\n                for k, v in price_dict.items():\\n                    if k in key or key in k:\\n                        price = v\\n                        break\\n                # token match\\n                if price is None:\\n                    for token in key.split():\\n                        if token in price_dict:\\n                            price = price_dict[token]\\n                            break\\n            if price:\\n                total += qty * price\\n            else:\\n                missing.append(key)\\n            continue\\n        else:\\n            conv = UNIT_CONVERSION.get(unit, 0.0)\\n            if conv == 0:\\n                missing.append(key)\\n                continue\\n            kg = qty * conv\\n\\n        # prezzo per kg\\n        price = price_dict.get(key)\\n        if price is None:\\n            for k, v in price_dict.items():\\n                if k in key or key in k:\\n                    price = v\\n                    break\\n        if price is None:\\n            missing.append(key)\\n            continue\\n\\n        total += kg * price\\n\\n    return round(total, 2), missing\\n\\n# 5. Applica al DataFrame\\n    df['INGREDIENTS'] = df['INGREDIENTS'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\\n    df['NER_clean']  = df['NER_clean'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\\n\\ndef compute_cost_row(row):\\n     cost, _ = calculate_recipe_cost_positional(row['INGREDIENTS'], row['NER_clean'])\\n     return cost\\n\\ndf['total_cost'] = df.apply(compute_cost_row, axis=1)\\n\\ndf['CATEGORY_COST'] = df['total_cost'].apply(categorize_cost)\\n\\n# Mostra risultati\\ndf[['INGREDIENTS', 'NER', 'CATEGORY_COST']].head(200)\""
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "df['NER_clean'] = df['NER'].apply(ast.literal_eval)\n",
    "\n",
    "# List containing keywords\n",
    "NON_VEGAN_KEYWORDS = {\n",
    "    'milk', 'cheese', 'butter', 'cream', 'yogurt', 'gelatin', 'lard', 'honey',\n",
    "    'egg', 'eggs', 'fish', 'meat', 'chicken', 'beef', 'pork', 'gelatina',\n",
    "    'collagen', 'casein', 'whey', 'lactose', 'ghee', 'isinglass', 'carmine',\n",
    "    'shellac', 'albumen', 'pepsin', 'royal jelly', 'propolis', 'cocoa butter',\n",
    "    'bacon', 'sour cream', 'condensed milk', 'shredded cheese', 'cheddar',\n",
    "    'paraffin', 'marshmallows', 'buttermilk', 'ground beef', 'steak', 'tuna'\n",
    "}\n",
    "\n",
    "VEGAN_EXCEPTIONS = {\n",
    "    'milk': {'soy', 'almond', 'oat', 'rice', 'coconut', 'cashew', 'hazelnut'},\n",
    "    'cheese': {'vegan', 'nutritional yeast', 'cashew', 'tofu'},\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'butter': {'vegan', 'plant', 'peanut', 'almond', 'soy'},\n",
    "    'cream': {'coconut', 'soy', 'oat', 'vegan'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'}\n",
    "}\n",
    "\n",
    "VEGAN_MODIFIERS = {\n",
    "    'vegan', 'vegetable', 'plant-based', 'no milk', 'no eggs',\n",
    "    'dairy-free', 'without animal derivatives', 'cruelty-free', '100% vegetable'\n",
    "}\n",
    "\n",
    "# --- Utility\n",
    "def parse_ingredients(ingredients_input):\n",
    "    \"\"\"Always returning a parsed list of ingredients\"\"\"\n",
    "    if isinstance(ingredients_input, list):\n",
    "        return ingredients_input\n",
    "    if isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "        try:\n",
    "            return ast.literal_eval(ingredients_input)\n",
    "        except:\n",
    "            return [\n",
    "                x.strip().strip('\"').strip(\"'\")\n",
    "                for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                if x.strip()\n",
    "            ]\n",
    "    return []\n",
    "\n",
    "def contains_vegan_exception(ingredient, keyword):\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE)\n",
    "               for ex in VEGAN_EXCEPTIONS.get(keyword, set()))\n",
    "\n",
    "# --- Classification\n",
    "def classify_vegan(ingredients_input):\n",
    "    \"\"\"Returning True or False based on the ingredients\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        if any(re.search(rf'\\b{re.escape(mod)}\\b', ing_lower) for mod in VEGAN_MODIFIERS):\n",
    "            continue\n",
    "        for keyword in NON_VEGAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegan_exception(ing_lower, keyword):\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def get_non_vegan_ingredients(ingredients_input):\n",
    "    \"\"\"Returning list of ingredients without vegan exceptions\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    non_vegan = []\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        for keyword in NON_VEGAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegan_exception(ing_lower, keyword):\n",
    "                    non_vegan.append(ing)\n",
    "                break\n",
    "    return non_vegan\n",
    "\n",
    "# --- Apply\n",
    "df['VEGAN'] = df['NER_clean'].apply(classify_vegan)\n",
    "df['NON_VEGAN_INGREDIENTS'] = df['NER_clean'].apply(get_non_vegan_ingredients)\n",
    "\n",
    "# --- Final validation\n",
    "anti_patterns = re.compile(\n",
    "    r'\\b(not vegan|meat|steak|fish|cheese|egg|eggs|beef|chicken|pork|bacon|cream)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "df['VEGAN'] = df.apply(\n",
    "    lambda row: False if row['VEGAN'] and isinstance(row['TITLE'], str) and anti_patterns.search(row['TITLE']) else row['VEGAN'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# View results\n",
    "df[['TITLE', 'NER', 'VEGAN', 'NON_VEGAN_INGREDIENTS']].head(200)"
   ],
   "metadata": {
    "collapsed": false,
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:36:46.788284700Z",
     "start_time": "2025-05-21T20:36:27.434733800Z"
    }
   },
   "id": "fd85d06e00f4b10c",
   "outputs": [
    {
     "data": {
      "text/plain": "                                     TITLE  \\\n0                      Chocolate Chip Cake   \n1                         Cheesy Ham Rolls   \n2          Light(Er) Cajun Chicken Alfredo   \n3    No Bubbles! Easy Mentsuyu Chawanmushi   \n4          Neiman Marcus Tuna Pecan Salad    \n..                                     ...   \n195             Laura'S Famous Cheese Ball   \n196                         Ginger Muffins   \n197               Stuffing For Slow Cooker   \n198                           Marbled Eggs   \n199        Vickys Banana Cinnamon Pancakes   \n\n                                                   NER  VEGAN  \\\n0    [\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...  False   \n1    [\"green beans\", \"ham slices\", \"butter\", \"flour...  False   \n2    [\"chicken breasts\", \"fresh linguine\", \"blacken...  False   \n3    [\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...  False   \n4    [\"white albacore\", \"celery\", \"water chestnuts\"...   True   \n..                                                 ...    ...   \n195  [\"cream cheese\", \"Cheddar cheese\", \"onion\", \"g...  False   \n196  [\"flour\", \"baking powder\", \"salt\", \"cinnamon\",...  False   \n197  [\"water\", \"egg\", \"onions\", \"lots of butter\", \"...  False   \n198  [\"fresh beets\", \"water\", \"apple cider vinegar\"...  False   \n199  [\"rice flour\", \"flour\", \"flour\", \"baking powde...   True   \n\n                                 NON_VEGAN_INGREDIENTS  \n0                           [butter, eggs, sour cream]  \n1                                       [butter, milk]  \n2    [chicken breasts, light cream, chicken broth, ...  \n3                       [Eggs, Chicken thigh, chicken]  \n4                                                   []  \n..                                                 ...  \n195         [cream cheese, Cheddar cheese, bacon bits]  \n196                                        [egg, milk]  \n197                              [egg, lots of butter]  \n198                                             [eggs]  \n199                                                 []  \n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>NER</th>\n      <th>VEGAN</th>\n      <th>NON_VEGAN_INGREDIENTS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chocolate Chip Cake</td>\n      <td>[\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...</td>\n      <td>False</td>\n      <td>[butter, eggs, sour cream]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cheesy Ham Rolls</td>\n      <td>[\"green beans\", \"ham slices\", \"butter\", \"flour...</td>\n      <td>False</td>\n      <td>[butter, milk]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Light(Er) Cajun Chicken Alfredo</td>\n      <td>[\"chicken breasts\", \"fresh linguine\", \"blacken...</td>\n      <td>False</td>\n      <td>[chicken breasts, light cream, chicken broth, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Bubbles! Easy Mentsuyu Chawanmushi</td>\n      <td>[\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...</td>\n      <td>False</td>\n      <td>[Eggs, Chicken thigh, chicken]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neiman Marcus Tuna Pecan Salad</td>\n      <td>[\"white albacore\", \"celery\", \"water chestnuts\"...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Laura'S Famous Cheese Ball</td>\n      <td>[\"cream cheese\", \"Cheddar cheese\", \"onion\", \"g...</td>\n      <td>False</td>\n      <td>[cream cheese, Cheddar cheese, bacon bits]</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Ginger Muffins</td>\n      <td>[\"flour\", \"baking powder\", \"salt\", \"cinnamon\",...</td>\n      <td>False</td>\n      <td>[egg, milk]</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Stuffing For Slow Cooker</td>\n      <td>[\"water\", \"egg\", \"onions\", \"lots of butter\", \"...</td>\n      <td>False</td>\n      <td>[egg, lots of butter]</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Marbled Eggs</td>\n      <td>[\"fresh beets\", \"water\", \"apple cider vinegar\"...</td>\n      <td>False</td>\n      <td>[eggs]</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Vickys Banana Cinnamon Pancakes</td>\n      <td>[\"rice flour\", \"flour\", \"flour\", \"baking powde...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "tags": [
     "Works"
    ],
    "ExecuteTime": {
     "end_time": "2025-05-21T20:37:00.463481400Z",
     "start_time": "2025-05-21T20:36:46.784767600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of non vegetarian ingredients\n",
    "NON_VEGETARIAN_KEYWORDS = {\n",
    "    'meat', 'chicken', 'beef', 'pork', 'fish', 'anchovy', 'tuna', 'salmon',\n",
    "    'shellfish', 'shrimp', 'crab', 'lobster', 'bacon', 'gelatin', 'lard',\n",
    "    'collagen', 'isinglass', 'pepsin', 'ground beef', 'steak', 'tuna'\n",
    "}\n",
    "\n",
    "# Exceptions for vegetarian subs\n",
    "VEGETARIAN_EXCEPTIONS = {\n",
    "    'meat': {'soy', 'seitan', 'tofu', 'tempeh', 'jackfruit', 'plant-based'},\n",
    "    'bacon': {'vegan', 'tempeh', 'coconut'},\n",
    "    'gelatin': {'agar', 'pectin'},\n",
    "    'fish': {'banana blossom', 'tofu', 'plant-based'}\n",
    "}\n",
    "\n",
    "VEGETARIAN_MODIFIERS = {\n",
    "    'vegetarian', 'veggie', 'plant-based', 'meatless', 'no meat',\n",
    "    'without meat', 'cruelty-free'\n",
    "}\n",
    "\n",
    "# --- Utility\n",
    "def parse_ingredients(ingredients_input):\n",
    "    \"\"\"Always returning a parsed list of ingredients\"\"\"\n",
    "    if isinstance(ingredients_input, list):\n",
    "        return ingredients_input\n",
    "    if isinstance(ingredients_input, str) and ingredients_input.strip():\n",
    "        try:\n",
    "            return ast.literal_eval(ingredients_input)\n",
    "        except:\n",
    "            return [\n",
    "                x.strip().strip('\"').strip(\"'\")\n",
    "                for x in re.split(r',(?![^[]*\\])', ingredients_input.strip('[]'))\n",
    "                if x.strip()\n",
    "            ]\n",
    "    return []\n",
    "\n",
    "def contains_vegetarian_exception(ingredient, keyword):\n",
    "    exceptions = VEGETARIAN_EXCEPTIONS.get(keyword, set())\n",
    "    return any(re.search(rf'\\b{re.escape(ex)}\\b', ingredient, re.IGNORECASE) for ex in exceptions)\n",
    "\n",
    "# --- Classification\n",
    "def classify_vegetarian(ingredients_input):\n",
    "    \"\"\"Returning True or False based on the ingredients\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        if any(re.search(rf'\\b{re.escape(mod)}\\b', ing_lower) for mod in VEGETARIAN_MODIFIERS):\n",
    "            continue\n",
    "        for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegetarian_exception(ing_lower, keyword):\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def get_non_vegetarian_ingredients(ingredients_input):\n",
    "    \"\"\"Returning list of ingredients without vegetarian exceptions\"\"\"\n",
    "    ingredients = parse_ingredients(ingredients_input)\n",
    "    non_vegetarian = []\n",
    "    for ing in ingredients:\n",
    "        if not isinstance(ing, str):\n",
    "            continue\n",
    "        ing_lower = ing.lower()\n",
    "        if any(skip in ing_lower for skip in ('water', 'salt')):\n",
    "            continue\n",
    "        for keyword in NON_VEGETARIAN_KEYWORDS:\n",
    "            if re.search(rf'\\b{re.escape(keyword)}(?:s)?\\b', ing_lower):\n",
    "                if not contains_vegetarian_exception(ing_lower, keyword):\n",
    "                    non_vegetarian.append(ing)\n",
    "                break\n",
    "    return non_vegetarian\n",
    "\n",
    "# Apply to dataframe\n",
    "df['VEGETARIAN'] = df['NER_clean'].apply(classify_vegetarian)\n",
    "df['NON_VEGETARIAN_INGREDIENTS'] = df['NER_clean'].apply(get_non_vegetarian_ingredients)\n",
    "\n",
    "anti_patterns = re.compile(\n",
    "    r'\\b(not vegetarian|not veg|meat|steak|fish|beef|chicken|pork|bacon)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "df['VEGETARIAN'] = df.apply(\n",
    "    lambda row: False if row['VEGETARIAN'] and isinstance(row['TITLE'], str) and anti_patterns.search(row['TITLE']) else row['VEGETARIAN'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show results\n",
    "df[['TITLE', 'NER', 'VEGETARIAN', 'NON_VEGETARIAN_INGREDIENTS']].head(200)"
   ],
   "id": "8813043f994e6a4e",
   "outputs": [
    {
     "data": {
      "text/plain": "                                     TITLE  \\\n0                      Chocolate Chip Cake   \n1                         Cheesy Ham Rolls   \n2          Light(Er) Cajun Chicken Alfredo   \n3    No Bubbles! Easy Mentsuyu Chawanmushi   \n4          Neiman Marcus Tuna Pecan Salad    \n..                                     ...   \n195             Laura'S Famous Cheese Ball   \n196                         Ginger Muffins   \n197               Stuffing For Slow Cooker   \n198                           Marbled Eggs   \n199        Vickys Banana Cinnamon Pancakes   \n\n                                                   NER  VEGETARIAN  \\\n0    [\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...        True   \n1    [\"green beans\", \"ham slices\", \"butter\", \"flour...        True   \n2    [\"chicken breasts\", \"fresh linguine\", \"blacken...       False   \n3    [\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...       False   \n4    [\"white albacore\", \"celery\", \"water chestnuts\"...        True   \n..                                                 ...         ...   \n195  [\"cream cheese\", \"Cheddar cheese\", \"onion\", \"g...       False   \n196  [\"flour\", \"baking powder\", \"salt\", \"cinnamon\",...        True   \n197  [\"water\", \"egg\", \"onions\", \"lots of butter\", \"...        True   \n198  [\"fresh beets\", \"water\", \"apple cider vinegar\"...        True   \n199  [\"rice flour\", \"flour\", \"flour\", \"baking powde...        True   \n\n           NON_VEGETARIAN_INGREDIENTS  \n0                                  []  \n1                                  []  \n2    [chicken breasts, chicken broth]  \n3            [Chicken thigh, chicken]  \n4                                  []  \n..                                ...  \n195                      [bacon bits]  \n196                                []  \n197                                []  \n198                                []  \n199                                []  \n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>NER</th>\n      <th>VEGETARIAN</th>\n      <th>NON_VEGETARIAN_INGREDIENTS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chocolate Chip Cake</td>\n      <td>[\"butter\", \"sugar\", \"vanilla\", \"eggs\", \"sour c...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cheesy Ham Rolls</td>\n      <td>[\"green beans\", \"ham slices\", \"butter\", \"flour...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Light(Er) Cajun Chicken Alfredo</td>\n      <td>[\"chicken breasts\", \"fresh linguine\", \"blacken...</td>\n      <td>False</td>\n      <td>[chicken breasts, chicken broth]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Bubbles! Easy Mentsuyu Chawanmushi</td>\n      <td>[\"Eggs\", \"Water\", \"Chicken thigh\", \"soy sauce\"...</td>\n      <td>False</td>\n      <td>[Chicken thigh, chicken]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neiman Marcus Tuna Pecan Salad</td>\n      <td>[\"white albacore\", \"celery\", \"water chestnuts\"...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Laura'S Famous Cheese Ball</td>\n      <td>[\"cream cheese\", \"Cheddar cheese\", \"onion\", \"g...</td>\n      <td>False</td>\n      <td>[bacon bits]</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Ginger Muffins</td>\n      <td>[\"flour\", \"baking powder\", \"salt\", \"cinnamon\",...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Stuffing For Slow Cooker</td>\n      <td>[\"water\", \"egg\", \"onions\", \"lots of butter\", \"...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Marbled Eggs</td>\n      <td>[\"fresh beets\", \"water\", \"apple cider vinegar\"...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Vickys Banana Cinnamon Pancakes</td>\n      <td>[\"rice flour\", \"flour\", \"flour\", \"baking powde...</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [
    "Qui inizia la magia:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "345918a28f5a9fc0"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpu = torch.cuda.get_device_name(0)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {gpu}\")\n",
    "\n",
    "# Eseguire questa cella solo se runnata dal Barone\n",
    "if gpu == \"NVIDIA GeForce RTX 3060 Ti\":\n",
    "    classifier = pipeline(\n",
    "        task=\"zero-shot-classification\",\n",
    "        model=\"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\",\n",
    "        device=0,\n",
    "        torch_dtype=torch.float16,\n",
    "        model_kwargs={\"cache_dir\": \"./cache\"},\n",
    "        batch_size=32,  # Optimal for RTX 3060 Ti\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # %% Data Loading\n",
    "    df['NER'] = df['NER'].apply(eval)  # Convert string lists to actual lists\n",
    "    \n",
    "    # %% Food Categories & Prices (EUR/kg)\n",
    "    CATEGORIES = [\n",
    "        \"dairy\", \"meat\", \"seafood\", \"grain\", \"vegetable\",\n",
    "        \"fruit\", \"spice/herb\", \"processed\", \"sweetener\",\n",
    "        \"condiment\", \"legume\", \"oil/fat\"\n",
    "    ]\n",
    "    \n",
    "    MEDIAN_PRICES = {\n",
    "        \"dairy\": 3.50,       # Milk, cheese\n",
    "        \"meat\": 7.50,        # Chicken, beef\n",
    "        \"seafood\": 12.00,    # Fish, shrimp\n",
    "        \"grain\": 2.20,       # Flour, rice\n",
    "        \"vegetable\": 1.80,   # Onions, garlic\n",
    "        \"fruit\": 2.50,       # Tomatoes, bananas\n",
    "        \"spice/herb\": 18.00, # Vanilla, cinnamon\n",
    "        \"processed\": 4.50,   # Pasta, canned goods\n",
    "        \"sweetener\": 2.20,   # Sugar\n",
    "        \"condiment\": 5.00,   # Mayo, dressings\n",
    "        \"legume\": 3.00,      # Beans, lentils\n",
    "        \"oil/fat\": 8.00      # Olive oil\n",
    "    }\n",
    "    \n",
    "    # %% Ingredient Cleaning (Fixed)\n",
    "    def clean_ingredient(ingredient: str) -> str:\n",
    "        \"\"\"Conservative cleaning preserving ingredient names\"\"\"\n",
    "        # Remove quantities (e.g., \"200g\", \"1/2 cup\")\n",
    "        cleaned = re.sub(r'\\b\\d+[\\d/\\.]*\\s*[a-z]*\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "        # Remove special chars except spaces\n",
    "        cleaned = re.sub(r'[^\\w\\s]', '', cleaned).strip().lower()\n",
    "        return cleaned if cleaned else \"unknown\"\n",
    "    \n",
    "    # %% Batch Classification (GPU-optimized)\n",
    "    classification_cache = {}\n",
    "    \n",
    "    def batch_classify(ingredients: list, batch_size: int = 16) -> dict:  # Reduced batch size\n",
    "        unique_ingredients = list(set(ingredients))\n",
    "    \n",
    "        with torch.no_grad():  # Disable gradient tracking\n",
    "            for batch in tqdm([unique_ingredients[i:i+batch_size]\n",
    "                               for i in range(0, len(unique_ingredients), batch_size)],\n",
    "                              desc=\"Classifying Ingredients\"):\n",
    "                # Process batch on GPU\n",
    "                results = classifier(batch, CATEGORIES, multi_label=False)\n",
    "    \n",
    "                # Cache results\n",
    "                for ing, result in zip(batch, results):\n",
    "                    classification_cache[ing] = result['labels'][0]\n",
    "    \n",
    "                # Clear GPU cache\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "        return classification_cache\n",
    "    \n",
    "    # %% Process Entire Dataset\n",
    "    # Get all unique ingredients\n",
    "    all_ingredients = [clean_ingredient(ing)\n",
    "                       for recipe in df['NER']\n",
    "                       for ing in recipe]\n",
    "    unique_ingredients = list(set(all_ingredients))\n",
    "    \n",
    "    # Batch classify with progress bar\n",
    "    _ = batch_classify(unique_ingredients, batch_size=64)\n",
    "    \n",
    "    # Calculate recipe costs\n",
    "    df['total_cost'] = df['NER'].apply(\n",
    "        lambda x: round(sum(\n",
    "            MEDIAN_PRICES.get(classification_cache[clean_ingredient(ing)], 3.00)\n",
    "            for ing in x\n",
    "        ), 2)\n",
    "    )\n",
    "    \n",
    "    # Dynamic price categorization\n",
    "    costs = df['total_cost'].values\n",
    "    \n",
    "    # threshold per le categorie degli prezzi\n",
    "    very_cheap, cheap, medium, expensive = np.percentile(costs, [20, 40, 60, 85])\n",
    "    \n",
    "    df['price_tag'] = df['total_cost'].apply(\n",
    "        lambda x: 'very cheap' if x <= very_cheap\n",
    "        else 'cheap' if x <= cheap\n",
    "        else 'medium' if x <= medium\n",
    "        else 'expensive' if x <= expensive\n",
    "        else 'rich'\n",
    "    )\n",
    "\n",
    "    def get_categories(ingredient_list):\n",
    "        return [classification_cache.get(ing) for ing in ingredient_list]\n",
    "    \n",
    "    def is_vegan(cat_list):\n",
    "        return all(cat not in ['dairy', 'meat', 'seafood'] for cat in cat_list if cat is not None)\n",
    "    \n",
    "    def is_vegetarian(cat_list):\n",
    "        return all(cat not in ['meat', 'seafood'] for cat in cat_list if cat is not None)\n",
    "    \n",
    "    df['categories'] = df['NER_clean'].apply(get_categories)\n",
    "    df['vegan'] = df['categories'].apply(is_vegan)\n",
    "    df['vegetarian'] = df['categories'].apply(is_vegetarian)\n",
    "    \n",
    "    # Save outputs\n",
    "    df.to_csv('full_tagged_dataset_10%', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-21T20:40:23.158053500Z",
     "start_time": "2025-05-21T20:37:38.119163800Z"
    }
   },
   "id": "6c57cbd4e0ba36f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Classifying Ingredients:   0%|          | 0/260 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Classifying Ingredients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [02:41<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "Qui la magia finisce :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eade76ff96b7ad22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'PREPARATION_TIME' e testing",
   "id": "f22b17441612ef05"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Method to preprocess a dataframe\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "# Method to train a classificator\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Saving model\n",
    "    model.save(f\"classifiers/prep_time/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/prep_time/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/prep_time/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === FIRST MODEL: PREPARATION_TIME ===\n",
    "df_time = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"PREPARATION_TIME\"]].copy()\n",
    "df_time, prep_time_encoder = preprocess(df_time, [\"INGREDIENTS\", \"DIRECTIONS\"], \"PREPARATION_TIME\")\n",
    "prep_time_model = train_text_classifier(df_time, prep_time_encoder, model_name_prefix=\"prep_time_classifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.288549Z"
    }
   },
   "id": "f4190c03acb0a826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.291549800Z",
     "start_time": "2025-05-21T20:20:50.289547700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "prep_time_model = load_model(\"classifiers/prep_time/prep_time_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/prep_time/prep_time_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    prep_time_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/prep_time/prep_time_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    prep_time_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_prep_time_label_map = {v: k for k, v in prep_time_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected time\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sautÃ© garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_time\": \"15 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_time\": \"10 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"SautÃ© the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_time\": \"30 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_time\": \"5 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, bÃ©chamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, bÃ©chamel and cheese. Bake at 180Â°C for 40 minutes.\",\n",
    "        \"expected_time\": \"60 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_time\": \"10 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_time\": \"25 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_time\": \"30 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_time\": \"20 min\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. SautÃ© onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_time\": \"90 min\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "prep_sequences = prep_time_tokenizer.texts_to_sequences(texts)\n",
    "prep_padded = pad_sequences(prep_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting time with probabilities\n",
    "prep_preds = prep_time_model.predict(prep_padded)\n",
    "prep_classes = prep_preds.argmax(axis=1)\n",
    "prep_labels = [inv_prep_time_label_map[c] for c in prep_classes]\n",
    "\n",
    "# Print results with probabilities\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected preparation time: {recipe['expected_time']} minutes\")\n",
    "    print(f\"  Predicted preparation time: {prep_labels[i]}\")\n",
    "    prep_probs_str = \", \".join([f\"{inv_prep_time_label_map[j]}: {prep_preds[i][j]*100:.2f}%\" for j in range(len(prep_preds[i]))])\n",
    "    print(f\"  Preparation time probabilities: {prep_probs_str}\")"
   ],
   "id": "367571519be110ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'DIFFICULTY' e testing",
   "id": "2b694bd06c7801a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.291549800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/difficulty/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/difficulty/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/difficulty/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === SECOND MODEL: DIFFICULTY ===\n",
    "df_difficulty = pd.read_csv(\"recipes_with_prices\")\n",
    "df_difficulty, difficulty_encoder = preprocess(df_difficulty, [\"ingredients\", \"directions\"], \"difficulty\")\n",
    "difficulty_model = train_text_classifier(df_difficulty, difficulty_encoder, model_name_prefix=\"difficulty_classifier\")"
   ],
   "id": "2c63caf69e9c1eb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.293549800Z",
     "start_time": "2025-05-21T20:20:50.292551900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "difficulty_model = load_model(\"classifiers/difficulty/difficulty_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/difficulty/difficulty_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    difficulty_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/difficulty/difficulty_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    difficulty_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_difficulty_label_map = {v: k for k, v in difficulty_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected difficulty\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sautÃ© garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"SautÃ© the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, bÃ©chamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, bÃ©chamel and cheese. Bake at 180Â°C for 40 minutes.\",\n",
    "        \"expected_difficulty\": \"Hard\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_difficulty\": \"Easy\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_difficulty\": \"Medium\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. SautÃ© onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_difficulty\": \"Hard\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "diff_sequences = difficulty_tokenizer.texts_to_sequences(texts)\n",
    "diff_padded = pad_sequences(diff_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting difficulty\n",
    "diff_preds = difficulty_model.predict(diff_padded)\n",
    "diff_classes = diff_preds.argmax(axis=1)\n",
    "diff_labels = [inv_difficulty_label_map[c] for c in diff_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected difficulty: {recipe['expected_difficulty']}\")\n",
    "    print(f\"  Predicted difficulty: {diff_labels[i]}\")\n",
    "    diff_probs_str = \", \".join([f\"{inv_difficulty_label_map[j]}: {diff_preds[i][j]*100:.2f}%\" for j in range(len(diff_preds[i]))])\n",
    "    print(f\"  Difficulty probabilities: {diff_probs_str}\\n\")"
   ],
   "id": "8c4c90ec82e24a52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'VEGAN' e testing",
   "id": "a4918a853d499001"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.295554300Z",
     "start_time": "2025-05-21T20:20:50.293549800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/vegan/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/vegan/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/vegan/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === THIRD MODEL: VEGAN ===\n",
    "df_vegan = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"VEGAN\"]].copy()\n",
    "df_vegan, vegan_encoder = preprocess(df_vegan, [\"INGREDIENTS\", \"DIRECTIONS\"], \"VEGAN\")\n",
    "vegan_classifier_model = train_text_classifier(df_vegan, vegan_encoder, model_name_prefix=\"vegan_classifier\")"
   ],
   "id": "a46683e1e4a3fd77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T20:20:50.301553500Z",
     "start_time": "2025-05-21T20:20:50.295554300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "vegan_model = load_model(\"classifiers/vegan/vegan_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/vegan/vegan_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    vegan_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/vegan/vegan_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    vegan_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_vegan_label_map = {v: k for k, v in vegan_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected vegan\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sautÃ© garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_vegan\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"SautÃ© the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, bÃ©chamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, bÃ©chamel and cheese. Bake at 180Â°C for 40 minutes.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_vegan\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_vegan\": False\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. SautÃ© onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_vegan\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "vegan_sequences = vegan_tokenizer.texts_to_sequences(texts)\n",
    "vegan_padded = pad_sequences(vegan_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting vegan true or false\n",
    "vegan_preds = vegan_model.predict(vegan_padded)\n",
    "vegan_classes = vegan_preds.argmax(axis=1)\n",
    "vegan_labels = [inv_vegan_label_map[c] for c in vegan_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected vegan: {recipe['expected_vegan']}\")\n",
    "    print(f\"  Predicted vegan: {vegan_labels[i]}\")\n",
    "    vegan_probs_str = \", \".join([f\"{inv_vegan_label_map[j]}: {vegan_preds[i][j]*100:.2f}%\" for j in range(len(vegan_preds[i]))])\n",
    "    print(f\"  Vegan probabilities: {vegan_probs_str}\\n\")"
   ],
   "id": "3de5d93512c1d065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione del modello per la classificazione del tag 'VEGETARIAN' e testing",
   "id": "35c80420b43a76c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.297555600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Default parameters\n",
    "MAX_LEN = 500\n",
    "NUM_WORDS = 20000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def preprocess(df, text_columns, label_column, n=10000):\n",
    "    df = df[text_columns + [label_column]].dropna().head(n).copy()\n",
    "    df[text_columns[0]] = df[text_columns[0]].apply(eval)\n",
    "    df[text_columns[1]] = df[text_columns[1]].apply(eval)\n",
    "    df[\"full_text\"] = df[text_columns[0]].apply(lambda x: \" \".join(x)) + \" \" + df[text_columns[1]].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"encoded_label\"] = label_encoder.fit_transform(df[label_column])\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "def train_text_classifier(df, label_encoder, model_name_prefix):\n",
    "    X = df[\"full_text\"]\n",
    "    y = df[\"encoded_label\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save(f\"classifiers/vegetarian/{model_name_prefix}.h5\")\n",
    "    with open(f\"classifiers/vegetarian/{model_name_prefix}_label_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))), f)\n",
    "\n",
    "    with open(f\"classifiers/vegetarian/{model_name_prefix}_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    print(f\"Modello '{model_name_prefix}' salvato con successo.\")\n",
    "    return model\n",
    "\n",
    "# === THIRD MODEL: VEGETARIAN ===\n",
    "df_vegetarian = df[[\"INGREDIENTS\", \"DIRECTIONS\", \"VEGETARIAN\"]].copy()\n",
    "df_vegetarian, vegetarian_encoder = preprocess(df_vegetarian, [\"INGREDIENTS\", \"DIRECTIONS\"], \"VEGETARIAN\")\n",
    "vegetarian_classifier_model = train_text_classifier(df_vegetarian, vegetarian_encoder, model_name_prefix=\"vegetarian_classifier\")"
   ],
   "id": "44472144d51bbbb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.298553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "MAX_LEN = 500  # same as training\n",
    "\n",
    "# Load model and tokenizer\n",
    "vegetarian_model = load_model(\"classifiers/vegetarian/vegetarian_classifier.h5\")\n",
    "\n",
    "with open(\"classifiers/vegetarian/vegetarian_classifier_tokenizer.pkl\", \"rb\") as f:\n",
    "    vegetarian_tokenizer = pickle.load(f)\n",
    "\n",
    "with open(\"classifiers/vegetarian/vegetarian_classifier_label_mapping.pkl\", \"rb\") as f:\n",
    "    vegetarian_label_map = pickle.load(f)\n",
    "\n",
    "# Reverse dictionaries to decode predictions\n",
    "inv_vegetarian_label_map = {v: k for k, v in vegetarian_label_map.items()}\n",
    "\n",
    "# List of 10 recipes with expected vegetarian\n",
    "recipes = [\n",
    "    {\n",
    "        \"ingredients\": \"200g spaghetti, 2 cloves garlic, chili pepper, extra virgin olive oil, salt\",\n",
    "        \"instructions\": \"Cook the spaghetti. Meanwhile, sautÃ© garlic and chili in the oil. Mix with the pasta.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lettuce, 1 can of tuna, tomatoes, black olives, onion, olive oil, salt\",\n",
    "        \"instructions\": \"Wash and cut the vegetables. Add the drained tuna and olives. Dress with oil and salt.\",\n",
    "        \"expected_vegetarian\": False  # Tuna = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"300g Carnaroli rice, 1 saffron sachet, vegetable broth, butter, onion, Parmesan cheese\",\n",
    "        \"instructions\": \"SautÃ© the onion, add rice and deglaze with wine. Gradually pour in the broth. Add saffron and stir in butter and cheese.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"3 eggs, salt, pepper, butter\",\n",
    "        \"instructions\": \"Beat the eggs with salt and pepper. Pour into a pan with melted butter and stir until set.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Lasagna sheets, meat sauce, bÃ©chamel, Parmesan cheese\",\n",
    "        \"instructions\": \"Layer pasta, sauce, bÃ©chamel and cheese. Bake at 180Â°C for 40 minutes.\",\n",
    "        \"expected_vegetarian\": False  # Meat sauce = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Apples, bananas, oranges, strawberries, lemon juice, sugar\",\n",
    "        \"instructions\": \"Cut the fruit into pieces, mix with lemon juice and sugar, refrigerate.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Chicken breast, onion, curry powder, cream or coconut milk, oil, salt\",\n",
    "        \"instructions\": \"Brown the onion, add diced chicken, curry, and cream. Cook until the chicken is tender.\",\n",
    "        \"expected_vegetarian\": False  # Chicken = non vegetarian\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Ladyfingers, mascarpone, eggs, sugar, coffee, cocoa powder\",\n",
    "        \"instructions\": \"Make a cream with yolks, sugar and mascarpone. Layer ladyfingers soaked in coffee and the cream. Dust with cocoa and chill.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"2 eggs, 250ml milk, 125g flour, sugar, butter\",\n",
    "        \"instructions\": \"Mix flour, eggs and milk into a batter. Cook in pan with butter. Fill as desired.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"Mixed dried legumes, onion, carrot, celery, vegetable broth, oil, salt\",\n",
    "        \"instructions\": \"Soak legumes for 12 hours. SautÃ© onion, carrot, celery. Add legumes and broth and cook for at least an hour.\",\n",
    "        \"expected_vegetarian\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare input texts for models (ingredients + instructions)\n",
    "texts = [r[\"ingredients\"] + \" \" + r[\"instructions\"] for r in recipes]\n",
    "\n",
    "# Tokenize and padding\n",
    "vegetarian_sequences = vegetarian_tokenizer.texts_to_sequences(texts)\n",
    "vegetarian_padded = pad_sequences(vegetarian_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Predicting vegetarian true or false\n",
    "vegetarian_preds = vegetarian_model.predict(vegetarian_padded)\n",
    "vegetarian_classes = vegetarian_preds.argmax(axis=1)\n",
    "vegetarian_labels = [inv_vegetarian_label_map[c] for c in vegetarian_classes]\n",
    "\n",
    "# Print results\n",
    "for i, recipe in enumerate(recipes):\n",
    "    print(f\"Recipe {i+1}:\")\n",
    "    print(f\"  Expected vegetarian: {recipe['expected_vegetarian']}\")\n",
    "    print(f\"  Predicted vegetarian: {vegetarian_labels[i]}\")\n",
    "    vegetarian_probs_str = \", \".join([f\"{inv_vegetarian_label_map[j]}: {vegetarian_preds[i][j]*100:.2f}%\" for j in range(len(vegetarian_preds[i]))])\n",
    "    print(f\"  Vegetarian probabilities: {vegetarian_probs_str}\\n\")"
   ],
   "id": "63280a53e93b2d1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-21T20:20:50.299556100Z"
    }
   },
   "id": "7e31b42298771f5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
